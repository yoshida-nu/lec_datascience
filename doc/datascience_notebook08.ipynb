{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 事前準備：共通コードの実行\n",
    "* このノートブックに接続したら，まずは以下の2つの共通コード（コードAとコードB）を実行する\n",
    "* これらの共通コードを実行しないと，それ以降のコードが実行できないので注意する\n",
    "* また，コードAとコードBは，ノートブックに接続するたび毎回実行すること（ノートブックに接続中は，何度も実行する必要はない）\n",
    "* 共通コードの詳細についての説明は割愛する（簡単な説明は第2回の「[サンプルノートブック02](https://colab.research.google.com/github/yoshida-nu/lec_datascience/blob/main/doc/datascience_notebook02.ipynb)」を参照）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27115,
     "status": "ok",
     "timestamp": 1716689312959,
     "user": {
      "displayName": "Takahiro YOSHIDA",
      "userId": "00096252480874798687"
     },
     "user_tz": -540
    },
    "id": "3pAqkx-zbIU2",
    "outputId": "b4d1e387-8e66-426b-8183-225623aa6c06"
   },
   "outputs": [],
   "source": [
    "# コードA：日本語化ライブラリ導入\n",
    "! pip install japanize-matplotlib | tail -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3722,
     "status": "ok",
     "timestamp": 1718943596154,
     "user": {
      "displayName": "Takahiro YOSHIDA",
      "userId": "00096252480874798687"
     },
     "user_tz": -540
    },
    "id": "SOfPe7UybRuo"
   },
   "outputs": [],
   "source": [
    "# コードB：共通事前処理\n",
    "\n",
    "# B1:余分なワーニングを非表示にする\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 必要ライブラリのimport\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib # matplotlib日本語化対応\n",
    "import seaborn as sns\n",
    "\n",
    "# B2:データフレーム表示用関数\n",
    "from IPython.display import display\n",
    "\n",
    "# B3:表示オプション調整\n",
    "np.set_printoptions(suppress = True, precision = 3) #numpyの浮動小数点の表示精度\n",
    "pd.options.display.float_format = '{:.3f}'.format #pandasでの浮動小数点の表示精度\n",
    "pd.set_option('display.max_columns', None) #データフレームですべての列データを表示\n",
    "\n",
    "# B4:グラフのデフォルトフォント指定\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "# 乱数の種\n",
    "random_seed = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ボストン住宅データ\n",
    "* 第6回「[サンプルノートブック06](https://colab.research.google.com/github/yoshida-nu/lec_datascience/blob/main/doc/datascience_notebook06.ipynb)」で使用で使用した1970年代後半におけるボストンの住宅価格データ\n",
    "* URL: https://bit.ly/4hwOUgx\n",
    "\n",
    "|**列名**| **意味** |\n",
    "|:--|:--|\n",
    "|CRIME| その地域の犯罪発生率（high / low / very_low） |\n",
    "|ZN| 25,000平方フィートを超える住居区画の占める割合（広い部屋の割合） |\n",
    "|INDUS| 非小売業が占める面積の割合 |\n",
    "|CHAS| チャールズ川の付近かどうかのダミー変数（1: 川周辺，0: それ以外） |\n",
    "|NOX| 窒素酸化物の濃度 |\n",
    "|RM| 1戸当たりの平均部屋数 |\n",
    "|AGE| 1940年より前に建てられた物件の割合（築年数が35～40年ほどの割合） |\n",
    "|DIS| ボストン市内の5つの雇用施設までの距離 |\n",
    "|RAD| 主要高速道路へのアクセスしやすさの指標 |\n",
    "|TAX| 10,000ドル当たりの固定資産税率 |\n",
    "|PTRATIO| その地域の教員1人当たりの生徒数 |\n",
    "|LSTAT| その地域の低所得者の割合 |\n",
    "|PRICE| その地域の住宅平均価格（1,000ドル単位） |\n",
    "  \n",
    "**［以下のコードの処理内容］**\n",
    "*  1行目: ファイルのURLを変数`url`に代入\n",
    "*  2行目: pandasの`read_csv`関数を使って，ファイルをDataFrameとして読み込んで，変数`df`に代入\n",
    "*  3行目: `display`関数を使ってデータ（`df`の内容）を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIME</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.718</td>\n",
       "      <td>3.561</td>\n",
       "      <td>87.900</td>\n",
       "      <td>1.613</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>7.120</td>\n",
       "      <td>27.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>low</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.140</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.950</td>\n",
       "      <td>82.000</td>\n",
       "      <td>3.990</td>\n",
       "      <td>4.000</td>\n",
       "      <td>307</td>\n",
       "      <td>21.000</td>\n",
       "      <td>27.710</td>\n",
       "      <td>13.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>very_low</td>\n",
       "      <td>82.500</td>\n",
       "      <td>2.030</td>\n",
       "      <td>0</td>\n",
       "      <td>0.415</td>\n",
       "      <td>6.162</td>\n",
       "      <td>38.400</td>\n",
       "      <td>6.270</td>\n",
       "      <td>2.000</td>\n",
       "      <td>348</td>\n",
       "      <td>14.700</td>\n",
       "      <td>7.430</td>\n",
       "      <td>24.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>low</td>\n",
       "      <td>0.000</td>\n",
       "      <td>21.890</td>\n",
       "      <td>0</td>\n",
       "      <td>0.624</td>\n",
       "      <td>6.151</td>\n",
       "      <td>97.900</td>\n",
       "      <td>1.669</td>\n",
       "      <td>4.000</td>\n",
       "      <td>437</td>\n",
       "      <td>21.200</td>\n",
       "      <td>18.460</td>\n",
       "      <td>17.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.614</td>\n",
       "      <td>6.980</td>\n",
       "      <td>67.600</td>\n",
       "      <td>2.533</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>11.660</td>\n",
       "      <td>29.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>high</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.740</td>\n",
       "      <td>6.219</td>\n",
       "      <td>100.000</td>\n",
       "      <td>2.005</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>16.590</td>\n",
       "      <td>18.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>high</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.655</td>\n",
       "      <td>5.759</td>\n",
       "      <td>48.200</td>\n",
       "      <td>3.067</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>14.130</td>\n",
       "      <td>19.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>high</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.671</td>\n",
       "      <td>6.380</td>\n",
       "      <td>96.200</td>\n",
       "      <td>1.386</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>23.690</td>\n",
       "      <td>13.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>low</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.900</td>\n",
       "      <td>0</td>\n",
       "      <td>0.544</td>\n",
       "      <td>5.914</td>\n",
       "      <td>83.200</td>\n",
       "      <td>3.999</td>\n",
       "      <td>4.000</td>\n",
       "      <td>304</td>\n",
       "      <td>18.400</td>\n",
       "      <td>18.330</td>\n",
       "      <td>17.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>high</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.693</td>\n",
       "      <td>5.453</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.490</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>30.590</td>\n",
       "      <td>5.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIME     ZN  INDUS  CHAS   NOX    RM     AGE   DIS    RAD  TAX  \\\n",
       "0       high  0.000 18.100     0 0.718 3.561  87.900 1.613 24.000  666   \n",
       "1        low  0.000  8.140     0 0.538 5.950  82.000 3.990  4.000  307   \n",
       "2   very_low 82.500  2.030     0 0.415 6.162  38.400 6.270  2.000  348   \n",
       "3        low  0.000 21.890     0 0.624 6.151  97.900 1.669  4.000  437   \n",
       "4       high  0.000 18.100     0 0.614 6.980  67.600 2.533 24.000  666   \n",
       "..       ...    ...    ...   ...   ...   ...     ...   ...    ...  ...   \n",
       "95      high  0.000 18.100     0 0.740 6.219 100.000 2.005 24.000  666   \n",
       "96      high  0.000 18.100     0 0.655 5.759  48.200 3.067 24.000  666   \n",
       "97      high  0.000 18.100     0 0.671 6.380  96.200 1.386 24.000  666   \n",
       "98       low  0.000  9.900     0 0.544 5.914  83.200 3.999  4.000  304   \n",
       "99      high  0.000 18.100     0 0.693 5.453 100.000 1.490 24.000  666   \n",
       "\n",
       "    PTRATIO  LSTAT  PRICE  \n",
       "0    20.200  7.120 27.500  \n",
       "1    21.000 27.710 13.200  \n",
       "2    14.700  7.430 24.100  \n",
       "3    21.200 18.460 17.800  \n",
       "4    20.200 11.660 29.800  \n",
       "..      ...    ...    ...  \n",
       "95   20.200 16.590 18.400  \n",
       "96   20.200 14.130 19.900  \n",
       "97   20.200 23.690 13.100  \n",
       "98   18.400 18.330 17.800  \n",
       "99   20.200 30.590  5.000  \n",
       "\n",
       "[100 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'https://bit.ly/4hwOUgx'\n",
    "df = pd.read_csv(url)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代表的な回帰モデル\n",
    "* 線形回帰モデル\n",
    ">* 最も基本的なモデルで説明変数と目的変数が線形関係にあると仮定\n",
    "* 多項式回帰モデル\n",
    ">* 線形回帰を拡張し，説明変数の高次の項を含めたモデル\n",
    ">* 線形回帰モデルの説明変数を2乗，3乗，… した変数や説明変数同士の積などを説明変数に含んだモデルとなる\n",
    ">* より複雑な非線形関係をモデル化できる\n",
    "* リッジ回帰モデル／ラッソ回帰モデル\n",
    ">* 線形回帰モデルと多項式回帰モデルは，回帰係数を求めるために最小化する損失関数を平均二乗誤差としている\n",
    ">* これに対して，リッジ回帰モデルやラッソ回帰モデルは，平均二乗誤差にに正則化項（後述）を加えたものを損失関数としている\n",
    ">* 過学習を起こしにくいモデルとなる\n",
    "* エラスティックネット（Elastic Net）モデル\n",
    ">* リッジ回帰とラッソ回帰の正則化項を組み合わせたモデル\n",
    "* 回帰木モデル\n",
    ">* 分類木の概念を回帰に応用したモデル\n",
    ">* 説明変数と目的変数の間の非線形関係もモデル化できる\n",
    ">* そのため，複雑なデータ構造に対応する柔軟性を持つ\n",
    ">* データのスケールの影響が少ないため，データの標準化を必要としない\n",
    ">* 変数間の複雑な関係を木構造で可視化できるため，人間が理解しやすい形でモデルを示すことができる\n",
    "* ランダムフォレスト回帰モデル\n",
    ">* 複数の回帰木を組み合わせたモデル\n",
    ">* 各回帰木の予測を平均化することで，モデルの精度を向上させる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTB7BgX6Yi5H"
   },
   "source": [
    "# データの前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理の概要\n",
    "* まずは，多項式回帰モデルを考える\n",
    "* このモデルに合わせて以下の前処理を順に行う\n",
    ">* 学習に利用しないCRIM列を削除する（欠損値への対処を単純化するためでもある）\n",
    ">* 欠損値を算術平均に置き換える\n",
    ">* 外れ値を選択・削除する\n",
    ">* 目的変数と説明変数に分割\n",
    ">* 訓練データ（70％）とテストデータ（30%）に分割\n",
    ">* データの標準化\n",
    "* 本来は「訓練データ＆検証データ」と「テストデータ」に分割し，モデルをチューニングする作業も行うが，ここではチューニング作業を省略する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 列の削除／欠損値の対処／外れ値の削除\n",
    "* `drop`メソッドを用いて，CRIME列をDataFrameから削除 ⇒ `df.drop(['CRIM'], axis = 1)`\n",
    ">* `axis = 1`で行データを削除\n",
    "* 欠損値を算術平均に置き換える ⇒ `df.fillna(df.mean())`\n",
    ">* `mean`メソッドで求めた算術平均を引数として，`fillna`メソッドを呼び出す\n",
    "* `drop`メソッドで外れ値を削除 ⇒ `df.drop([76], axis = 0)`\n",
    ">* 第6回講義「線形回帰モデルの学習(2)」と同様に，インデックス76のデータを外れ値として削除する\n",
    ">* `axis = 0`で行データを削除\n",
    "  \n",
    "**［以下のコードの処理内容］**\n",
    "* 1～2行目: ファイルをDataFrameとして読み込み，変数`df`に代入\n",
    "* 3行目: `drop`メソッドで，`df`からCRIME列を削除し，その結果を`df`に代入\n",
    "* 4行目: `fillna`メソッドと`mean`メソッドを使って，`df`の欠損値を算術平均で穴埋めし，その結果を`df`に代入\n",
    "* 5行目: `drop`メソッドで，`df`から外れ値（インデックス76に対応する行データ）を削除し，その結果を`df`に代入\n",
    "* 6行目: `isnull`メソッドと`sum`メソッドを組み合わせて，各列の欠損値の数を計算して，`display`関数で表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "executionInfo": {
     "elapsed": 846,
     "status": "ok",
     "timestamp": 1716689330773,
     "user": {
      "displayName": "Takahiro YOSHIDA",
      "userId": "00096252480874798687"
     },
     "user_tz": -540
    },
    "id": "PquWcK03JaNa",
    "outputId": "7fe44825-4704-4d98-b144-58215e3cff33"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>欠損値の数</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRICE</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         欠損値の数\n",
       "ZN           0\n",
       "INDUS        0\n",
       "CHAS         0\n",
       "NOX          0\n",
       "RM           0\n",
       "AGE          0\n",
       "DIS          0\n",
       "RAD          0\n",
       "TAX          0\n",
       "PTRATIO      0\n",
       "LSTAT        0\n",
       "PRICE        0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'https://bit.ly/4hwOUgx'\n",
    "df = pd.read_csv(url)\n",
    "df = df.drop(['CRIME'], axis = 1)\n",
    "df = df.fillna(df.mean())\n",
    "df = df.drop([76], axis = 0)\n",
    "display(pd.DataFrame(df.isnull().sum(), columns = ['欠損値の数']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目的変数と説明変数に分割\n",
    "* `PRICE`を目的変数とする\n",
    "* 説明変数として，`RM`, `LSTAT`, `PTRATIO`を選択する\n",
    "* さらに，説明変数として選択した `RM`, `LSTAT`, `PTRATIO` から決まる以下の量を説明変数に加える\n",
    ">* `RM^2`: `RM`の2乗\n",
    ">* `LSTAT^2`：, `LSTAT`の2乗\n",
    ">* `PTRATIO^2`： `PTRATIO`の2乗\n",
    ">* `RM LSTAT`： `RM`と`LSTAT`の積\n",
    ">* `RM PTRATIO`： `RM`と`PTRATIO`の積\n",
    ">* `LSTAT PTRATIO`： `LSTAT`と`PTRATIO`の積\n",
    "* `RM LSTAT`, `RM PTRATIO`, `LSTAT PTRATIO` を交互作用項と呼ぶ\n",
    "* また，このモデルを次数が2（2次）の多項式回帰モデルと呼ぶ\n",
    "* 任意の次数の多項式回帰モデルの説明変数は，`sklearn`（scikit-learn）の`preprocessing`モジュールにおける，`PolynomialFeatures`クラスを利用することで簡単に作成できる\n",
    "  \n",
    "**［`PolynomialFeatures`クラスによる説明変数の作成手順］**\n",
    "* まず，多項式モデルの説明変数を生成するためのオブジェクトを`PolynomialFeatures`クラスから生成し，変数に代入する\n",
    "* 書式: `変数 = PolynomialFeatures(degree = 次数, include_bias = False)`  \n",
    ">* `include_bias`: 定数項を含む（`True`），含まない（`False`）を指定\n",
    ">* `include_bias = True`にすると，すべての値が1の列（定数項）を作成する\n",
    ">* `include_bias = False`は，この列を作成しないということになるが，モデルの学習において定数項を0にするという意味ではないことに注意する\n",
    "* 生成したオブジェクトの`fit_transform`メソッドに説明変数データを渡して呼び出す\n",
    "* 書式: `変数.fit_transform(元の説明変数データ)`\n",
    ">* 引数で指定した説明変数データに対して，次数に応じた説明変数データが生成される\n",
    ">* 戻り値のクラス（データ型）は ndarray\n",
    "  \n",
    "**［以下のコードの処理内容］**\n",
    "* 1～2行目: ファイルをDataFrameとして読み込み，変数`df`に代入\n",
    "* 3～5行目: 列の削除，欠損値の対処，外れ値の削除\n",
    "* 6行目: 説明変数の列名を要素とするリスト`['RM', 'PTRATIO', 'LSTAT']`を変数`x_cols`に代入\n",
    "* 7行目: 目的変数の列名（リスト）`['PRICE']`を変数`t_col`に代入\n",
    "* 8行目: DataFrame `df` から,`df[x_cols]`で，説明変数の列だけ取り出し変数`x`に代入\n",
    "* 9行目: DataFrame `df` から,`df[t_col]`で目的変数の列だけ取り出し変数`t`に代入\n",
    "* 10行目: `preprocessing`モジュールの`PolynomialFeatures`クラスの読み込み\n",
    "* 11行目: `PolynomialFeatures`クラスのオブジェクトを生成し，変数`pf`に代入\n",
    ">* `degree = 2`で，2次の多項式回帰モデルを指定\n",
    ">* `include_bias = False`で，定数項の列を作成しない\n",
    "* 12行目: `fit_transform`メソッドで，2次の多項式回帰モデルの説明変数データを生成し，変数`x`に代入\n",
    ">* 引数は3つの説明変数 `RM`, `PTRATIO`, `LSTAT` のデータ `x`\n",
    ">* このデータをもとに2次の多項式回帰モデルの説明変数データ（2次の項） `RM^2`, `LSTAT^2`, `PTRATIO^2`, `RM LSTAT`, `RM PTRATIO`, `LSTAT PTRATIO`を生成\n",
    "* 13行目: `DataFrame`関数で，`x`をDataFrameに変換し，その結果を変数`x`に代入\n",
    ">* `pf.get_feature_names_out()`で，2次の多項式回帰モデルの説明変数名を取り出し，DataFrameの列名（`columns`）として設定\n",
    "* 14行目: `display`関数で，`x`の内容を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RM</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RM^2</th>\n",
       "      <th>RM PTRATIO</th>\n",
       "      <th>RM LSTAT</th>\n",
       "      <th>PTRATIO^2</th>\n",
       "      <th>PTRATIO LSTAT</th>\n",
       "      <th>LSTAT^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.561</td>\n",
       "      <td>20.200</td>\n",
       "      <td>7.120</td>\n",
       "      <td>12.681</td>\n",
       "      <td>71.932</td>\n",
       "      <td>25.354</td>\n",
       "      <td>408.040</td>\n",
       "      <td>143.824</td>\n",
       "      <td>50.694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.950</td>\n",
       "      <td>21.000</td>\n",
       "      <td>27.710</td>\n",
       "      <td>35.403</td>\n",
       "      <td>124.950</td>\n",
       "      <td>164.875</td>\n",
       "      <td>441.000</td>\n",
       "      <td>581.910</td>\n",
       "      <td>767.844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.162</td>\n",
       "      <td>14.700</td>\n",
       "      <td>7.430</td>\n",
       "      <td>37.970</td>\n",
       "      <td>90.581</td>\n",
       "      <td>45.784</td>\n",
       "      <td>216.090</td>\n",
       "      <td>109.221</td>\n",
       "      <td>55.205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.151</td>\n",
       "      <td>21.200</td>\n",
       "      <td>18.460</td>\n",
       "      <td>37.835</td>\n",
       "      <td>130.401</td>\n",
       "      <td>113.547</td>\n",
       "      <td>449.440</td>\n",
       "      <td>391.352</td>\n",
       "      <td>340.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.980</td>\n",
       "      <td>20.200</td>\n",
       "      <td>11.660</td>\n",
       "      <td>48.720</td>\n",
       "      <td>140.996</td>\n",
       "      <td>81.387</td>\n",
       "      <td>408.040</td>\n",
       "      <td>235.532</td>\n",
       "      <td>135.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>6.219</td>\n",
       "      <td>20.200</td>\n",
       "      <td>16.590</td>\n",
       "      <td>38.676</td>\n",
       "      <td>125.624</td>\n",
       "      <td>103.173</td>\n",
       "      <td>408.040</td>\n",
       "      <td>335.118</td>\n",
       "      <td>275.228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5.759</td>\n",
       "      <td>20.200</td>\n",
       "      <td>14.130</td>\n",
       "      <td>33.166</td>\n",
       "      <td>116.332</td>\n",
       "      <td>81.375</td>\n",
       "      <td>408.040</td>\n",
       "      <td>285.426</td>\n",
       "      <td>199.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>6.380</td>\n",
       "      <td>20.200</td>\n",
       "      <td>23.690</td>\n",
       "      <td>40.704</td>\n",
       "      <td>128.876</td>\n",
       "      <td>151.142</td>\n",
       "      <td>408.040</td>\n",
       "      <td>478.538</td>\n",
       "      <td>561.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5.914</td>\n",
       "      <td>18.400</td>\n",
       "      <td>18.330</td>\n",
       "      <td>34.975</td>\n",
       "      <td>108.818</td>\n",
       "      <td>108.404</td>\n",
       "      <td>338.560</td>\n",
       "      <td>337.272</td>\n",
       "      <td>335.989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.453</td>\n",
       "      <td>20.200</td>\n",
       "      <td>30.590</td>\n",
       "      <td>29.735</td>\n",
       "      <td>110.151</td>\n",
       "      <td>166.807</td>\n",
       "      <td>408.040</td>\n",
       "      <td>617.918</td>\n",
       "      <td>935.748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RM  PTRATIO  LSTAT   RM^2  RM PTRATIO  RM LSTAT  PTRATIO^2  \\\n",
       "0  3.561   20.200  7.120 12.681      71.932    25.354    408.040   \n",
       "1  5.950   21.000 27.710 35.403     124.950   164.875    441.000   \n",
       "2  6.162   14.700  7.430 37.970      90.581    45.784    216.090   \n",
       "3  6.151   21.200 18.460 37.835     130.401   113.547    449.440   \n",
       "4  6.980   20.200 11.660 48.720     140.996    81.387    408.040   \n",
       "..   ...      ...    ...    ...         ...       ...        ...   \n",
       "94 6.219   20.200 16.590 38.676     125.624   103.173    408.040   \n",
       "95 5.759   20.200 14.130 33.166     116.332    81.375    408.040   \n",
       "96 6.380   20.200 23.690 40.704     128.876   151.142    408.040   \n",
       "97 5.914   18.400 18.330 34.975     108.818   108.404    338.560   \n",
       "98 5.453   20.200 30.590 29.735     110.151   166.807    408.040   \n",
       "\n",
       "    PTRATIO LSTAT  LSTAT^2  \n",
       "0         143.824   50.694  \n",
       "1         581.910  767.844  \n",
       "2         109.221   55.205  \n",
       "3         391.352  340.772  \n",
       "4         235.532  135.956  \n",
       "..            ...      ...  \n",
       "94        335.118  275.228  \n",
       "95        285.426  199.657  \n",
       "96        478.538  561.216  \n",
       "97        337.272  335.989  \n",
       "98        617.918  935.748  \n",
       "\n",
       "[99 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'https://bit.ly/4hwOUgx'\n",
    "df = pd.read_csv(url)\n",
    "df = df.drop(['CRIME'], axis = 1)\n",
    "df = df.fillna(df.mean())\n",
    "df = df.drop([76], axis = 0)\n",
    "x_cols = ['RM', 'PTRATIO', 'LSTAT']\n",
    "t_col = ['PRICE']\n",
    "x = df[x_cols]\n",
    "t = df[t_col]\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pf = PolynomialFeatures(degree = 2, include_bias = False)\n",
    "x = pf.fit_transform(x)\n",
    "x = pd.DataFrame(x, columns = pf.get_feature_names_out())\n",
    "display(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練データとテストデータに分割／データの標準化\n",
    "* 説明変数と目的変数に分割できたので，次に，訓練データとテストデータに分割し，データの標準化を行う\n",
    "* 分割と標準化の処理は第6回「[サンプルノートブック06](https://colab.research.google.com/github/yoshida-nu/lec_datascience/blob/main/doc/datascience_notebook06.ipynb)」のコードと同様\n",
    "  \n",
    "**［以下のコードの処理内容］**\n",
    "* 1～2行目: ファイルをDataFrameとして読み込み，変数`df`に代入\n",
    "* 3～5行目: 列の削除，欠損値の対処，外れ値の削除\n",
    "* 6～13行目: 説明変数と目的変数に分割し，変数`x`と`t`にそれぞれ代入\n",
    "* 14行目: `model_selection`モジュールの`train_test_split`関数の読み込み\n",
    "* 15行目: 説明変数と目的変数を訓練データ（70％）と検証データ（30％）に分割し，`x_train`, `x_test`, `t_train`, `t_test`にそれぞれ代入\n",
    "* 16行目: `preprocessing`モジュールの`StandardScaler`クラスの読み込み\n",
    "* 17行目: `StandardScaler`クラスのオブジェクトを生成し，変数`sc_x`に代入\n",
    "* 18行目: `sc_x`に対し，`fit`メソッドを適用する（引数は`x_train`）\n",
    "* 19行目: `sc_x`に対する`transform`メソッドで`x_train`を標準化し，その結果を変数`x_train_s`に代入\n",
    "* 20行目: `DataFrame`関数で，`x_train_s`をDataFrameに変換し，その結果を変数`x_train_s`に代入\n",
    "* 21行目: `sc_x`に対する`transform`メソッドで`x_test`を標準化し，その結果を変数`x_test_s`に代入\n",
    "* 22行目: `DataFrame`関数で，`x_test_s`をDataFrameに変換し，その結果を変数`x_test_s`に代入\n",
    "* 23行目: `StandardScaler`クラスのオブジェクトを生成し，変数`sc_t`に代入\n",
    "* 24行目: `sc_t`に対し，`fit`メソッドを適用する（引数は`t_train`）\n",
    "* 25行目: `sc_t`に対する`transform`メソッドで`t_train`を標準化し，その結果を変数`t_train_s`に代入\n",
    "* 26行目: `DataFrame`関数で，`t_train_s`をDataFrameに変換し，その結果を変数`t_train_s`に代入\n",
    "* 27行目: `sc_t`に対する`transform`メソッドで`t_test`を標準化し，その結果を変数`t_test_s`に代入\n",
    "* 28行目: `DataFrame`関数で，`t_test_s`をDataFrameに変換し，その結果を変数`t_test_s`に代入\n",
    "* 29～36行目: `x_train_s`, `x_test_s`, `t_train_s`, `t_test_s`の内容をそれぞれ表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ x_train_s ================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RM</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RM^2</th>\n",
       "      <th>RM PTRATIO</th>\n",
       "      <th>RM LSTAT</th>\n",
       "      <th>PTRATIO^2</th>\n",
       "      <th>PTRATIO LSTAT</th>\n",
       "      <th>LSTAT^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.503</td>\n",
       "      <td>1.182</td>\n",
       "      <td>0.641</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.613</td>\n",
       "      <td>1.248</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.306</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.497</td>\n",
       "      <td>0.245</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-0.437</td>\n",
       "      <td>-1.036</td>\n",
       "      <td>-0.628</td>\n",
       "      <td>-0.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.461</td>\n",
       "      <td>-1.963</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.485</td>\n",
       "      <td>-2.084</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-1.878</td>\n",
       "      <td>-0.422</td>\n",
       "      <td>-0.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.131</td>\n",
       "      <td>0.015</td>\n",
       "      <td>2.644</td>\n",
       "      <td>-1.071</td>\n",
       "      <td>-1.032</td>\n",
       "      <td>2.353</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>2.436</td>\n",
       "      <td>3.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.859</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>0.599</td>\n",
       "      <td>-0.839</td>\n",
       "      <td>-1.061</td>\n",
       "      <td>0.459</td>\n",
       "      <td>-0.401</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.187</td>\n",
       "      <td>-0.847</td>\n",
       "      <td>-0.758</td>\n",
       "      <td>0.127</td>\n",
       "      <td>-0.562</td>\n",
       "      <td>-0.753</td>\n",
       "      <td>-0.894</td>\n",
       "      <td>-0.827</td>\n",
       "      <td>-0.699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-0.426</td>\n",
       "      <td>0.827</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>-0.453</td>\n",
       "      <td>0.344</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>0.840</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>-0.118</td>\n",
       "      <td>1.233</td>\n",
       "      <td>-0.491</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>1.026</td>\n",
       "      <td>-0.504</td>\n",
       "      <td>1.307</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>-0.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>-0.277</td>\n",
       "      <td>-1.709</td>\n",
       "      <td>0.151</td>\n",
       "      <td>-0.315</td>\n",
       "      <td>-1.722</td>\n",
       "      <td>0.158</td>\n",
       "      <td>-1.667</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>-0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.390</td>\n",
       "      <td>0.132</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>-0.378</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-0.451</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RM  PTRATIO  LSTAT   RM^2  RM PTRATIO  RM LSTAT  PTRATIO^2  \\\n",
       "0  -0.503    1.182  0.641 -0.523       0.566     0.613      1.248   \n",
       "1   0.306   -0.999 -0.497  0.245      -0.601    -0.437     -1.036   \n",
       "2  -0.461   -1.963 -0.039 -0.485      -2.084    -0.089     -1.878   \n",
       "3  -1.131    0.015  2.644 -1.071      -1.032     2.353     -0.039   \n",
       "4  -0.859   -0.340  0.599 -0.839      -1.061     0.459     -0.401   \n",
       "..    ...      ...    ...    ...         ...       ...        ...   \n",
       "64  0.187   -0.847 -0.758  0.127      -0.562    -0.753     -0.894   \n",
       "65 -0.426    0.827 -0.128 -0.453       0.344    -0.174      0.840   \n",
       "66 -0.118    1.233 -0.491 -0.166       1.026    -0.504      1.307   \n",
       "67 -0.277   -1.709  0.151 -0.315      -1.722     0.158     -1.667   \n",
       "68 -0.071   -0.390  0.132 -0.122      -0.378     0.190     -0.451   \n",
       "\n",
       "    PTRATIO LSTAT  LSTAT^2  \n",
       "0           0.861    0.388  \n",
       "1          -0.628   -0.559  \n",
       "2          -0.422   -0.244  \n",
       "3           2.436    3.398  \n",
       "4           0.445    0.344  \n",
       "..            ...      ...  \n",
       "64         -0.827   -0.699  \n",
       "65         -0.005   -0.313  \n",
       "66         -0.316   -0.556  \n",
       "67         -0.232   -0.088  \n",
       "68          0.016   -0.103  \n",
       "\n",
       "[69 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ t_train_s ================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-0.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>-0.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>-0.418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PRICE\n",
       "0  -0.346\n",
       "1   0.146\n",
       "2  -0.394\n",
       "3   0.157\n",
       "4  -0.358\n",
       "..    ...\n",
       "64  0.026\n",
       "65 -0.214\n",
       "66 -0.214\n",
       "67 -0.418\n",
       "68  0.865\n",
       "\n",
       "[69 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ x_test_s ================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RM</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RM^2</th>\n",
       "      <th>RM PTRATIO</th>\n",
       "      <th>RM LSTAT</th>\n",
       "      <th>PTRATIO^2</th>\n",
       "      <th>PTRATIO LSTAT</th>\n",
       "      <th>LSTAT^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.455</td>\n",
       "      <td>-1.963</td>\n",
       "      <td>2.455</td>\n",
       "      <td>-1.336</td>\n",
       "      <td>-2.838</td>\n",
       "      <td>1.996</td>\n",
       "      <td>-1.878</td>\n",
       "      <td>1.413</td>\n",
       "      <td>3.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.057</td>\n",
       "      <td>0.827</td>\n",
       "      <td>-0.237</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.847</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>0.840</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.492</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-1.065</td>\n",
       "      <td>0.431</td>\n",
       "      <td>-0.441</td>\n",
       "      <td>-1.070</td>\n",
       "      <td>-1.036</td>\n",
       "      <td>-1.100</td>\n",
       "      <td>-0.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.143</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.269</td>\n",
       "      <td>-0.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.286</td>\n",
       "      <td>0.827</td>\n",
       "      <td>2.198</td>\n",
       "      <td>-1.199</td>\n",
       "      <td>-0.554</td>\n",
       "      <td>1.843</td>\n",
       "      <td>0.840</td>\n",
       "      <td>2.347</td>\n",
       "      <td>2.581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.375</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>-0.908</td>\n",
       "      <td>1.368</td>\n",
       "      <td>0.739</td>\n",
       "      <td>-0.778</td>\n",
       "      <td>-0.651</td>\n",
       "      <td>-0.930</td>\n",
       "      <td>-0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.237</td>\n",
       "      <td>-0.390</td>\n",
       "      <td>-0.724</td>\n",
       "      <td>2.363</td>\n",
       "      <td>1.743</td>\n",
       "      <td>-0.418</td>\n",
       "      <td>-0.451</td>\n",
       "      <td>-0.746</td>\n",
       "      <td>-0.682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.143</td>\n",
       "      <td>0.218</td>\n",
       "      <td>-0.853</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.377</td>\n",
       "      <td>-0.866</td>\n",
       "      <td>0.174</td>\n",
       "      <td>-0.799</td>\n",
       "      <td>-0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.331</td>\n",
       "      <td>-0.390</td>\n",
       "      <td>-1.200</td>\n",
       "      <td>2.477</td>\n",
       "      <td>1.830</td>\n",
       "      <td>-1.071</td>\n",
       "      <td>-0.451</td>\n",
       "      <td>-1.171</td>\n",
       "      <td>-0.869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.927</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>-1.277</td>\n",
       "      <td>3.218</td>\n",
       "      <td>2.133</td>\n",
       "      <td>-1.133</td>\n",
       "      <td>-0.651</td>\n",
       "      <td>-1.251</td>\n",
       "      <td>-0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.343</td>\n",
       "      <td>-0.898</td>\n",
       "      <td>0.178</td>\n",
       "      <td>-0.376</td>\n",
       "      <td>-1.068</td>\n",
       "      <td>0.171</td>\n",
       "      <td>-0.941</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.491</td>\n",
       "      <td>0.827</td>\n",
       "      <td>-1.072</td>\n",
       "      <td>0.430</td>\n",
       "      <td>1.299</td>\n",
       "      <td>-1.077</td>\n",
       "      <td>0.840</td>\n",
       "      <td>-0.959</td>\n",
       "      <td>-0.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.257</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.295</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.207</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>-0.317</td>\n",
       "      <td>-0.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.517</td>\n",
       "      <td>0.320</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-0.536</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>-0.201</td>\n",
       "      <td>0.282</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.080</td>\n",
       "      <td>0.269</td>\n",
       "      <td>-1.341</td>\n",
       "      <td>1.046</td>\n",
       "      <td>1.349</td>\n",
       "      <td>-1.353</td>\n",
       "      <td>0.228</td>\n",
       "      <td>-1.261</td>\n",
       "      <td>-0.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.871</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.123</td>\n",
       "      <td>-0.849</td>\n",
       "      <td>-0.658</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.119</td>\n",
       "      <td>-0.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.710</td>\n",
       "      <td>-0.847</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.709</td>\n",
       "      <td>-1.345</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.894</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.316</td>\n",
       "      <td>-0.289</td>\n",
       "      <td>-1.335</td>\n",
       "      <td>2.458</td>\n",
       "      <td>1.931</td>\n",
       "      <td>-1.261</td>\n",
       "      <td>-0.350</td>\n",
       "      <td>-1.285</td>\n",
       "      <td>-0.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-2.955</td>\n",
       "      <td>0.827</td>\n",
       "      <td>1.693</td>\n",
       "      <td>-2.418</td>\n",
       "      <td>-2.294</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.840</td>\n",
       "      <td>1.836</td>\n",
       "      <td>1.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.338</td>\n",
       "      <td>0.320</td>\n",
       "      <td>-0.330</td>\n",
       "      <td>-0.372</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.371</td>\n",
       "      <td>0.282</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>-0.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.058</td>\n",
       "      <td>-1.963</td>\n",
       "      <td>-0.744</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>-1.778</td>\n",
       "      <td>-0.772</td>\n",
       "      <td>-1.878</td>\n",
       "      <td>-0.941</td>\n",
       "      <td>-0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.504</td>\n",
       "      <td>0.320</td>\n",
       "      <td>-0.539</td>\n",
       "      <td>-0.524</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>-0.621</td>\n",
       "      <td>0.282</td>\n",
       "      <td>-0.487</td>\n",
       "      <td>-0.584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.317</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>-0.353</td>\n",
       "      <td>-0.781</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>-0.651</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>-0.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.299</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.237</td>\n",
       "      <td>1.099</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.187</td>\n",
       "      <td>1.233</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.143</td>\n",
       "      <td>1.307</td>\n",
       "      <td>0.321</td>\n",
       "      <td>-0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.612</td>\n",
       "      <td>0.320</td>\n",
       "      <td>-1.162</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.936</td>\n",
       "      <td>-1.172</td>\n",
       "      <td>0.282</td>\n",
       "      <td>-1.086</td>\n",
       "      <td>-0.858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.267</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.263</td>\n",
       "      <td>-0.342</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>-0.414</td>\n",
       "      <td>-0.505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.481</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.698</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.515</td>\n",
       "      <td>-0.642</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.676</td>\n",
       "      <td>-0.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.815</td>\n",
       "      <td>-2.826</td>\n",
       "      <td>-1.398</td>\n",
       "      <td>1.865</td>\n",
       "      <td>-1.295</td>\n",
       "      <td>-1.379</td>\n",
       "      <td>-2.545</td>\n",
       "      <td>-1.463</td>\n",
       "      <td>-0.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-1.073</td>\n",
       "      <td>0.827</td>\n",
       "      <td>2.803</td>\n",
       "      <td>-1.021</td>\n",
       "      <td>-0.331</td>\n",
       "      <td>2.542</td>\n",
       "      <td>0.840</td>\n",
       "      <td>2.959</td>\n",
       "      <td>3.711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RM  PTRATIO  LSTAT   RM^2  RM PTRATIO  RM LSTAT  PTRATIO^2  \\\n",
       "0  -1.455   -1.963  2.455 -1.336      -2.838     1.996     -1.878   \n",
       "1   0.057    0.827 -0.237  0.001       0.847    -0.190      0.840   \n",
       "2   0.492   -0.999 -1.065  0.431      -0.441    -1.070     -1.036   \n",
       "3   0.010    0.827  0.143 -0.045       0.797     0.222      0.840   \n",
       "4  -1.286    0.827  2.198 -1.199      -0.554     1.843      0.840   \n",
       "5   1.375   -0.593 -0.908  1.368       0.739    -0.778     -0.651   \n",
       "6   2.237   -0.390 -0.724  2.363       1.743    -0.418     -0.451   \n",
       "7   0.143    0.218 -0.853  0.084       0.377    -0.866      0.174   \n",
       "8   2.331   -0.390 -1.200  2.477       1.830    -1.071     -0.451   \n",
       "9   2.927   -0.593 -1.277  3.218       2.133    -1.133     -0.651   \n",
       "10 -0.343   -0.898  0.178 -0.376      -1.068     0.171     -0.941   \n",
       "11  0.491    0.827 -1.072  0.430       1.299    -1.077      0.840   \n",
       "12  0.257   -0.086 -0.295  0.196       0.207    -0.215     -0.144   \n",
       "13 -0.517    0.320 -0.134 -0.536      -0.184    -0.201      0.282   \n",
       "14  1.080    0.269 -1.341  1.046       1.349    -1.353      0.228   \n",
       "15 -0.871    0.168  0.123 -0.849      -0.658    -0.020      0.120   \n",
       "16 -0.710   -0.847  0.022 -0.709      -1.345    -0.083     -0.894   \n",
       "17  2.316   -0.289 -1.335  2.458       1.931    -1.261     -0.350   \n",
       "18 -2.955    0.827  1.693 -2.418      -2.294     0.619      0.840   \n",
       "19 -0.338    0.320 -0.330 -0.372      -0.006    -0.371      0.282   \n",
       "20 -0.058   -1.963 -0.744 -0.109      -1.778    -0.772     -1.878   \n",
       "21 -0.504    0.320 -0.539 -0.524      -0.171    -0.621      0.282   \n",
       "22 -0.317   -0.593 -0.098 -0.353      -0.781    -0.118     -0.651   \n",
       "23  0.299    0.827  0.419  0.237       1.099     0.611      0.840   \n",
       "24 -0.187    1.233  0.115 -0.231       0.952     0.143      1.307   \n",
       "25  0.612    0.320 -1.162  0.554       0.936    -1.172      0.282   \n",
       "26  0.267   -0.035 -0.408  0.206       0.263    -0.342     -0.092   \n",
       "27  0.481    0.015 -0.698  0.420       0.515    -0.642     -0.039   \n",
       "28  1.815   -2.826 -1.398  1.865      -1.295    -1.379     -2.545   \n",
       "29 -1.073    0.827  2.803 -1.021      -0.331     2.542      0.840   \n",
       "\n",
       "    PTRATIO LSTAT  LSTAT^2  \n",
       "0           1.413    3.043  \n",
       "1          -0.115   -0.391  \n",
       "2          -1.100   -0.826  \n",
       "3           0.269   -0.094  \n",
       "4           2.347    2.581  \n",
       "5          -0.930   -0.766  \n",
       "6          -0.746   -0.682  \n",
       "7          -0.799   -0.742  \n",
       "8          -1.171   -0.869  \n",
       "9          -1.251   -0.890  \n",
       "10         -0.046   -0.063  \n",
       "11         -0.959   -0.828  \n",
       "12         -0.317   -0.431  \n",
       "13         -0.099   -0.317  \n",
       "14         -1.261   -0.906  \n",
       "15          0.119   -0.111  \n",
       "16         -0.168   -0.195  \n",
       "17         -1.285   -0.904  \n",
       "18          1.836    1.756  \n",
       "19         -0.287   -0.455  \n",
       "20         -0.941   -0.692  \n",
       "21         -0.487   -0.584  \n",
       "22         -0.224   -0.289  \n",
       "23          0.548    0.160  \n",
       "24          0.321   -0.118  \n",
       "25         -1.086   -0.858  \n",
       "26         -0.414   -0.505  \n",
       "27         -0.676   -0.669  \n",
       "28         -1.463   -0.918  \n",
       "29          2.959    3.711  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ t_test_s ================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1.258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-2.086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PRICE\n",
       "0  -0.550\n",
       "1   0.074\n",
       "2   0.841\n",
       "3  -0.118\n",
       "4  -1.438\n",
       "5   1.105\n",
       "6   2.089\n",
       "7   0.289\n",
       "8   3.312\n",
       "9   3.108\n",
       "10 -0.322\n",
       "11 -0.058\n",
       "12  0.086\n",
       "13 -0.286\n",
       "14  0.865\n",
       "15 -0.598\n",
       "16 -0.634\n",
       "17  2.568\n",
       "18 -1.258\n",
       "19  0.277\n",
       "20  0.205\n",
       "21 -0.166\n",
       "22  0.229\n",
       "23 -0.682\n",
       "24 -0.946\n",
       "25  0.661\n",
       "26  0.181\n",
       "27  0.241\n",
       "28  2.532\n",
       "29 -2.086"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'https://bit.ly/4hwOUgx'\n",
    "df = pd.read_csv(url)\n",
    "df = df.drop(['CRIME'], axis = 1)\n",
    "df = df.fillna(df.mean())\n",
    "df = df.drop([76], axis = 0)\n",
    "x_cols = ['RM', 'PTRATIO', 'LSTAT']\n",
    "t_col = ['PRICE']\n",
    "x = df[x_cols]\n",
    "t = df[t_col]\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pf = PolynomialFeatures(degree = 2, include_bias = False)\n",
    "x = pf.fit_transform(x)\n",
    "x = pd.DataFrame(x, columns = pf.get_feature_names_out())\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size = 0.3, random_state = random_seed)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x = StandardScaler()\n",
    "sc_x.fit(x_train)\n",
    "x_train_s = sc_x.transform(x_train)\n",
    "x_train_s = pd.DataFrame(x_train_s, columns = x_train.columns)\n",
    "x_test_s = sc_x.transform(x_test)\n",
    "x_test_s = pd.DataFrame(x_test_s, columns = x_test.columns)\n",
    "sc_t = StandardScaler()\n",
    "sc_t.fit(t_train)\n",
    "t_train_s = sc_t.transform(t_train)\n",
    "t_train_s = pd.DataFrame(t_train_s, columns = t_train.columns)\n",
    "t_test_s = sc_t.transform(t_test)\n",
    "t_test_s = pd.DataFrame(t_test_s, columns = t_test.columns)\n",
    "print('================ x_train_s ================')\n",
    "display(x_train_s)\n",
    "print('================ t_train_s ================')\n",
    "display(pd.DataFrame(t_train_s))\n",
    "print('================ x_test_s ================')\n",
    "display(x_test_s)\n",
    "print('================ t_test_s ================')\n",
    "display(pd.DataFrame(t_test_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8alCl897vEK"
   },
   "source": [
    "# 多項式回帰モデルの学習と評価\n",
    "* 以下のコードで，前処理したボストン住宅データで多項式回帰モデルの学習と評価\n",
    "* 学習と評価（一連の分析）の処理は第6回「[サンプルノートブック06](https://colab.research.google.com/github/yoshida-nu/lec_datascience/blob/main/doc/datascience_notebook06.ipynb)」のコードと同様\n",
    "* ただし，予測の処理は除く\n",
    "* 実行結果の決定係数をみると，テストデータに対する決定係数は，訓練データに対する決定係数よりも小さくなっており，過学習が発生している\n",
    ">* これを過学習と判断するかは分析者次第のところもある\n",
    "  \n",
    "**［以下のコードの処理内容］**\n",
    "* 1～2行目: ファイルをDataFrameとして読み込み，変数`df`に代入\n",
    "* 3～5行目: 列の削除，欠損値の対処，外れ値の削除\n",
    "* 6～13行目: 説明変数と目的変数に分割し，変数`x`と`t`にそれぞれ代入\n",
    "* 14～15行目:  説明変数と目的変数を訓練データ（70％）と検証データ（30％）に分割し，`x_train`, `x_test`, `t_train`, `t_test`にそれぞれ代入\n",
    "* 16～28行目: データの標準化を行い，その結果を`x_train_s`, `x_test_s`, `t_train_s`, `t_test_s`にそれぞれ代入\n",
    "* 29行目:  `sklearn` (scikit-learn) の`linear_model`モジュール内にある`LinearRegression`クラスを読み込む \n",
    "* 30行目: `LinearRegression()`で，モデルの学習を行うためのオブジェクトを`LinearRegression`クラスから生成し，変数`linear_regression_model`に代入\n",
    "* 31行目: 標準化した訓練データ（`x_train_s`と`t_train_s`）を用いて，`fit`メソッドでモデルの学習を実行\n",
    "* 32行目: `linear_regression_model.score(X = x_train_s, y = t_train_s)`で，標準化した訓練データに対する決定係数を計算して変数`score_train`に代入\n",
    "* 33行目: `linear_regression_model.score(X = x_test_s, y = t_test_s)`で，標準化したテストデータに対する決定係数を計算して変数`score_test`に代入\n",
    "* 34行目: `print`関数とf-stringを使って，訓練データに対する決定係数（`score_train`）とテストデータに対する決定係数（`score_test`）を小数点以下3桁まで表示\n",
    "* 35行目: `linear_regression_model`オブジェクトの`coef_`属性から回帰係数（定数項以外）を取り出し，変数`a`に代入\n",
    "* 36行目: `linear_regression_model`オブジェクトの`intercept_`属性から定数項を取り出し，変数`b`に代入\n",
    "* 37行目: `print`関数とf-stringを使って，回帰係数`a`を表示\n",
    "* 38行目: `print`関数とf-stringを使って，定数項`b`を表示（標準化しているので 0 になる）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データの決定係数=0.852 / テストデータの決定係数=0.727\n",
      "回帰係数（定数項以外）: [[-1.08   2.033  1.784  2.269 -0.434 -2.455 -1.831  0.516  0.008]]\n",
      "定数項: [0.]\n"
     ]
    }
   ],
   "source": [
    "url = 'https://bit.ly/4hwOUgx'\n",
    "df = pd.read_csv(url)\n",
    "df = df.drop(['CRIME'], axis = 1)\n",
    "df = df.fillna(df.mean())\n",
    "df = df.drop([76], axis = 0)\n",
    "x_cols = ['RM', 'PTRATIO', 'LSTAT']\n",
    "t_col = ['PRICE']\n",
    "x = df[x_cols]\n",
    "t = df[t_col]\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pf = PolynomialFeatures(degree = 2, include_bias = False)\n",
    "x = pf.fit_transform(x)\n",
    "x = pd.DataFrame(x, columns = pf.get_feature_names_out())\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size = 0.3, random_state = random_seed)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x = StandardScaler()\n",
    "sc_x.fit(x_train)\n",
    "x_train_s = sc_x.transform(x_train)\n",
    "x_train_s = pd.DataFrame(x_train_s, columns = x_train.columns)\n",
    "x_test_s = sc_x.transform(x_test)\n",
    "x_test_s = pd.DataFrame(x_test_s, columns = x_test.columns)\n",
    "sc_t = StandardScaler()\n",
    "sc_t.fit(t_train)\n",
    "t_train_s = sc_t.transform(t_train)\n",
    "t_train_s = pd.DataFrame(t_train_s, columns = t_train.columns)\n",
    "t_test_s = sc_t.transform(t_test)\n",
    "t_test_s = pd.DataFrame(t_test_s, columns = t_test.columns)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linear_regression_model = LinearRegression()\n",
    "linear_regression_model.fit(X = x_train_s, y = t_train_s)\n",
    "score_train = linear_regression_model.score(X = x_train_s, y = t_train_s)\n",
    "score_test = linear_regression_model.score(X = x_test_s, y = t_test_s)\n",
    "print(f'訓練データの決定係数={score_train:.3f} / テストデータの決定係数={score_test:.3f}')\n",
    "a = linear_regression_model.coef_\n",
    "b = linear_regression_model.intercept_\n",
    "print(f'回帰係数（定数項以外）: {a}')\n",
    "print(f'定数項: {b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UoWNVxr8Gmp"
   },
   "source": [
    "# リッジ回帰モデルの学習と評価\n",
    "* 多項式回帰モデルの学習を行った結果，過学習が起きていることが確認できた\n",
    "* この問題を改善するためにモデルを変更する\n",
    "* ここでは，リッジ回帰モデルで学習を試みる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KLy6TOUsagXi"
   },
   "source": [
    "## モデルの学習と評価\n",
    "* ここでは，正則化パラメータを5としたときの，リッジ回帰モデルの学習を行う\n",
    "* リッジ回帰モデルの学習は，`sklearn`（scikit-learn）の`linear_model`モジュールにおける`Ridge`クラスを使う\n",
    "* `Ridge`クラスは，線形回帰モデルの学習を行うときに用いるクラス（`LinearRegression`クラス）とは異なるクラス\n",
    "* リッジ回帰モデルの学習の流れ:\n",
    ">* `Ridge`クラスを読み込む（インポートする）\n",
    ">* インポートの書式: `from sklearn.linear_model import Ridge`\n",
    ">* `Ridge`クラスのオブジェクトを生成し，変数に代入する\n",
    ">* オブジェクト生成の書式: `変数 = Ridge(alpha = 正則化パラメータ)`\n",
    ">* モデルを学習する\n",
    ">* モデルの学習の書式（これまでのモデルと同様）: `変数.fit(説明変数データ, 目的変数データ)`\n",
    "* 以下のコードで，モデルの学習と評価（訓練データとテストデータに対する決定係数をそれぞれ計算）を行う\n",
    "* 決定係数の計算は，これまでのモデルと同様に`score`メソッドを用いる\n",
    "* 実行結果の決定係数から，過学習の問題が改善されていることがわかる\n",
    "* ただし，正則化パラメータの値やデータによってモデルの性能（決定係数）が変わってくることに注意する\n",
    "  \n",
    "**［以下のコードの処理内容］**\n",
    "* 1～2行目: ファイルをDataFrameとして読み込み，変数`df`に代入\n",
    "* 3～5行目: 列の削除，欠損値の対処，外れ値の削除\n",
    "* 6～13行目: 説明変数と目的変数に分割し，変数`x`と`t`にそれぞれ代入\n",
    "* 14～15行目:  説明変数と目的変数を訓練データ（70％）と検証データ（30％）に分割し，`x_train`, `x_test`, `t_train`, `t_test`にそれぞれ代入\n",
    "* 16～28行目: データの標準化を行い，その結果を`x_train_s`, `x_test_s`, `t_train_s`, `t_test_s`にそれぞれ代入\n",
    "* 29行目:  `sklearn` (scikit-learn) の`linear_model`モジュール内にある`Ridge`クラスを読み込む \n",
    "* 30行目: `Ridge(alpha = 5)`で，モデルの学習を行うためのオブジェクトを`Ridge`クラスから生成し，変数`ridge_regression_model`に代入\n",
    ">* `alpha = 5`で，正則化パラメータを 5と設定\n",
    "* 31行目: 標準化した訓練データ（`x_train_s`と`t_train_s`）を用いて，`fit`メソッドでモデルの学習を実行\n",
    "* 32行目: `ridge_regression_model.score(X = x_train_s, y = t_train_s)`で，標準化した訓練データに対する決定係数を計算して変数`score_train`に代入\n",
    "* 33行目: `ridge_regression_model.score(X = x_test_s, y = t_test_s)`で，標準化したテストデータに対する決定係数を計算して変数`score_test`に代入\n",
    "* 34行目: `print`関数とf-stringを使って，訓練データに対する決定係数（`score_train`）とテストデータに対する決定係数（`score_test`）を小数点以下3桁まで表示\n",
    "* 35行目: `ridge_regression_model`オブジェクトの`coef_`属性から回帰係数（定数項以外）を取り出し，変数`a`に代入\n",
    "* 36行目: `ridge_regression_model`オブジェクトの`intercept_`属性から定数項を取り出し，変数`b`に代入\n",
    "* 37行目: `print`関数とf-stringを使って，回帰係数`a`を表示\n",
    "* 38行目: `print`関数とf-stringを使って，定数項`b`を表示（標準化しているので 0 になる）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 699,
     "status": "ok",
     "timestamp": 1716690078567,
     "user": {
      "displayName": "Takahiro YOSHIDA",
      "userId": "00096252480874798687"
     },
     "user_tz": -540
    },
    "id": "QzbmNaVZS-IR",
    "outputId": "7f3b3809-a748-4e4d-f7be-f21d1e808c19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データの決定係数=0.756 / テストデータの決定係数=0.835\n",
      "回帰係数（定数項以外）: [ 0.123  0.016 -0.16   0.57  -0.275 -0.418  0.013 -0.023  0.278]\n",
      "定数項: [0.]\n"
     ]
    }
   ],
   "source": [
    "url = 'https://bit.ly/4hwOUgx'\n",
    "df = pd.read_csv(url)\n",
    "df = df.drop(['CRIME'], axis = 1)\n",
    "df = df.fillna(df.mean())\n",
    "df = df.drop([76], axis = 0)\n",
    "x_cols = ['RM', 'PTRATIO', 'LSTAT']\n",
    "t_col = ['PRICE']\n",
    "x = df[x_cols]\n",
    "t = df[t_col]\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pf = PolynomialFeatures(degree = 2, include_bias = False)\n",
    "x = pf.fit_transform(x)\n",
    "x = pd.DataFrame(x, columns = pf.get_feature_names_out())\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size = 0.3, random_state = random_seed)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x = StandardScaler()\n",
    "sc_x.fit(x_train)\n",
    "x_train_s = sc_x.transform(x_train)\n",
    "x_train_s = pd.DataFrame(x_train_s, columns = x_train.columns)\n",
    "x_test_s = sc_x.transform(x_test)\n",
    "x_test_s = pd.DataFrame(x_test_s, columns = x_test.columns)\n",
    "sc_t = StandardScaler()\n",
    "sc_t.fit(t_train)\n",
    "t_train_s = sc_t.transform(t_train)\n",
    "t_train_s = pd.DataFrame(t_train_s, columns = t_train.columns)\n",
    "t_test_s = sc_t.transform(t_test)\n",
    "t_test_s = pd.DataFrame(t_test_s, columns = t_test.columns)\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge_regression_model = Ridge(alpha = 5)\n",
    "ridge_regression_model.fit(X = x_train_s, y = t_train_s)\n",
    "score_train = ridge_regression_model.score(X = x_train_s, y = t_train_s)\n",
    "score_test = ridge_regression_model.score(X = x_test_s, y = t_test_s)\n",
    "print(f'訓練データの決定係数={score_train:.3f} / テストデータの決定係数={score_test:.3f}')\n",
    "a = ridge_regression_model.coef_\n",
    "b = ridge_regression_model.intercept_\n",
    "print(f'回帰係数（定数項以外）: {a}')\n",
    "print(f'定数項: {b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考コード（理解する必要はない）\n",
    "* 以下のコードは，正則化パラメータを0.1から20.0まで0.1刻みで変化させたときの決定係数を求め，決定係数の最大値とそのときの正則化パラメータの値を出力する\n",
    "* また，データを分割する際に使用する乱数の種を変数`seed`で指定している（1行目）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23351,
     "status": "ok",
     "timestamp": 1716539627228,
     "user": {
      "displayName": "Takahiro YOSHIDA",
      "userId": "00096252480874798687"
     },
     "user_tz": -540
    },
    "id": "HzRhAGAnbAgw",
    "outputId": "2805e6d4-029f-4849-9c3b-0b3f1f4533eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最大の決定係数: 0.836\n",
      "そのときの正則化パラメータ: 3.7\n"
     ]
    }
   ],
   "source": [
    "seed = 1 # 乱数の種\n",
    "url = 'https://bit.ly/4hwOUgx'\n",
    "df = pd.read_csv(url)\n",
    "df = df.drop(['CRIME'], axis = 1)\n",
    "df = df.fillna(df.mean())\n",
    "df = df.drop([76], axis = 0)\n",
    "x_cols = ['RM', 'PTRATIO', 'LSTAT']\n",
    "t_col = ['PRICE']\n",
    "x = df[x_cols]\n",
    "t = df[t_col]\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pf = PolynomialFeatures(degree = 2, include_bias = False)\n",
    "x = pf.fit_transform(x)\n",
    "x = pd.DataFrame(x, columns = pf.get_feature_names_out())\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size = 0.3, random_state = seed)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x = StandardScaler()\n",
    "sc_x.fit(x_train)\n",
    "x_train_s = sc_x.transform(x_train)\n",
    "x_train_s = pd.DataFrame(x_train_s, columns = x_train.columns)\n",
    "x_test_s = sc_x.transform(x_test)\n",
    "x_test_s = pd.DataFrame(x_test_s, columns = x_test.columns)\n",
    "sc_t = StandardScaler()\n",
    "sc_t.fit(t_train)\n",
    "t_train_s = sc_t.transform(t_train)\n",
    "t_train_s = pd.DataFrame(t_train_s, columns = t_train.columns)\n",
    "t_test_s = sc_t.transform(t_test)\n",
    "t_test_s = pd.DataFrame(t_test_s, columns = t_test.columns)\n",
    "from sklearn.linear_model import Ridge\n",
    "max_score = 0 # 最大の決定係数を格納する変数\n",
    "max_param = 0 # そのときの正則化パラメータを格納する変数\n",
    "for i in range(1, 201):\n",
    "    param = i/10\n",
    "    ridge_regression_model = Ridge(alpha = param)\n",
    "    ridge_regression_model.fit(X = x_train_s, y = t_train_s)\n",
    "    score = ridge_regression_model.score(X = x_test_s, y = t_test_s)\n",
    "    if score > max_score:\n",
    "        max_score = score\n",
    "        max_param = param\n",
    "print(f'最大の決定係数: {max_score:.3f}')\n",
    "print(f'そのときの正則化パラメータ: {max_param}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrnAElGXai7g"
   },
   "source": [
    "## 回帰係数の大きさの比較\n",
    "* 次に，多項式回帰モデルとリッジ回帰モデルの大きさを比較する\n",
    "* 回帰係数（切片以外）は`coef_`プロパティ，切片は`intercept_`プロパティで確認できる\n",
    "* 以下のコードでは，多項式回帰モデルとリッジ回帰モデル（正則化パラメータは5）の学習をそれぞれ行い，回帰係数の絶対値の合計をそれぞれ計算している\n",
    "* なお，データの標準化により，定数項は 0 となるので，合計の計算には定数項を入れていない\n",
    "  \n",
    "**［以下のコードの処理内容］**\n",
    "* 1～2行目: ファイルをDataFrameとして読み込み，変数`df`に代入\n",
    "* 3～5行目: 列の削除，欠損値の対処，外れ値の削除\n",
    "* 6～13行目: 説明変数と目的変数に分割し，変数`x`と`t`にそれぞれ代入\n",
    "* 14～15行目:  説明変数と目的変数を訓練データ（70％）と検証データ（30％）に分割し，`x_train`, `x_test`, `t_train`, `t_test`にそれぞれ代入\n",
    "* 16～28行目: データの標準化を行い，その結果を`x_train_s`, `x_test_s`, `t_train_s`, `t_test_s`にそれぞれ代入\n",
    "* 29～33行目: 多項式回帰モデルの学習を行い，回帰係数を表示\n",
    "* 34～38行目: リッジ回帰モデルの学習を行い，回帰係数を表示\n",
    "* 39行目: `sum`関数と`abs`関数を使って，多項式回帰モデルの回帰係数の絶対値の合計を計算し，変数`sum_coef_linear`に代入\n",
    ">*  `abs`関数は引数でしていした数値の絶対値を返す\n",
    ">*  `coef_[0]`で，回帰係数のリストを取り出している\n",
    ">*  `sum`関数は引数で指定した複数の数値の合計を返す\n",
    "* 40行目: 同様に `sum`関数と`abs`関数を使って，リッジ回帰モデルの回帰係数の絶対値の合計を計算し，変数`sum_coef_ridge`に代入\n",
    ">*  `coef_`のデータ構造が，`linear_regression_model`と異なるので，回帰係数の指定が`coef_[0]`ではなく，`coef_`となっている\n",
    "* 41行目: `print`関数とf-stringを使って，多項式回帰モデルの回帰係数の絶対値の合計 `sum_coef_linear`を表示\n",
    "* 42行目: `print`関数とf-stringを使って，リッジ回帰モデルの回帰係数の絶対値の合計 `sum_coef_ridge`を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mwucn6H6anaI",
    "outputId": "15b12020-b6f3-4161-d192-18d5ee94e1e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "多項式回帰モデルの回帰係数（定数項以外）: [[-1.08   2.033  1.784  2.269 -0.434 -2.455 -1.831  0.516  0.008]]\n",
      "リッジ回帰モデルの回帰係数（定数項以外）: [ 0.123  0.016 -0.16   0.57  -0.275 -0.418  0.013 -0.023  0.278]\n",
      "多項式回帰モデルの回帰係数の合計: 12.411\n",
      "リッジ回帰モデルの回帰係数の合計: 1.876\n"
     ]
    }
   ],
   "source": [
    "url = 'https://bit.ly/4hwOUgx'\n",
    "df = pd.read_csv(url)\n",
    "df = df.drop(['CRIME'], axis = 1)\n",
    "df = df.fillna(df.mean())\n",
    "df = df.drop([76], axis = 0)\n",
    "x_cols = ['RM', 'PTRATIO', 'LSTAT']\n",
    "t_col = ['PRICE']\n",
    "x = df[x_cols]\n",
    "t = df[t_col]\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pf = PolynomialFeatures(degree = 2, include_bias = False)\n",
    "x = pf.fit_transform(x)\n",
    "x = pd.DataFrame(x, columns = pf.get_feature_names_out())\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size = 0.3, random_state = random_seed)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x = StandardScaler()\n",
    "sc_x.fit(x_train)\n",
    "x_train_s = sc_x.transform(x_train)\n",
    "x_train_s = pd.DataFrame(x_train_s, columns = x_train.columns)\n",
    "x_test_s = sc_x.transform(x_test)\n",
    "x_test_s = pd.DataFrame(x_test_s, columns = x_test.columns)\n",
    "sc_t = StandardScaler()\n",
    "sc_t.fit(t_train)\n",
    "t_train_s = sc_t.transform(t_train)\n",
    "t_train_s = pd.DataFrame(t_train_s, columns = t_train.columns)\n",
    "t_test_s = sc_t.transform(t_test)\n",
    "t_test_s = pd.DataFrame(t_test_s, columns = t_test.columns)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linear_regression_model = LinearRegression()\n",
    "linear_regression_model.fit(X = x_train_s, y = t_train_s)\n",
    "a = linear_regression_model.coef_\n",
    "print(f'多項式回帰モデルの回帰係数（定数項以外）: {a}')\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge_regression_model = Ridge(alpha = 5)\n",
    "ridge_regression_model.fit(X = x_train_s, y = t_train_s)\n",
    "a = ridge_regression_model.coef_\n",
    "print(f'リッジ回帰モデルの回帰係数（定数項以外）: {a}')\n",
    "sum_coef_linear = sum(abs(linear_regression_model.coef_[0]))\n",
    "sum_coef_ridge = sum(abs(ridge_regression_model.coef_))\n",
    "print(f'多項式回帰モデルの回帰係数の合計: {sum_coef_linear:.3f}')\n",
    "print(f'リッジ回帰モデルの回帰係数の合計: {sum_coef_ridge:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BcATIxVuaVvU"
   },
   "source": [
    "# ラッソ回帰モデルの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの学習と評価\n",
    "* ここでは，正則化パラメータを0.05としたときの，ラッソ回帰モデルの学習を行う\n",
    "* ラッソ回帰モデルの学習は，`sklearn`（scikit-learn）の`linear_model`モジュールにおける`Lasso`クラスを使う\n",
    "* 学習の流れは，リッジ回帰モデルと同様\n",
    "* ラッソ回帰モデルの学習の流れ:\n",
    ">* `Lasso`クラスを読み込む（インポートする）\n",
    ">* インポートの書式: `from sklearn.linear_model import Lasso`\n",
    ">* `Lasso`クラスのオブジェクトを生成し，変数に代入する\n",
    ">* オブジェクト生成の書式: `変数 = Lasso(alpha = 正則化パラメータ)`\n",
    ">* モデルを学習する\n",
    ">* モデルの学習の書式（これまでのモデルと同様）: `変数.fit(説明変数データ, 目的変数データ)`\n",
    "* 以下のコードで，モデルの学習と評価（訓練データとテストデータに対する決定係数をそれぞれ計算）を行う\n",
    "* 決定係数の計算は，これまでのモデルと同様に`score`メソッドを用いる\n",
    "* リッジ回帰モデルの学習と同様，正則化パラメータの値やデータによってモデルの性能（決定係数）が変わってくることに注意する\n",
    "* ラッソ回帰モデルの学習では，目的変数に影響を与えない説明変数の係数を0にするという特徴があるが，実行結果から．それが確認できる\n",
    "  \n",
    "**［以下のコードの処理内容］**\n",
    "* 1～2行目: ファイルをDataFrameとして読み込み，変数`df`に代入\n",
    "* 3～5行目: 列の削除，欠損値の対処，外れ値の削除\n",
    "* 6～13行目: 説明変数と目的変数に分割し，変数`x`と`t`にそれぞれ代入\n",
    "* 14～15行目:  説明変数と目的変数を訓練データ（70％）と検証データ（30％）に分割し，`x_train`, `x_test`, `t_train`, `t_test`にそれぞれ代入\n",
    "* 16～28行目: データの標準化を行い，その結果を`x_train_s`, `x_test_s`, `t_train_s`, `t_test_s`にそれぞれ代入\n",
    "* 29行目:  `sklearn` (scikit-learn) の`linear_model`モジュール内にある`Lasso`クラスを読み込む \n",
    "* 30行目: `Lasso(alpha = 0.05)`で，モデルの学習を行うためのオブジェクトを`Lasso`クラスから生成し，変数`lasso_regression_model`に代入\n",
    ">* `alpha = 0.05`で，正則化パラメータを 0.05 と設定\n",
    "* 31行目: 標準化した訓練データ（`x_train_s`と`t_train_s`）を用いて，`fit`メソッドでモデルの学習を実行\n",
    "* 32行目: `lasso_regression_model.score(X = x_train_s, y = t_train_s)`で，標準化した訓練データに対する決定係数を計算して変数`score_train`に代入\n",
    "* 33行目: `lasso_regression_model.score(X = x_test_s, y = t_test_s)`で，標準化したテストデータに対する決定係数を計算して変数`score_test`に代入\n",
    "* 34行目: `print`関数とf-stringを使って，訓練データに対する決定係数（`score_train`）とテストデータに対する決定係数（`score_test`）を小数点以下3桁まで表示\n",
    "* 35行目: `lasso_regression_model`オブジェクトの`coef_`属性から回帰係数（定数項以外）を取り出し，変数`a`に代入\n",
    "* 36行目: `a`をDataFrameに変換し，インデックスと列名を加え見やすくしたものを`display`関数で表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "_jj7iiNpaZde",
    "outputId": "81f22ff2-aa53-4e86-d3c9-e8799e83f998"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データの決定係数=0.731 / テストデータの決定係数=0.836\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>係数</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM^2</th>\n",
       "      <td>0.668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM PTRATIO</th>\n",
       "      <td>-0.218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM LSTAT</th>\n",
       "      <td>-0.310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO^2</th>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO LSTAT</th>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT^2</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  係数\n",
       "RM             0.000\n",
       "PTRATIO       -0.000\n",
       "LSTAT         -0.000\n",
       "RM^2           0.668\n",
       "RM PTRATIO    -0.218\n",
       "RM LSTAT      -0.310\n",
       "PTRATIO^2     -0.000\n",
       "PTRATIO LSTAT -0.000\n",
       "LSTAT^2        0.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'https://bit.ly/4hwOUgx'\n",
    "df = pd.read_csv(url)\n",
    "df = df.drop(['CRIME'], axis = 1)\n",
    "df = df.fillna(df.mean())\n",
    "df = df.drop([76], axis = 0)\n",
    "x_cols = ['RM', 'PTRATIO', 'LSTAT']\n",
    "t_col = ['PRICE']\n",
    "x = df[x_cols]\n",
    "t = df[t_col]\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pf = PolynomialFeatures(degree = 2, include_bias = False)\n",
    "x = pf.fit_transform(x)\n",
    "x = pd.DataFrame(x, columns = pf.get_feature_names_out())\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size = 0.3, random_state = random_seed)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x = StandardScaler()\n",
    "sc_x.fit(x_train)\n",
    "x_train_s = sc_x.transform(x_train)\n",
    "x_train_s = pd.DataFrame(x_train_s, columns = x_train.columns)\n",
    "x_test_s = sc_x.transform(x_test)\n",
    "x_test_s = pd.DataFrame(x_test_s, columns = x_test.columns)\n",
    "sc_t = StandardScaler()\n",
    "sc_t.fit(t_train)\n",
    "t_train_s = sc_t.transform(t_train)\n",
    "t_train_s = pd.DataFrame(t_train_s, columns = t_train.columns)\n",
    "t_test_s = sc_t.transform(t_test)\n",
    "t_test_s = pd.DataFrame(t_test_s, columns = t_test.columns)\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso_regression_model = Lasso(alpha = 0.05)\n",
    "lasso_regression_model.fit(X = x_train_s, y = t_train_s)\n",
    "score_train = lasso_regression_model.score(X = x_train_s, y = t_train_s)\n",
    "score_test = lasso_regression_model.score(X = x_test_s, y = t_test_s)\n",
    "print(f'訓練データの決定係数={score_train:.3f} / テストデータの決定係数={score_test:.3f}')\n",
    "a = lasso_regression_model.coef_\n",
    "display(pd.DataFrame(a, index = pf.get_feature_names_out(), columns = ['係数']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3bAbydDUc-E_"
   },
   "source": [
    "# 回帰木モデルの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの前処理\n",
    "* ここでは，回帰木モデルの学習を行う\n",
    "* 説明変数は，目的変数である`PRICE`を除くすべての特徴量とする\n",
    "* また，回帰木モデルは，データのスケールや外れ値の影響を受けない（受けにくい）ので，データの標準化と外れ値の対処は行わず学習する\n",
    "* この特徴は分類木モデルも同様\n",
    "\n",
    "  \n",
    "**［以下のコードの処理内容］**\n",
    "* 1～2行目: ファイルをDataFrameとして読み込み，変数`df`に代入\n",
    "* 3～4行目: 列の削除，欠損値の対処\n",
    "* 5～7行目: 説明変数と目的変数に分割し，変数`x`と`t`にそれぞれ代入\n",
    ">* `df.drop(['PRICE'], axis = 1)`で，`PRICE`列を削除したDataFrame（これが説明変数となる）を変数`x`に代入している\n",
    "* 8～9行目: 説明変数と目的変数を訓練データ（70％）と検証データ（30％）に分割し，`x_train`, `x_test`, `t_train`, `t_test`にそれぞれ代入\n",
    "* 10～17行目: `x_train`, `x_test`, `t_train`, `t_test`をそれぞれ表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ x_train ================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.000</td>\n",
       "      <td>5.190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.515</td>\n",
       "      <td>6.310</td>\n",
       "      <td>38.500</td>\n",
       "      <td>6.458</td>\n",
       "      <td>5.000</td>\n",
       "      <td>224</td>\n",
       "      <td>20.200</td>\n",
       "      <td>6.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.693</td>\n",
       "      <td>5.453</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.490</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>30.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.000</td>\n",
       "      <td>9.900</td>\n",
       "      <td>0</td>\n",
       "      <td>0.544</td>\n",
       "      <td>6.382</td>\n",
       "      <td>67.200</td>\n",
       "      <td>3.533</td>\n",
       "      <td>4.000</td>\n",
       "      <td>304</td>\n",
       "      <td>18.400</td>\n",
       "      <td>10.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.740</td>\n",
       "      <td>6.219</td>\n",
       "      <td>100.000</td>\n",
       "      <td>2.005</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>16.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.659</td>\n",
       "      <td>4.138</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.178</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>23.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.000</td>\n",
       "      <td>3.240</td>\n",
       "      <td>0</td>\n",
       "      <td>0.460</td>\n",
       "      <td>6.333</td>\n",
       "      <td>17.200</td>\n",
       "      <td>5.215</td>\n",
       "      <td>4.000</td>\n",
       "      <td>430</td>\n",
       "      <td>16.900</td>\n",
       "      <td>7.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.583</td>\n",
       "      <td>5.905</td>\n",
       "      <td>53.200</td>\n",
       "      <td>3.152</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>11.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.000</td>\n",
       "      <td>11.930</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.700</td>\n",
       "      <td>2.288</td>\n",
       "      <td>1.000</td>\n",
       "      <td>273</td>\n",
       "      <td>21.000</td>\n",
       "      <td>9.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.500</td>\n",
       "      <td>7.870</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.009</td>\n",
       "      <td>82.900</td>\n",
       "      <td>6.227</td>\n",
       "      <td>5.000</td>\n",
       "      <td>311</td>\n",
       "      <td>15.200</td>\n",
       "      <td>13.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.000</td>\n",
       "      <td>2.460</td>\n",
       "      <td>0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>6.153</td>\n",
       "      <td>68.800</td>\n",
       "      <td>3.280</td>\n",
       "      <td>3.000</td>\n",
       "      <td>193</td>\n",
       "      <td>17.800</td>\n",
       "      <td>13.150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ZN  INDUS  CHAS   NOX    RM     AGE   DIS    RAD  TAX  PTRATIO  LSTAT\n",
       "67  0.000  5.190     0 0.515 6.310  38.500 6.458  5.000  224   20.200  6.750\n",
       "99  0.000 18.100     0 0.693 5.453 100.000 1.490 24.000  666   20.200 30.590\n",
       "54  0.000  9.900     0 0.544 6.382  67.200 3.533  4.000  304   18.400 10.360\n",
       "95  0.000 18.100     0 0.740 6.219 100.000 2.005 24.000  666   20.200 16.590\n",
       "88  0.000 18.100     0 0.659 4.138 100.000 1.178 24.000  666   20.200 23.340\n",
       "..    ...    ...   ...   ...   ...     ...   ...    ...  ...      ...    ...\n",
       "75  0.000  3.240     0 0.460 6.333  17.200 5.215  4.000  430   16.900  7.340\n",
       "9   0.000 18.100     0 0.583 5.905  53.200 3.152 24.000  666   20.200 11.450\n",
       "72  0.000 11.930     0 0.573 6.120  76.700 2.288  1.000  273   21.000  9.080\n",
       "12 12.500  7.870     0 0.524 6.009  82.900 6.227  5.000  311   15.200 13.270\n",
       "37  0.000  2.460     0 0.488 6.153  68.800 3.280  3.000  193   17.800 13.150\n",
       "\n",
       "[70 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ t_train ================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>20.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>23.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>18.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>11.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>22.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>20.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>29.600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PRICE\n",
       "67 20.700\n",
       "99  5.000\n",
       "54 23.100\n",
       "95 18.400\n",
       "88 11.900\n",
       "..    ...\n",
       "75 22.600\n",
       "9  20.600\n",
       "72 20.600\n",
       "12 18.900\n",
       "37 29.600\n",
       "\n",
       "[70 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ x_test ================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>52.500</td>\n",
       "      <td>5.320</td>\n",
       "      <td>0</td>\n",
       "      <td>0.405</td>\n",
       "      <td>6.209</td>\n",
       "      <td>31.300</td>\n",
       "      <td>7.317</td>\n",
       "      <td>6.000</td>\n",
       "      <td>293</td>\n",
       "      <td>16.600</td>\n",
       "      <td>7.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.532</td>\n",
       "      <td>6.242</td>\n",
       "      <td>64.700</td>\n",
       "      <td>3.424</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>10.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.718</td>\n",
       "      <td>6.545</td>\n",
       "      <td>82.900</td>\n",
       "      <td>1.905</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>5.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.655</td>\n",
       "      <td>6.209</td>\n",
       "      <td>65.400</td>\n",
       "      <td>2.963</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>13.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.000</td>\n",
       "      <td>19.580</td>\n",
       "      <td>0</td>\n",
       "      <td>0.871</td>\n",
       "      <td>5.186</td>\n",
       "      <td>93.800</td>\n",
       "      <td>1.530</td>\n",
       "      <td>5.000</td>\n",
       "      <td>403</td>\n",
       "      <td>14.700</td>\n",
       "      <td>28.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000</td>\n",
       "      <td>6.200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.504</td>\n",
       "      <td>7.163</td>\n",
       "      <td>79.900</td>\n",
       "      <td>3.216</td>\n",
       "      <td>8.000</td>\n",
       "      <td>307</td>\n",
       "      <td>17.400</td>\n",
       "      <td>6.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.000</td>\n",
       "      <td>8.560</td>\n",
       "      <td>0</td>\n",
       "      <td>0.520</td>\n",
       "      <td>5.851</td>\n",
       "      <td>96.700</td>\n",
       "      <td>2.107</td>\n",
       "      <td>5.000</td>\n",
       "      <td>384</td>\n",
       "      <td>20.900</td>\n",
       "      <td>16.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>25.000</td>\n",
       "      <td>4.860</td>\n",
       "      <td>0</td>\n",
       "      <td>0.426</td>\n",
       "      <td>6.302</td>\n",
       "      <td>32.200</td>\n",
       "      <td>5.401</td>\n",
       "      <td>4.000</td>\n",
       "      <td>281</td>\n",
       "      <td>19.000</td>\n",
       "      <td>6.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.000</td>\n",
       "      <td>19.580</td>\n",
       "      <td>0</td>\n",
       "      <td>0.605</td>\n",
       "      <td>5.875</td>\n",
       "      <td>94.600</td>\n",
       "      <td>2.426</td>\n",
       "      <td>5.000</td>\n",
       "      <td>403</td>\n",
       "      <td>14.700</td>\n",
       "      <td>14.430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.584</td>\n",
       "      <td>5.427</td>\n",
       "      <td>95.400</td>\n",
       "      <td>2.430</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>18.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.000</td>\n",
       "      <td>6.200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.507</td>\n",
       "      <td>8.247</td>\n",
       "      <td>70.400</td>\n",
       "      <td>3.652</td>\n",
       "      <td>8.000</td>\n",
       "      <td>307</td>\n",
       "      <td>17.400</td>\n",
       "      <td>3.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.000</td>\n",
       "      <td>6.910</td>\n",
       "      <td>0</td>\n",
       "      <td>0.448</td>\n",
       "      <td>5.602</td>\n",
       "      <td>62.000</td>\n",
       "      <td>6.088</td>\n",
       "      <td>3.000</td>\n",
       "      <td>233</td>\n",
       "      <td>17.900</td>\n",
       "      <td>16.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.693</td>\n",
       "      <td>6.404</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.639</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>20.310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.000</td>\n",
       "      <td>4.050</td>\n",
       "      <td>0</td>\n",
       "      <td>0.510</td>\n",
       "      <td>6.416</td>\n",
       "      <td>84.100</td>\n",
       "      <td>2.646</td>\n",
       "      <td>5.000</td>\n",
       "      <td>296</td>\n",
       "      <td>16.600</td>\n",
       "      <td>9.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.000</td>\n",
       "      <td>8.140</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.965</td>\n",
       "      <td>89.200</td>\n",
       "      <td>4.012</td>\n",
       "      <td>4.000</td>\n",
       "      <td>307</td>\n",
       "      <td>21.000</td>\n",
       "      <td>13.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.000</td>\n",
       "      <td>4.050</td>\n",
       "      <td>0</td>\n",
       "      <td>0.510</td>\n",
       "      <td>6.546</td>\n",
       "      <td>33.100</td>\n",
       "      <td>3.132</td>\n",
       "      <td>5.000</td>\n",
       "      <td>296</td>\n",
       "      <td>16.600</td>\n",
       "      <td>5.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>12.500</td>\n",
       "      <td>6.070</td>\n",
       "      <td>0</td>\n",
       "      <td>0.409</td>\n",
       "      <td>5.594</td>\n",
       "      <td>36.800</td>\n",
       "      <td>6.498</td>\n",
       "      <td>4.000</td>\n",
       "      <td>345</td>\n",
       "      <td>18.900</td>\n",
       "      <td>13.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.000</td>\n",
       "      <td>5.960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.499</td>\n",
       "      <td>5.850</td>\n",
       "      <td>41.500</td>\n",
       "      <td>3.934</td>\n",
       "      <td>5.000</td>\n",
       "      <td>279</td>\n",
       "      <td>19.200</td>\n",
       "      <td>8.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.000</td>\n",
       "      <td>5.960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.499</td>\n",
       "      <td>5.841</td>\n",
       "      <td>61.400</td>\n",
       "      <td>3.378</td>\n",
       "      <td>5.000</td>\n",
       "      <td>279</td>\n",
       "      <td>19.200</td>\n",
       "      <td>11.410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000</td>\n",
       "      <td>5.960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.499</td>\n",
       "      <td>5.966</td>\n",
       "      <td>30.200</td>\n",
       "      <td>3.847</td>\n",
       "      <td>5.000</td>\n",
       "      <td>279</td>\n",
       "      <td>19.200</td>\n",
       "      <td>10.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82.500</td>\n",
       "      <td>2.030</td>\n",
       "      <td>0</td>\n",
       "      <td>0.415</td>\n",
       "      <td>6.162</td>\n",
       "      <td>38.400</td>\n",
       "      <td>6.270</td>\n",
       "      <td>2.000</td>\n",
       "      <td>348</td>\n",
       "      <td>14.700</td>\n",
       "      <td>7.430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>55.000</td>\n",
       "      <td>3.780</td>\n",
       "      <td>0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>6.874</td>\n",
       "      <td>28.100</td>\n",
       "      <td>6.465</td>\n",
       "      <td>5.000</td>\n",
       "      <td>370</td>\n",
       "      <td>17.600</td>\n",
       "      <td>4.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.671</td>\n",
       "      <td>6.380</td>\n",
       "      <td>96.200</td>\n",
       "      <td>1.386</td>\n",
       "      <td>24.000</td>\n",
       "      <td>666</td>\n",
       "      <td>20.200</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>22.000</td>\n",
       "      <td>5.860</td>\n",
       "      <td>0</td>\n",
       "      <td>0.431</td>\n",
       "      <td>6.957</td>\n",
       "      <td>6.800</td>\n",
       "      <td>8.907</td>\n",
       "      <td>7.000</td>\n",
       "      <td>330</td>\n",
       "      <td>19.100</td>\n",
       "      <td>3.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000</td>\n",
       "      <td>8.140</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.072</td>\n",
       "      <td>100.000</td>\n",
       "      <td>4.175</td>\n",
       "      <td>4.000</td>\n",
       "      <td>307</td>\n",
       "      <td>21.000</td>\n",
       "      <td>13.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.000</td>\n",
       "      <td>2.460</td>\n",
       "      <td>0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>7.765</td>\n",
       "      <td>83.300</td>\n",
       "      <td>2.741</td>\n",
       "      <td>3.000</td>\n",
       "      <td>193</td>\n",
       "      <td>17.800</td>\n",
       "      <td>7.560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.000</td>\n",
       "      <td>4.490</td>\n",
       "      <td>0</td>\n",
       "      <td>0.449</td>\n",
       "      <td>6.389</td>\n",
       "      <td>48.000</td>\n",
       "      <td>4.779</td>\n",
       "      <td>3.000</td>\n",
       "      <td>247</td>\n",
       "      <td>18.500</td>\n",
       "      <td>9.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20.000</td>\n",
       "      <td>6.960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464</td>\n",
       "      <td>6.538</td>\n",
       "      <td>58.700</td>\n",
       "      <td>3.917</td>\n",
       "      <td>3.000</td>\n",
       "      <td>223</td>\n",
       "      <td>18.600</td>\n",
       "      <td>7.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.000</td>\n",
       "      <td>25.650</td>\n",
       "      <td>0</td>\n",
       "      <td>0.581</td>\n",
       "      <td>5.613</td>\n",
       "      <td>95.600</td>\n",
       "      <td>1.757</td>\n",
       "      <td>2.000</td>\n",
       "      <td>188</td>\n",
       "      <td>19.100</td>\n",
       "      <td>27.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>80.000</td>\n",
       "      <td>4.950</td>\n",
       "      <td>0</td>\n",
       "      <td>0.411</td>\n",
       "      <td>6.630</td>\n",
       "      <td>23.400</td>\n",
       "      <td>5.117</td>\n",
       "      <td>4.000</td>\n",
       "      <td>245</td>\n",
       "      <td>19.200</td>\n",
       "      <td>4.700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ZN  INDUS  CHAS   NOX    RM     AGE   DIS    RAD  TAX  PTRATIO  LSTAT\n",
       "80 52.500  5.320     0 0.405 6.209  31.300 7.317  6.000  293   16.600  7.140\n",
       "84  0.000 18.100     0 0.532 6.242  64.700 3.424 24.000  666   20.200 10.740\n",
       "33  0.000 18.100     1 0.718 6.545  82.900 1.905 24.000  666   20.200  5.290\n",
       "81  0.000 18.100     0 0.655 6.209  65.400 2.963 24.000  666   20.200 13.220\n",
       "93  0.000 19.580     0 0.871 5.186  93.800 1.530  5.000  403   14.700 28.320\n",
       "17  0.000  6.200     0 0.504 7.163  79.900 3.216  8.000  307   17.400  6.360\n",
       "36  0.000  8.560     0 0.520 5.851  96.700 2.107  5.000  384   20.900 16.470\n",
       "82 25.000  4.860     0 0.426 6.302  32.200 5.401  4.000  281   19.000  6.720\n",
       "69  0.000 19.580     0 0.605 5.875  94.600 2.426  5.000  403   14.700 14.430\n",
       "65  0.000 18.100     0 0.584 5.427  95.400 2.430 24.000  666   20.200 18.140\n",
       "92  0.000  6.200     0 0.507 8.247  70.400 3.652  8.000  307   17.400  3.950\n",
       "39  0.000  6.910     0 0.448 5.602  62.000 6.088  3.000  233   17.900 16.200\n",
       "56  0.000 18.100     0 0.693 6.404 100.000 1.639 24.000  666   20.200 20.310\n",
       "52  0.000  4.050     0 0.510 6.416  84.100 2.646  5.000  296   16.600  9.040\n",
       "51  0.000  8.140     0 0.538 5.965  89.200 4.012  4.000  307   21.000 13.830\n",
       "32  0.000  4.050     0 0.510 6.546  33.100 3.132  5.000  296   16.600  5.330\n",
       "31 12.500  6.070     0 0.409 5.594  36.800 6.498  4.000  345   18.900 13.090\n",
       "44  0.000  5.960     0 0.499 5.850  41.500 3.934  5.000  279   19.200  8.770\n",
       "78  0.000  5.960     0 0.499 5.841  61.400 3.378  5.000  279   19.200 11.410\n",
       "10  0.000  5.960     0 0.499 5.966  30.200 3.847  5.000  279   19.200 10.130\n",
       "2  82.500  2.030     0 0.415 6.162  38.400 6.270  2.000  348   14.700  7.430\n",
       "73 55.000  3.780     0 0.484 6.874  28.100 6.465  5.000  370   17.600  4.610\n",
       "97  0.000 18.100     0 0.671 6.380  96.200 1.386 24.000  666   20.200 23.690\n",
       "62 22.000  5.860     0 0.431 6.957   6.800 8.907  7.000  330   19.100  3.530\n",
       "19  0.000  8.140     0 0.538 6.072 100.000 4.175  4.000  307   21.000 13.040\n",
       "35  0.000  2.460     0 0.488 7.765  83.300 2.741  3.000  193   17.800  7.560\n",
       "94  0.000  4.490     0 0.449 6.389  48.000 4.779  3.000  247   18.500  9.620\n",
       "27 20.000  6.960     0 0.464 6.538  58.700 3.917  3.000  223   18.600  7.730\n",
       "46  0.000 25.650     0 0.581 5.613  95.600 1.757  2.000  188   19.100 27.260\n",
       "38 80.000  4.950     0 0.411 6.630  23.400 5.117  4.000  245   19.200  4.700"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ t_test ================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>23.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>23.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>21.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>21.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>17.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>31.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>19.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>24.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>17.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>13.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>48.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>19.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>12.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>23.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>19.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>29.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>17.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>21.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>20.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>31.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>13.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>29.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>14.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>39.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>23.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>24.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>15.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>27.900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PRICE\n",
       "80 23.200\n",
       "84 23.000\n",
       "33 21.900\n",
       "81 21.400\n",
       "93 17.800\n",
       "17 31.600\n",
       "36 19.500\n",
       "82 24.800\n",
       "69 17.400\n",
       "65 13.800\n",
       "92 48.300\n",
       "39 19.400\n",
       "56 12.100\n",
       "52 23.600\n",
       "51 19.600\n",
       "32 29.400\n",
       "31 17.400\n",
       "44 21.000\n",
       "78 20.000\n",
       "10 24.700\n",
       "2  24.100\n",
       "73 31.200\n",
       "97 13.100\n",
       "62 29.600\n",
       "19 14.500\n",
       "35 39.800\n",
       "94 23.900\n",
       "27 24.400\n",
       "46 15.700\n",
       "38 27.900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'https://bit.ly/4hwOUgx'\n",
    "df = pd.read_csv(url)\n",
    "df = df.drop(['CRIME'], axis = 1)\n",
    "df = df.fillna(df.mean())\n",
    "t_col = ['PRICE']\n",
    "x = df.drop(['PRICE'], axis = 1)\n",
    "t = df[t_col]\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size = 0.3, random_state = random_seed)\n",
    "print('================ x_train ================')\n",
    "display(x_train)\n",
    "print('================ t_train ================')\n",
    "display(pd.DataFrame(t_train))\n",
    "print('================ x_test ================')\n",
    "display(x_test)\n",
    "print('================ t_test ================')\n",
    "display(pd.DataFrame(t_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの学習と評価\n",
    "* 回帰木モデルの学習は，`sklearn`（scikit-learn）の`tree`モジュールにおける`DecisionTreeRegressor`クラスを使う\n",
    "* 回帰木モデルの学習の流れ:\n",
    ">* `DecisionTreeRegressor`クラスを読み込む（インポートする）\n",
    ">* インポートの書式: `from sklearn.tree import DecisionTreeRegressor`\n",
    ">* `DecisionTreeRegressor`クラスのオブジェクトを生成（引数は分類木と同様）し，変数に代入する\n",
    ">* オブジェクト生成の書式: `変数 = DecisionTreeRegressor(max_depth = [最大深さ], random_state = [乱数の種])`\n",
    ">* モデルを学習する\n",
    ">* モデルの学習の書式（これまでのモデルと同様）: `変数.fit(説明変数データ, 目的変数データ)`\n",
    "* 以下のコードで，木の最大深さを4とした回帰木モデルの学習と評価（決定係数と特徴量重要度を計算）を行う\n",
    "* 内容は第5回「[サンプルノートブック05](https://colab.research.google.com/github/yoshida-nu/lec_datascience/blob/main/doc/datascience_notebook05.ipynb)」の一連の分析と同様（ただし，ここでは予測を省いている）\n",
    "* さらに，`tree`モジュールの`plot_tree`関数で回帰木モデルを描画する（分類木モデルと同様）\n",
    ">* 詳細は第3回「サンプルノートブック03」を参照\n",
    "* 学習と評価を行った結果，良いモデルはできなかったので，さらなるチューニングが必要であるが，今回はここまでとする\n",
    "  \n",
    "**［以下のコードの処理内容］**\n",
    "* 1～2行目: ファイルをDataFrameとして読み込み，変数`df`に代入\n",
    "* 3～4行目: 列の削除，欠損値の対処\n",
    "* 5～7行目: 説明変数と目的変数に分割し，変数`x`と`t`にそれぞれ代入\n",
    "* 8～9行目: 説明変数と目的変数を訓練データ（70％）と検証データ（30％）に分割し，`x_train`, `x_test`, `t_train`, `t_test`にそれぞれ代入\n",
    "* 10行目: `sklearn` (scikit-learn) の`tree`モジュールを読み込む \n",
    "* 11行目: `tree.DecisionTreeClassifier`で，分類木モデルの学習を行うためのオブジェクトを`tree`モジュールの`DecisionTreeClassifier`クラスから生成し，変数`model_tree`に代入\n",
    "* 12行目: 訓練データ（`x_train`と`t_train`）を用いて，`fit`メソッドでモデルの学習を実行\n",
    "* 13行目: `model_tree.score(X = x_train, y = t_train)`で，訓練データに対する決定係数を計算して変数`score_train`に代入\n",
    "* 14行目: `model_tree.score(X = x_test, y = t_test)`で，テストデータに対する決定係数を計算して変数`score_test`に代入\n",
    "* 15行目: `print`関数とf-stringを使って，訓練データに対する決定係数（`score_train`）とテストデータに対する決定係数（`score_test`）を小数点以下3桁まで表示\n",
    "* 16行目: `display`関数で，`model_tree`オブジェクトの`feature_importances_`属性（特徴量重要度）を表示\n",
    "* 17行目: `pyplot`モジュールの`figure`関数を使って，図のサイズ（高さと幅）を指定\n",
    "* 18行目: `plot_tree`関数で回帰木を描画\n",
    "* 19行目: `show`関数で，それまでに設定した図（回帰木モデル）を実行画面に表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 940,
     "status": "ok",
     "timestamp": 1716691452095,
     "user": {
      "displayName": "Takahiro YOSHIDA",
      "userId": "00096252480874798687"
     },
     "user_tz": -540
    },
    "id": "laB5VCRCdFgU",
    "outputId": "6ca72640-00cc-44b1-f558-eca48c69d90f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データの決定係数=0.904 / テストデータの決定係数=0.293\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>特徴量重要度</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>0.851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         特徴量重要度\n",
       "ZN        0.000\n",
       "INDUS     0.000\n",
       "CHAS      0.000\n",
       "NOX       0.000\n",
       "RM        0.054\n",
       "AGE       0.006\n",
       "DIS       0.073\n",
       "RAD       0.000\n",
       "TAX       0.017\n",
       "PTRATIO   0.000\n",
       "LSTAT     0.851"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7YAAAD7CAYAAABe1Ai3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAACOBklEQVR4nOzdd1xW5f/48ReIAxQnjtQcKe4NyIYbcI/SzJEj98wUc6Rgao40V2pqrpIcpdUny5HroyAqggaJmjg/oqEiy4UoCFy/P/h5vt0higrc3PJ+Ph48Ht5nvs95e93XfZ3rnHOZKKUUQgghhBBCCCGEkTI1dABCCCGEEEIIIcSrkIatEEIIIYQQQgijJg1bIYQQQgghhBBGTRq2QgghhBBCCCGMmjRshRBCCCGEEEIYNWnYCiGEEEIIIYQwatKwFUIIIYQQQghh1KRhK4QQQgghhBDCqEnDVgghhBBCCCGEUZOGrRBCCCGEEEIIoyYNWyGEEEIIIYQQRk0atkIIIYQQQgghjJo0bIUQQgghhBBCGDVp2AohhBBCCCGEMGpmhg5ACCFEwXXt2jXi4uIMHYbIIVZWVlSrVs3QYQghhCiApGErhBDCIK5du0b9+vVJSkoydCgih1hYWBARESGNWyGEEHlOGrZCCCEMIi4ujqSkJDZt2kT9+vUNHY54RREREfTt25e4uDhp2AohhMhz0rAVQghhUPXr16dFixaGDkMIIYQQRkxeHiWEEOK1FhkZSbt27fSm3blzh44dO+Lq6oqTkxMnT57E29sbnU5HvXr1eOutt9DpdLzzzjvaOl26dGHr1q0AnDx5Ep1Oh06nw8LCQvv3tm3bcizuAQMG4OLiom07NjZWb35wcDCurq7Y29vTpUsXEhMTATh+/DhDhgzBysoqx2IRQggh8jvpsRVCCFHgbNiwAU9PT8aPH8+lS5c4deoUS5YsAcDPz4/o6GgmT56sLR8TE0PRokXZsmULPXv2pFmzZgQEBABQr1497d/PEhISQkJCAu3bt89WjLdu3SIwMBBT06dfg963bx/btm3DysoKX19fvv/+e4YNG0axYsWYNm0aR44cydZ+hBBCiNeB9NgKIYQocOrUqcPBgweJjo6mdu3avPvuu89cftOmTfTq1QsTExNu3LjxQvs6evQoH330EX/99RetWrXi+vXrWi/sk7+nNXbv3r1L3759cXNz46uvvso0f9q0aVhZWZGamsr169dp3LgxAE2aNJFnXIUQQhQ40mMrhBCiwGnXrh2mpqYMGDCA6tWrM3/+fEqVKpXl8tu3b2fv3r2kpaWxceNGPvnkk+fuIzw8HD8/P+zt7Vm6dKnW81qlSpVs9fA2b96cGTNmULp0abp27YqNjQ1OTk56y3z99dfMnj2bHj16YGdn99xtCiGEEK8r6bEVQghRILVp04Y9e/bQpk0bBg8enOVyoaGhREVF0b9/f7Zs2cKWLVuytf2iRYtiYmLCvXv3ePz4sTY9uz22K1asoHz58hQuXJgOHToQGhqaaZmRI0dy9epVAJYtW5atuIQQQojXkTRshRBCFDg7d+7kxIkTQEbPaExMTJbL+vn58e2337JlyxZ+/vlnmjdvTkhIyHP3Ua9ePRYvXoyDgwMTJ05k6dKlPHjwQOux/eff7t279dZNTk5m5syZpKWloZTi4MGD2q3GAOnp6cyZM4eUlBTMzMyoX78+d+/efcmzIYQQQhg/uRVZCCHEa+/48ePodDog41bg6dOnM3LkSBITE0lLS3vqM6wAKSkpHDx4kKVLl2rTevbsqd1inB1NmjRh2bJlnD59mqNHj9KmTZvnrlO0aFEsLS2xtbXFwsKC1q1bo9PpOHnyJH5+fixZsoRq1arh5ORE8eLFsbS05LvvvstWPEIIIcTryEQppQwdhBBCiIInLCwMGxsbQkNDZRzb14DkUwghhCHJrchCCCGEEEIIIYyaNGyFEEIIIYQQQhg1adgKIYQQ/19cXJz2LG5+tX//ft5//32aNGmiN3379u3Y29vTokULvv7660zrvf3228yYMSPL7f7nP/+hZs2a2ue1a9fi6OhIs2bN8PX1BeD06dN6b3OuVKkS27Zty5kDE0IIIV6BvDxKCCGEMCKlSpViyZIluLu7a9Pu3r3LlClTCAoKwtzcHDc3Nzp06ED16tUB+P777zE3N89ym7dv32bjxo1Uq1YNyHhp1uXLlzl69CgmJia4ublx4cIFGjdurI3Bm5iYSKdOnXj77bdz72CFEEKIbJIeWyGEEPlCeHg4dnZ2uLu7s2vXLgA2btyIjY0N7du3Z9CgQQQEBBAZGUm7du209Ro1agTAzZs38fLywsHBgTFjxgAQEBDAqFGjeOeddwgLC8Pf3x8HBwccHR3ZuHEjALGxsXh5edG2bVsWLlz4zBi3bt2Kvb09jo6O7Nu3D4AZM2YwZ84c2rRpQ2pqKo6OjowdO5b169dz48YNOnTogE6no3PnztqwQjqdjq+//pqxY8dq205LS8s0vq1Op8s0jE/Lli2pWLGi3rSgoCA8PT0pVaoURYoUoVevXlp8sbGxrF+/nmHDhmV5XOPHj8fHxwcTExMAihQpwrx58zA1NeXOnTuYmZnxxhtv6K3z5ZdfMnr0aAoVKvTMcyaEEELkBemxFUIIkS8EBgYyZMgQBg8eTHx8PPHx8SxatIhjx45RqFAhPDw8nrn+3bt3+eKLL7C1taVVq1bExcUBcPjwYY4dO0bx4sWpV68eR44coWzZsrRq1Yq3336buXPnMnDgQPr27cuePXsIDg5+6vZv377NrFmzOHHiBOnp6bRq1UobuufSpUtaQ/L8+fOsXLmS5s2b06dPH8aMGUO7du349ddf8fHxYd26dQBYWFjoDSNUqFAhrTf0RSUkJFChQgXtc8WKFYmMjATg448/Zu7cuSQmJj513X379mFpaUnLli0zzRs8eDC7du1i/vz5WFpaatMfPnzIrl27tFuUhRBCCEOThq0QQoh8YdiwYSxatIjhw4czadIk7t69S7NmzbRbaJs3b/7M9RMTE5k2bRpJSUmcO3dOa8i1bNmSEiVKEBsbS0xMDN27dwcyGoORkZGcO3eOjz76CABbW9sst3/p0iXi4+Np3749kNGQjo+PB8DT01NbrkyZMlqsp06donXr1gC0bt2a2bNna8v9cx3I6LH18vLKtN/ffvuNUqVKPfPYK1SoQEhIiPY5NjYWKysrduzYQfny5bG1tX1qozkxMZHZs2fz+++/P3W733zzDffu3aNDhw40bNgQGxsbAH744Qc6d+6Mqanc+CWEECJ/kIatEEKIfCEuLo7x48dz8+ZNxo0bx7p16wgLC+PRo0copQgODua9997D0tKS2NhYIKM39sGDBwDMmjWLyZMn4+rqioeHB0+GaS9cuDAAVlZW1K5dmx07dmBpacnJkyextramQYMG+Pv7U7NmTfbv359lfLVq1cLa2pr9+/dTuHBhgoODKV26tN4+/v3vhg0bEhgYiIeHBwcOHNBum/73cvBqPbbOzs58/PHH3L9/HwsLC3766Sc2bdrEwoULuXTpEl26dCEuLo64uDgqVarEiBEjADh+/Dipqan07dsXgDNnztCjRw8WL17Mzp07GTFiBCVLlqR69ercu3dP25+fnx/r169/qViFEEKI3CANWyGEEPnChQsX6N27N4mJiXh7e1OuXDm8vb1xdHSkevXqVK1aFYBy5cpha2uLk5MTTk5O2i24ffv25cMPP6R+/fo0bNiQqKgove2bmJiwYMEC2rVrh6mpKQ0aNGDFihX4+PjQq1cv1q9fr/fs7r+VLVuW0aNH4+bmhpmZGW5ubjg4ODzzmBYtWsTQoUOZOXMmxYsX125DzmkWFhZ89tlnuLu7Y2ZmxoABA6hevTpfffWVtkxAQAABAQGMGDGCPXv2cPLkSSZPnkxQUJC2jE6n48cffyQ9PZ1Lly5ha2tL0aJFsbW11d4WnZCQQHR0NLVq1cqVYxFCCCFehol6cklbCCGEyENhYWHY2NgQGhpKixYtnrv86NGjee+99/JkOJ49e/Ywb948vWnz589/6nOoIsOL5lMIIYTISdJjK4QQQvxLu3btntl7K4QQQoj8RRq2QgghjMLy5csNHYIQQggh8il5naEQQgghhBBCCKMmDVshhBAiB+l0OqKjo3Nl2/v370en02l/pUuX5s8//wTgs88+w97eHltbW70XQgkhhBAFgdyKLIQQQhiJ1q1ba+PiXrt2jdGjR9O8eXMOHjzIn3/+SUhICFFRUXTq1ImTJ08aNlghhBAiD0mPrRBCiAIlPDwcOzs73N3d2bVrFwDLli3Dzs6Oli1bcvr0aSCj59XHxwcbGxtWrlxJt27daNasGQcPHgRgwIAB+Pj4oNPpcHZ25sqVK5n2NXHiRJydnWnVqhWRkZGkp6fTrVs33NzcGDVqlN6yoaGher2xOp2OgQMHZnkcn332GZ9++ikAe/fupV+/fgBUrVqVGjVqcPHixVc/WUIIIYSRkB5bIYQQBUpgYCBDhgxh8ODBxMfHA2BlZUVISAhBQUGsXr1ae1GVu7s7vr6+VKxYkfPnz3Pv3j0++eQTPD09ATA3NycgIIDff/+dqVOnsnnzZm0/e/bs4e+//+bo0aOcOnWKqVOn8tVXXxEXF0dAQAA3btzQi8vGxoaAgIBsHcP169f5+++/sbOzAzLGln0yni9AxYoViYuLw9ra+qXPkxBCCGFMpMdWCCFEgTJs2DDi4+MZPnw4d+7cIT09nbNnz+Lu7s748eNJTEzUlm3atCnFixenRo0aVKlShfLly3Pv3j1t/pPbgj08PDh37pzefk6fPk14eDg6nY4xY8YQExNDmTJl8PHxYdCgQVrP7xMv0mO7evVq+vfvr32uUKECsbGx2ufY2FisrKxe/iQJIYQQRkZ6bIUQQhQocXFxjB8/nps3bzJu3DimTZtGcHAwhw4dIiAggO+++y7b2zpx4gQODg4cPXqUevXq6c1r1KgRbdq0YenSpaSnpxMSEkJaWhr16tXDz88PT09POnfuTJkyZYAX67HdunUrYWFh2uf27duzePFi3n33XaKjo7l69ar01gohhChQpGErhBCiQLlw4QK9e/cmMTERb29v6tevj6mpKW3atKFt27bcvXs329uKiIigffv2PHjwgA0bNujNa9++PYcOHcLZ2RkTExO8vb25f/8+EyZM4ObNm1SqVInSpUu/cPzh4eFUrVqV4sWLa9NcXFzYvXs3tra2FCpUiGXLlr3wdoUQQghjZqKUUoYOQgghRMETFhaGjY0NoaGhtGjRwtDhvLABAwYwYsQIHBwcDB1KvmDs+RRCCGHc5BlbIYQQQgghhBBGTW5FFkIIIV6Cn5+foUMQQgghxP8nPbZCCCEEMGPGDLZs2ZKr+0hOTqZPnz64u7vj5OREaGgoAMHBwbi6umJvb0+XLl303sz8RMOGDbW3Jffp0weA27dv8/bbb+Ps7EynTp24ffu23jpXr17F0tKSyMjIXD0uIYQQwtCkYSuEEELkkTVr1uDo6MihQ4f49ttvmTBhAgD79u1j27ZthISE0LBhQ77//nu99dLS0qhRowYBAQEEBARo4+V+8cUXdOvWjaNHj9K7d28+//xzvfUmTJiAi4tL3hycEEIIYUDSsBVCCJHnEhIS8Pf3z5N9ubi4EBUVBYCvry/btm0jMDCQli1bYmNjozUS/+mfQ/c0atQIgNTUVD744APc3Nzo3Llzpt7ROXPmZBqHduvWrXrLjBo1ihEjRgDw+PFjzM3NAZg2bRpWVlakpqZy/fp1GjdurLfe9evXSUhIoEOHDuh0Om1YoFOnTuHu7g5A165d9c6pn58fDg4OVKxY8YXP2at4kbdKCyGEEDlFGrZCCCFyXXx8PNu2bWPs2LE0bdoUKysrrbcytw0ePFjrAQ0ICKBz5848fPiQXbt2ceTIEZYvX56t7axbt47KlSsTGBjIsGHDWLhwod58X19frUf1yV/Pnj31lilUqBBmZmYEBgYyZswYVqxYoc37+uuvqV69OmXKlMHOzk5vvbS0NDw9Pdm+fTs//vgjH330EQ8ePKBx48bs2LEDgJ9++omHDx8CEB0dzaZNm/D29n6hc5UTPD09adasGWPHjmXbtm3Ex8fneQxCCCEKHnl5lBBCiBwXGxtLYGAgAQEBHDp0iNOnTwNQs2ZNdDod48ePp1y5cnTq1CnXY+nZsydt27bFzc0NNzc3zMzMiIuLo0ePHiilMvW8ZuX06dMEBQURHBxMeno6tWrV0ps/Z84c9u/frzdt5MiRmRq3q1at4o8//mDnzp16Y9GOHDmSoUOHMnHiRJYtW8bHH3+szatZsyZz5swBoEKFCtSvX5///e9/+Pr6MnLkSH766Sfef/99qlSpAsDYsWOZP38+hQoVyv6JyiEzZszg6tWr7NixQxtPt3Hjxuh0Otzd3XFzc6N8+fJ5HpcQQojXmzRshRBCvLKYmBgOHTrEoUOHCAgI4K+//gKgVq1a6HQ6Jk6ciLu7O9WqVdPWCQsLy5PYLCwsaNSoEbNnz2bJkiUATJkyhTNnzpCeno6rq2umdR4/fkx6ejpXrlzh0qVLQMYtybVr12bcuHEkJydrjfUnfH198fX1fWYs+/bt48yZM6xbt06blp6ezty5c5k4cSJFihShfv36XL9+XW+9ixcvEhgYyODBg7l//z4RERHUqFGDuLg4vv76a0qWLImfnx/vvvsuiYmJnD9/npkzZwIZ5/nGjRssX76cOnXqvPD5e1GdO3fWxrG9du2a9n/i999/56uvvgL+70VY7u7uuLu7U6FChVyPSwghxOtNGrZCCCFe2K1bt7QGS0BAABEREQBYW1vj7u7OlClTcHd3p2rVqgaONMPQoUOZMGECtWvXBjJ6cVu3bo2NjQ01atQgJSVFb/mBAwdib29PkyZNaNCgAQBDhgxh+PDhuLm5ATB79uwXjmPNmjVcu3YNnU4HgLm5Obt376ZatWo4OTlRvHhxLC0t+e677wDo1asXS5YsoVq1agQFBbFq1SrMzMyYM2cOlpaWhIaG8v7772uN90WLFlG4cGFOnjyp7XPAgAHMmDGDGjVqvHC8r6patWr069ePfv36ARAVFaX9v9m7d692K3aDBg1wd3fXGrt5/VywEEII42eilFKGDkIIIUT+dvPmTa1BcujQIc6dOwdAnTp19HrentwKmx1hYWHY2NgQGhqq9fAJ4/Uy+bx+/bpeT/+FCxeAjJd3/fP/1RtvvJGboQshhHgNSI+tEEKITJ7X4Jg+fbo0OMQrq1KlCr1796Z3796A/gWUgIAAVq1aBbzaBRQhhBAFgzRshRBC6N0iGhAQoD1X2qBBA7y8vJg1axZubm5UqlTJwJGK19kbb7xBr1696NWrF5DxducnLyELCAhgzZo1wP/d8v6ksZtfbnkXQghhONKwFUKIAuifL/U5dOgQly9fBjJe6tO2bVs+//xz3Nzc5FlHYVCVKlWiR48e9OjRA8h4tjswMFD7v/vkJVxPXlL2pLH75ptvGjJsIYQQBiANWyGEKACuXr2qNWIDAgK4cuUKkDEMS/v27bVbPA0xDMuTF08J45YXeaxYsSLdu3ene/fuQMawUk9umT906BDffPMN8H/DSj1p6FavXj3XYxNCCGFY8vIoIYR4zSiliIyM1Lu1+OrVqwA0bdpU+7Hv6uqKlZWVweK8du0a9evXJykpyWAxiJxlYWFBRESE3rBOeSkuLo7Dhw9r/+9PnToFQI0aNbT/9zqdziBviBZCCJG7pGErhBBGTinFlStXtB/zhw4d4tq1a5iYmNC0aVOt58rV1ZVy5coZOlw9165dIy4uztBhiBxiZWVlsEbt08THx3P48GHtIk94eDhKKapVq6bXo1uzZk1MTEwMHa4QQohXIA1bIYQwMkopLl++rHdrcVRUFCYmJjRv3lyvIVumTBlDhytEvnH79m2tR/fQoUP8+eefKKWoWrWqXkO3Vq1a0tAVQggjIw1bIYTI55RSXLx4Ua8he+PGDUxNTWnRooX2Y9zFxYXSpUsbOlwhjMadO3c4cuSIdrfDn3/+SXp6OlWqVNF767K1tbU0dIUQIp+Thq0QQuQzSikuXLigd2vxzZs3KVSoEC1atNCeE3R2dqZUqVKGDleI18bdu3c5cuSIdgEpNDSU9PR03njjDb0e3Tp16khDVwgh8hlp2AohhIEppTh37pxej+ytW7coVKgQtra22g9qZ2dnSpYsaehwhSgw7t27x9GjR7Wy+ccff5CWlkalSpW0N4nrdDrq1asnDV0hhDAwadgKIUQeU0px9uxZvXFkY2JiMDMzw87OTvux7OTkhKWlpaHDFUL8f/fv3ycoKEi7m+KPP/4gNTWVChUq6N263KBBA2noCiFEHpOGrRBC5LL09HT++usvrSEbGBhIbGwshQsXxs7OTru12NHRkRIlShg6XCFENiUmJhIUFKSV7ePHj5Oamkr58uVxc3PTynaDBg0wNTU1dLhCCPFak4atEELksPT0dM6cOaP1xh46dIj4+HgKFy6Mvb291qvj6OhI8eLFDR2uECKHPHjwgGPHjmllPyQkhMePH1OuXDm9W5cbNWokDV0hhMhh0rAVQohXlJ6ezqlTp/R6ZBMSEihSpAgODg7aj1kHBwcsLCwMHa4QIo8kJSURHBysNXSDg4NJSUmhbNmyWo+uu7s7TZo0kYauEEK8ImnYCiHEC0pLSyM8PFxryB4+fJjbt29TtGhRHBwctNsP7e3tMTc3N3S4Qoh84uHDhwQHB2vfHcHBwSQnJ1OmTBlcXV21744mTZpQqFAhQ4crhBBGRRq2osC4du0acXFxhg5DvAQrKyuqVatmsP2npaVx8uRJ7YUxhw8f5u7duxQrVgxHR0et18Xe3p5ixYoZLE4hhHF59OgRISEhWo/usWPHePToEaVKlcLNzU2726NZs2YGb+hKHWq8DF2HCpFXpGErCoRr165Rv359kpKSDB2KeAkWFhZERETkWcWcmprKn3/+qf3YPHz4MPfu3cPc3BwnJyftx2bLli0pWrRonsQkhHj9JScnc/z4ce27JygoiIcPH1KyZEmtR9fd3Z3mzZtjZmaWZ3FJHWrc8roOFcJQpGErCoSwsDBsbGzYtGkT9evXN3Q44gVERETQt29fQkNDadGiRa7sIzU1ldDQUO32wCNHjnD//n0sLCxwdnbWGrJ2dnYUKVIkV2IQQoh/S05O5sSJE9p3U1BQEElJSVhaWuLi4qLdutyiRYtcbehKHWq88qIOFSK/yLvLfULkA/Xr15cvdsHjx48JDQ3VekWOHDlCYmIixYsXx9nZmSlTpuDu7o6tra00ZIUQBlO0aFFcXFxwcXHB19eXlJQU/vjjD62h+9lnn/HJJ59QokQJXFxctItwNjY2FC5cOMfjkTpUCJGfySv4hMhhkZGRlC1bVrtlrEePHly5ckWb165dOwD+/PNPXFxcsLe3p2vXriQkJORYDDExMXTs2BFXV1ecnJz466+/Mi2zYMEC7O3tcXBw4MMPPyQtLQ2lFOPHj8fR0ZGWLVsyc+ZMIKPX4Msvv6RFixbMmzcvx+LMKykpKQQFBfH555/Ttm1bypQpg6OjI3PmzAFg6tSpHDt2jNu3b7N3716mTJmCk5OTNGqFEPlKkSJFcHJyYsqUKezdu5c7d+5w7NgxfH19AZgzZw6Ojo6UKVOGtm3bMnfuXIKCgkhJSTFw5Bn+WQc+cefOHb366uTJk3h7e6PT6ahXrx5vvfUWOp2Od955R1unS5cubN26FYCTJ09qPdcWFhbav7dt25Zjcf/000907tyZDh06PHX+22+/zYwZMzJN3759O05OTtja2jJ48GBSU1MB2LhxI/b29ri6utKzZ0/tFu8BAwbo9cTHxsbm2DEIURBIj60QuaBly5bs2bMHgNDQULp3787hw4f1lpk1axZLly7FxsaGXbt2cfPmTcqWLfvU7aWkpODn58e7776LlZXVc/cfEBDAlClTcHFxYf/+/cyZM4fvv/9em3/t2jX+85//cOzYMUxNTenevTsHDhygWLFiXLt2jWPHjpGWloaTkxO9evWiVq1aNGnShBEjRuRoA/xVxcfHM3fuXCZMmEClSpW06c+6fc/V1ZVp06blye17QgiRmwoXLoyDgwMODg5MnjyZ1NRUwsLCtBfdzZ07Fx8fHywsLHByctIuuLZs2VLvwl10dDQLFy5kypQplCtXLk+PYcOGDXh6ejJ+/HguXbrEqVOnWLJkCQB+fn5ER0czefJkbfmYmBiKFi3Kli1b6NmzJ82aNSMgIACAevXqaf9+lpCQEBISEmjfvn22YqxUqRKzZs3Si+OJ77//Psu33wcFBXHgwAHMzc3p06cPBw8eRKfTMWvWLMLDwzE3N2fChAls2rSJYcOGcevWLQIDA2XoJyFekvyiEyKX2djY4Onpyf79+2nSpIk2vW7duvzyyy80aNCAjh07PnXd5ORkvv32WyIiIvjggw+wsrLim2++YePGjXrLde3albFjx2qfe/Toof378uXLNGvWTG95S0tLihcvTmpqKmZmZpiZmVG7dm3tarJSirS0NMqVK0elSpUoVKgQXl5e/P333696OnLMxYsX6dixI7dv32bUqFEcPnxY+zF37NgxvReufPbZZwZ54YoQQuQlMzMzWrZsScuWLZk0aZL2IrwnF/nmz5/P1KlTM70Ir3Llynz33Xds376dXbt2YW1tnWcx16lTh6+++oo+ffpQu3Ztateu/czlN23aRK9evdi4cSM3btygcuXK2d7X0aNH2bJlC82bN6dfv35cv36dPn366C1jbm7O7t279aa5uroSGRmZaXuxsbGsX7+eyZMnZ7p4DWh3OD18+JB79+5hbW2NmZkZFStWJCUlBXNzc1JTU2nYsCEAd+/epW/fvkRFRdG9e3c++uijbB+bEEIatkLkiZo1a3LlyhW9hu2cOXNYvXo1rVq1okuXLkyYMAETExNt/tq1a7l48SL9+/dn5MiR2vTBgwczePDg5+7z2LFjDB48mEqVKvHjjz/qzStTpgyjRo3iww8/xMrKCp1Ox1tvvQVkVOA+Pj4kJCQwYsQISpYs+aqHn+P++9//0q1bN4oUKULt2rVp2LCh3hAZs2fPxt3dPV8MkSGEEIZiZmaGnZ0ddnZ2TJgwQW/oskOHDrFo0SKmTZtGsWLFaNasGZcuXcLW1pb//Oc/tGrVKk9ibNeuHaampgwYMIDq1aszf/58SpUqleXy27dvZ+/evaSlpbFx40Y++eST5+4jPDwcPz8/7O3tWbp0qdYjWqVKlWz18Gbl448/Zu7cuSQmJma5zLRp01i9ejXjx4+nZs2aQEaDd+jQodjZ2VGyZEmcnZ0BaN68OTNmzKB06dJ07doVGxsbnJycXjo+IQoauddBiDxw+fJl3njjDb1ppqamjBw5ksOHDxMVFcWKFSv05pcoUYLHjx9z7949venffPON9vzNk7+lS5dm2qejoyNnz57lww8/ZNCgQXrzzp49y65du1i7di1z587l+vXr7N69m/379xMbG8vcuXNZvXo127Zt48yZMzl0FnLGX3/9RevWrbl37x737t0jPT0dHx8fwsLCiI+PZ/v27Xz88cfY2NhIo1YIIf6hUKFC2NjYMH78eLZv3058fDxhYWH4+PiQnp6ufa+2bt36qe9myC1t2rRhz549tGnT5pkXbkNDQ4mKiqJ///5s2bKFLVu2ZGv7RYsWxcTEhHv37vH48WNt+vXr1zPVp9m9PXnHjh2UL18eW1vbZy43c+ZMrl69yokTJ/jll1+Ii4vjiy++YOvWrUycOJHq1auzatUqAFasWEH58uUpXLgwHTp0IDQ0NFuxCCEySI+tELns+PHj/P7778yYMUNvcPvly5fTs2dPypcvT9OmTTPd5vT+++/To0cPvv/+ezZs2MB7772Hl5dXtnpsV61aRceOHXnzzTdp3Lgxd+/e1Zt/5coVHj16pH1OTk7m6tWrpKWl6d2O/PDhQ6KiomjUqNErnoWcY21tzZAhQ4iMjOSvv/7i+PHjhIeHM2TIEGnICiHECyhUqBAVK1Zkzpw5JCcn88Ybb9CgQQNq1qyZZ7cj79y5k4oVK2JnZ0fz5s2feqH2CT8/P7799lvc3NwAGDRoECEhIdjb2z9zH/Xq1WPx4sWcOnWKiRMnUqtWLYYMGfJKPbb79u3j0qVLdOnShbi4OOLi4qhUqRIjRowA4P79+6xcuZJJkyZRrFgxrK2tuXv3Lrdu3SIhIQGlFCYmJqSkpHD16lWSk5P54osv8PX1xdTUlIMHDzJ69OiXik2IgkoatkLkguPHj6PT6UhJSaFy5cps376dEiVK6DVsa9SoQbt27TAzM6NkyZJ6L3d6olChQvTr14/evXuzZcsWYmNjKV++/HP3b2dnx/vvvw+AiYkJX375JZBx+1OzZs1o06YNO3fupEmTJlhYWPDWW28xbdo00tPTGTx4sPYsqqOjI61bt86hs5IzihQpwtq1a4GMxve1a9eIjIykYsWKBo5MCCGMT6VKldi7dy81atSgWrVqeo/E5IYn9SNk3Ao8ffp0Ro4cSWJiImlpaXz11VdPXS8lJYWDBw/qNXx79uyp3WKcHU2aNGHZsmWcPn2ao0eP0qZNm5c+jn/G+eT9DiNGjGDPnj2cPHmSyZMnY2pqiq2tLcWLF6dq1apMnz6dokWL4uXlRZMmTShVqhSlSpXCz8+PokWLYmlpia2tLRYWFrRu3Vo7T0KI7DFRSilDByFEbnsyuLwMUG58JHdCCGFY8j1svCR3oiCRZ2yFEEIIIYQQQhg1adgKIYQQQgghhDBq0rAVwkDi4uLy/fMziYmJDBgwAE9PT9q1a8f//vc/ABYsWICDgwN2dnbs378/03rh4eE4Oztjb2/PuHHjtOl79+7FwcEBd3d32rVrx61bt4CMoY0cHR1p1qwZvr6+eXNwQgghjJYx1KGhoaG4ubnh5uZGz549SU5OBuDWrVt069YNLy8vunbtSnx8vN56t27dokOHDjg4ONC1a1eSkpKAjJdnNWrUSHuD85P6N6v9CFHQSMNWCJGluXPn0qdPHw4ePMh3332HlZUVERER7Nu3j6CgIHbv3s0nn3xCWlqa3nqjR4/mu+++IyQkhAcPHrBr1y4Axo8fz44dOzh06BCdOnVi6dKlpKSkcPnyZY4ePcqff/5JYGAgFy5cMMThCiGEEDlmwoQJbNmyhcDAQGrWrKkNTzRp0iRmz57NgQMHWLZsGcWLF9dbb+LEiQwdOpTg4GDc3NxYvHgxAFevXmXNmjXay6qevNwxq/0IUdBIw1YUSOHh4djZ2eHu7q41ujZu3IiNjQ3t27dn0KBBBAQEEBkZSbt27bT1ngx7c/PmTby8vHBwcGDMmDFAxlsRR40axTvvvENYWBj+/v44ODjg6OjIxo0bAYiNjcXLy4u2bduycOHCZ8a4detW7O3tcXR0ZN++fQDMmDGDOXPm0KZNG1JTU3F0dGTs2LGsX7+eGzdu0KFDB3Q6HZ07dyYmJgYAnU7H119/zdixY7Vtp6WlZRq7T6fTZRoWyN/fn/DwcFxdXfn8888xNzfn9OnTODs7Y2pqipWVFdbW1kREROitFx8fT+3atQHo2rUr/v7+ALz55pvaleTk5GSaNGlCkSJFmDdvHqampty5cwczM7NMY/4KIYTIP6QOzV4dumfPHipXrgzA48ePMTc3Jz09nUuXLrF+/XpcXV3x8/OjWLFieusdO3aMd955B4CBAweye/duIKNhu3btWtzd3fnwww+1Yfueth8hCiQlRAEQGhqqABUaGqqUUmrZsmVq1apV6vHjxyo6OlrFxcWppk2bqqSkJJWcnKycnJyUv7+/unLlimrbtq22nYYNGyqllIqIiFAnTpxQSinl5eWlYmNjlb+/v2rUqJG6f/++Sk9PV3Xq1FExMTEqNTVV6XQ6defOHTVu3Di1ceNGpZRSu3fvVu7u7k+NNyEhQTVs2FAlJSWpxMRE5eDgoJRSavr06WrAgAHacmXKlFFhYWFKKaV69+6tdu/erZRSatu2bWrw4MFKKaXc3d2Vn5/fS523kiVLqt9//10ppdTHH3+sVq1apc6cOaNcXFzUo0ePVFRUlKpWrZoKDg7WW8/JyUmFhYWp9PR0NXToUDVixAillFLnz59XnTp1UqtWrVLDhg1Tqamp2jqDBg1SFStWVN99953etv6dOyGEEHlL6tCXq0OVUio1NVVNnTpVjRw5UqWlpano6GhVokQJdfLkSZWWlqa6d++u9uzZo7dO3bp19T43btxYKaXUggULVEhIiFJKqTlz5qg5c+ZkuZ8npA4VBYmMYysKpGHDhrFo0SKGDx/OpEmTuHv3Ls2aNdOucjZv3vyZ6ycmJjJt2jSSkpI4d+4ciYmJALRs2ZISJUoQGxtLTEwM3bt3ByAhIYHIyEjOnTvHRx99BICtrW2W27906RLx8fG0b98egLt372rP4Hh6emrLlSlTRov11KlT2m1JrVu3Zvbs2dpy/1wHMq42e3l5Zdrvb7/9RqlSpbTPVatW1WLo0qULP/zwA8OHD6d37954eHhQt25dmjdvTtWqVfW2s2bNGry9vQFwc3PD1NSUx48fM2rUKHbt2kXRokU5cOAAvr6+zJs3D4BvvvmGe/fu0aFDBxo2bIiNjU2W50cIIYThSB2avTr0wYMH9OvXjx49etCrVy8ASpUqRZ06dWjatCkAnTt3Jjw8nLZt22rrmZqaopTCxMSEe/fuYWlpCWTccvxEly5d+PTTT7PcjxAFkTRsRYEUFxfH+PHjuXnzJuPGjWPdunWEhYXx6NEjlFIEBwfz3nvvYWlpSWxsLACHDx/mwYMHAMyaNYvJkyfj6uqKh4cH6v8PB124cGEArKysqF27Njt27MDS0pKTJ09ibW1NgwYN8Pf3p2bNmk996dITtWrVwtramv3791O4cGGCg4MpXbq03j7+/e+GDRsSGBiIh4cHBw4c0G75+vdyAIUKFSIgIOC558nW1pbAwEDc3Nw4ePAgjRs35uHDh3h5eTFy5Eji4uIYMGAAVapU0VsvLS2NvXv3YmpqyqBBg5gwYQKPHj3i2rVrpKenA5CSkkJkZCRRUVHs3LmTESNGULJkSapXr869e/eeG5sQQgjDkDo0e3XoyJEjmTBhAk5OTtq0YsWKUa5cOS5cuECdOnU4ePAgPXr00FvPycmJHTt28Pbbb7N582atgb548WL69u1LhQoVOHDgAI0bN85yP0IURNKwFQXShQsX6N27N4mJiXh7e1OuXDm8vb1xdHSkevXqWg9kuXLlsLW1xcnJCScnJypUqABA3759+fDDD6lfvz4NGzYkKipKb/smJiYsWLCAdu3aYWpqSoMGDVixYgU+Pj706tWL9evX6z139G9ly5Zl9OjRuLm5YWZmhpubGw4ODs88pkWLFjF06FBmzpxJ8eLFWbdu3SueJZg/fz5DhgzB19eXatWqMXnyZJKTk5kyZQq3bt3C0tKSJUuWAHDy5En8/PxYsmQJAQEBDBkyhBIlStCzZ08aNGgAwLhx47Czs6NUqVKYmZnxzTffULlyZS5duoStrS1FixbF1tY237/pUgghCjKpQ5/v/v37/Pbbb1y7dk2b1rVrV8aOHcvy5csZOXIkDx8+xNbWlvbt2+vVobNnz6Zv37588cUXVKhQgU2bNgHQtGlTOnbsiLm5OZUrV2bdunXP3I8QBY2JenKZTIjXWFhYGDY2NoSGhtKiRYvnLj969Gjee++9PGlg7dmzR7sd94n58+fTsmXLXN+3MXjR3AkhhMhZUocaL6lDRUEiPbZCGFi7du2eeeVZCCGEEE8ndagQ4glp2ArxFMuXLzd0CEIIIYRRkjpUCGEIMo6tEEZGp9MRHR2da9tfs2YNOp2OkSNH6k2fP38+Tk5O2NnZ8d133+Xa/oUQQojcktt1qJeXlzau7ZM3JycnJ9OvXz9cXFyws7Nj7dq1ubZ/IQoy6bEVQuipXbs2kyZNYvv27dq006dPc+LECYKCgkhOTqZp06b06tWLokWLGjBSIYQQIn8xMzPjwIEDetO2bt1KpUqV2LhxI0lJSTRq1Ii+fftqwyMJIXKG9NgKkcPCw8Oxs7PD3d2dXbt2AbBs2TLs7Oxo2bIlp0+fBjKuGvv4+GBjY8PKlSvp1q0bzZo14+DBgwAMGDAAHx8fdDodzs7OXLlyJdO+Jk6ciLOzM61atSIyMpL09HS6deuGm5sbo0aN0ls2NDRUu4r85G/gwIGZtunp6YmFhYXetMaNG2tvZUxPT8fMzAwTE5NXP1lCCCHEPxhzHZqWlkZ0dDRdu3bFzc2NH3/8EYA333yT5ORkAFJTU6lduzbFihXL2RMnhJAeWyFyWmBgIEOGDGHw4MHagPBWVlaEhIQQFBTE6tWrteeP3N3d8fX1pWLFipw/f5579+7xySefaIPBm5ubExAQwO+//87UqVPZvHmztp89e/bw999/c/ToUU6dOsXUqVP56quviIuLIyAggBs3bujFZWNjk61x97JStGhR/v77b4YOHcrChQspUqTIS29LCCGEeBpjrkOTkpJwd3dn7ty5KKVo1aoV9vb2eHh4sHv3bhYuXEhYWBizZs2Si8NC5ALpsRUihw0bNoz4+HiGDx/OnTt3SE9P5+zZs7i7uzN+/HgSExO1ZZs2bUrx4sWpUaMGVapUoXz58ty7d0+b37p1awA8PDw4d+6c3n5Onz5NeHg4Op2OMWPGEBMTQ5kyZfDx8WHQoEHaVesnsttjm5Xg4GCGDh3KqlWr5A2UQgghcoUx16GWlpYsW7aM4sWLU6JECdzc3Dh16hTr1q2jTp06TJgwgU2bNjFr1ixiY2Nz+tQJUeBJj60QOSwuLo7x48dz8+ZNxo0bx7Rp0wgODubQoUMEBAS80IuXTpw4gYODA0ePHqVevXp68xo1akSbNm1YunQp6enphISEkJaWRr169fDz88PT05POnTtTpkwZ4NV6bKOjo5k2bRrbt2+X26eEEELkGmOuQ2NjY9mwYQPjx4/n8ePHHD16lOHDhxMYGEjt2rWBjNuV79y5Q3x8POXLl3+xkyOEeCZp2AqRwy5cuEDv3r1JTEzE29ub+vXrY2pqSps2bWjbti13797N9rYiIiJo3749Dx48YMOGDXrz2rdvz6FDh3B2dsbExARvb2/u37/PhAkTuHnzJpUqVaJ06dI5ckw///wzkZGRej21q1evpm7dujmyfSGEEAKMuw61srIiJiaGFi1aULRoUQYOHEitWrX4+OOP6d+/P2vXrkUpxbvvvpupoS2EeHUmSill6CCEyG1hYWHY2NgQGhpKixYtDB1OtgwYMIARI0bg4OBg6FAMyhhzJ4QQrxNj/B6WOjSDMeZOiJclz9gKIYQQQgghhDBqciuyEPmUn5+foUMQQgghjJLUoUIUPNJjK4QQQgghhBDCqEnDVggDmzFjBlu2bMmTfV29ehVLS0siIyMBuH37Np06dUKn0+Hh4cH//vc/veWTk5P58ssvadGiBfPmzcuTGIUQQoh/y4u6MioqCh8fH6pWrUpwcLA2PTw8HGdnZ+zt7Rk3blym9TZu3Kg3DFCJEiW04Xx27tyJh4cHnp6ezJkzR1tn3bp1eHh44OHhwbfffpurxyVEQSG3IgtRgEyYMAEXFxft8+zZsxkxYgSdOnViz549zJo1i/Xr12vzzczMaNKkCSNGjCAhIcEQIQshhBB5wsTEhO7du3Pjxg296aNHj+a7776jdu3aDBs2jF27dtGxY0dtfr9+/ejXrx8AISEhrF+/nvLly5OQkMDq1avZv38/ZmZmXLhwAYDz588TGBiIv78/6enpXLlyJe8OUojXmPTYCpFLXFxciIqKAsDX15dt27YRGBhIy5YtsbGxYfPmzZnW+efr/xs1agRAamoqH3zwAW5ubnTu3Jnbt2/rrTNnzpxMg8Zv3bo107b9/PxwcHCgYsWK2rTPP/+cTp06AfD48WPMzc311ilUqBBeXl4UKVLkJc+CEEIIkbX8VFdWqVKF5s2bZ9pffHy8Ng5t165d8ff3z/J4ZsyYwaeffgrA7t27qVu3Lt26dUOn0xEXFwdkDKFnbW1Nu3btaNeuHampqc89T0KI55OGrRC5ZPDgwXz//fcABAQE0LlzZx4+fMiuXbs4cuQIy5cvz9Z21q1bR+XKlQkMDGTYsGEsXLhQb76vry8BAQF6fz179tRbJjo6mk2bNuHt7a03vWjRogD85z//YcWKFcyePfslj1YIIYR4cfmprsxKmTJl+PPPP1FKsW3bNh48ePDU5U6cOEHFihWpUqUKkHFrc3h4OFu3bmXjxo0MGzaM9PR0oqKiuHz5Mr///jtffPEFQ4YMyVYcQohnk1uRhcglPXv2pG3btri5ueHm5oaZmRlxcXH06NEDpVSmq8lZOX36NEFBQQQHB5Oenk6tWrX05s+ZM4f9+/frTRs5cqRehT127Fjmz59PoUKFMm1/6tSppKamsnPnTszM5CtBCCFE3slPdWVW1qxZo10YdnNzw9T06f1CX331FcOHD9c+lypVirfffptixYrx5ptvUrFiReLi4ihVqhQdOnTA1NSU5s2bc+fOnWwdoxDi2eRXrBC5xMLCgkaNGjF79myWLFkCwJQpUzhz5gzp6em4urpmWufx48fa8zaXLl0CMm6zql27NuPGjSM5OZnTp0/rrePr64uvr2+WcSQmJnL+/HlmzpwJZAzWfuPGDZYvX86hQ4coWbIkkyZNyqGjFkIIIbIvv9SVz5KWlsbevXsxNTVl0KBBTJgwIdMyiYmJnDhxgg0bNmjTWrVqxejRoxk1ahR37twhJiaG8uXL06ZNGzZt2kTnzp25ePEipUqVeqm4hBD65FZkIXLR0KFDSUpK0p7N6dmzJ61bt8bHx4caNWqQkpKit/zAgQOxt7fn888/p0GDBgAMGTKE06dP4+bmRuvWrUlKSnqhGEqUKMHJkyf59ddf+fXXX/H09GTNmjXUqVOH1atXs3PnTu15o4EDBwLQq1cvoqOjc+AMCCGEEM+WH+rKZwkICMDBwQFPT0/s7e21ff6zrjxw4ABOTk5669WuXZt3330Xd3d32rVrx6JFizAxMcHT05Nq1arh6upK//79+eqrr3IsViEKMhOllDJ0EELktrCwMGxsbAgNDaVFixaGDke8AMmdEEIYlnwPGy/JnShIpMdWCCGEEEIIIYRRk4atEEIIIYQQQgijJi+PEgVKRESEoUMQL0hyJoQQ+YN8HxsfyZkoSKRhKwoEKysrLCws6Nu3r6FDES/BwsICKysrQ4chhBAFktShxk3qUFFQyMujRIFx7do14uLitM/p6ekEBASwdu1aLly4QIsWLRg+fDi2trYGjLLgUErxxx9/sGbNGsLCwqhTpw7Dhg1Dp9NhYmKit6yVlRXVqlUzUKRCCCGkDs1fpA4VIjNp2IoCJz09nW3btjFz5kxOnTqFh4cH06dPx93d3dChFViHDh3is88+w9/fn6ZNmzJt2jS6dOmCqam8BkAIIfITqUPzH6lDhcgg/+NFgZGens7PP/9Ms2bNeO+99yhfvjyBgYEcPHhQKmQDc3d35+DBgxw6dIhy5crRrVs3mjVrxs8//0x6erqhwxNCiAJP6tD8S+pQITJIw1a89tLT0/nxxx9p2rQp3bt3p2LFihw+fJj//ve/uLq6Gjo88Q9ubm4cOHCAw4cPU7FiRbp3707Tpk356aefpHIWQggDkDrUeEgdKgo6adiK11ZaWhpbtmyhcePG9OzZk8qVK3P06FH279+Pi4uLocMTz+Di4sL+/fs5cuQIb7zxBj169KBJkyZs3bqVtLQ0Q4cnhBCvPalDjdeTOvTo0aNUrlxZ6lBRYEjDVrwWLl68iKenJzExMaSlpfHDDz/QuHFj3n//fapVq0ZQUBB79+7FycnJ0KGKF+Ds7My+ffsICgqiatWq9OrVi8aNG/PDDz+QlpbGrVu38PT05OLFi4YOVQghjJbUoa8nJycn9u7dK3WoKDCkYSuM3sOHD+nevTtRUVHs2rWLRo0a0bt3b2rUqEFwcDC7d+/G0dHR0GGKV+Do6MiePXs4duwYNWrUoHfv3jRq1Ijdu3cTFRVFjx49ePTokaHDFEIIoyN16OtP6lBRUEjDVhi9MWPGcPbsWVJSUhg0aBC1atUiJCSE33//HXt7e0OHJ3KQg4MDv//+OyEhIbz11lsMHDiQlJQU/vrrL8aMGWPo8IQQwuhIHVpwSB0qXndmhg5AiFcxZ84c1q1bB4CZmRl9+/bl7bffpmXLlgaOTOSmli1bMmDAAMqWLUtQUBCPHz9m7dq1VK9eHV9fX0OHJ4QQRkHq0IJJ6lDxupIeW2HUrly5gqWlJdWrV6dQoUIcP34cf39/Q4cl8oC/vz/Hjx/HzMyM6tWrY2lpyZUrVwwdlhBCGA2pQwsuqUPF68hEKaUMHYQQQgghhBBCCPGy5FbkbLp27RpxcXGGDkM8g5WVFdWqVTN0GCKPSJk0XlJWCwYpo8ZLyujrT8qn8ZLymTVp2GbDtWvXqF+/PklJSYYORTyDhYUFERERUtgLACmTxk3K6utPyqhxkzL6epPyadykfGZNGrbZEBcXR1JSEps2baJ+/fqGDkc8RUREBH379iUuLk4KegEgZdJ4SVktGKSMGi8po68/KZ/GS8rns0nD9gXUr1+fFi1a5Pp+vL29eeONN/jkk08ACAkJYerUqTx+/Jjk5GSmTp1Kx44dCQgIoHfv3tSpUweAEiVKsHPnzhyLY8CAAVy6dAkzs4z/Jj/99BNly5ZlzJgxhIeHk5iYyNSpU3nvvff01jt+/Dhr1qzh119/ldtcRK7KqzIZGRlJixYtaNKkCcnJyTg6OrJw4UKuXbvGW2+9xeHDh3F2dgYgJSWFatWqMWLECGbMmJEj+z99+jQfffSR9vncuXN8/fXXdO3aVZsWEBDAkCFDqFq1KgCDBw+mX79+WZbHzZs3s2TJEpRSjB07ln79+uVIrEL8U16UUUOXT4Bbt24xatQo7ty5Q8mSJVm3bh3lypXT5kdERLBq1So2b97MmTNnqFSpEgDbt29n3rx5pKSk0LRpU1avXo2ZmRmJiYmMHj2aa9euUaRIEVauXMlbb72VY/EKAblfPnU6HZBRZ1WuXJmSJUvi7u7OZ599xuPHj6lWrRqhoaFUrlyZ5ORk7O3t2bhxI40bNyYtLQ1nZ2cWL16Mk5NTjsRz8eJFhg8fTnJyMsWKFWPjxo1UrlyZW7duMXDgQBISEnjjjTfYvHkzFhYW+Pn5sXDhQqysrADw9fWldevW2vbS0tKoUqUK9erVA8DGxoZFixblSKziJSnxXKGhoQpQoaGhub6vlJQU1bVrV9W6dWullFI3b95Utra26ubNm0oppeLj49Xw4cNVamqq8vf3V8OHD8/2toODg9Xvv/+e7eXbtWun0tLS9KZFRESolStXKqWUSkhIULVr1860Xnh4uLp69aqqW7dutvf1qvIyR8Lw8jrfV65cUW3bttU+9+3bV/n7+6srV64oFxcXNXToUG3etm3bVNu2bdX06dOfuc0XLY9P3L9/X7m7u6vU1FS96X5+fmrz5s2Zln9aeUxISFAtWrRQDx8+VElJScrOzk7Fx8e/cCwvQ8pqwZCXec4P5fODDz5QZ8+eVUopde3aNfXw4UO9+RcuXFARERHK3d1dq8+VUuqTTz5RSUlJSimlevfurfbu3auUUsrHx0ft27dPKaVUdHS0unv3brZjeVVSRl9/eZ3j/v37q2PHjulN++WXX1SvXr3UvHnztGl//PGHcnZ2VmlpaWrhwoXKx8fnmdu9f/++WrJkiUpJSclWHMuWLVMXLlxQSim1Zs0aNWXKFKWUUv369VO//PKLUkqpxYsXq1mzZimllJoxY4Y6evRoltuLjIzU+37JC1I+n016bPOZHTt24OrqSmRkJCEhIQQGBjJ8+HDt6m7ZsmVZtWrVC23z6NGjbNmyhebNm9OvXz+uX79Onz599JYxNzdn9+7detPu3r1L3759iYqKonv37nz00UfUq1dPuzL1999/07Bhw0z7a9KkyQvFJ4QxefToEfHx8VSsWBGAWrVqcfnyZR49ekSxYsX44Ycf6Nq1Kzdv3nzq+i9bHp/48ssvGT16NIUKFdKbfvXqVSIiIlizZg1VqlRh+fLllClT5qnl8eLFizRu3JhixYoB4OHhQVBQEJ06dXrh8yFEfmKI8pmens6lS5dYv349x44do02bNnz66ad661hbWz91f/PmzQPg4cOH3Lt3T1vO39+fMmXKMHPmTFq0aMHChQtf7oQIkU9t2rSJZcuW0atXL+0ORRsbG7y8vJg4cSIhISFZDj117949Vq9eza1btxg6dCiFCxdmzpw57N+/X2+5kSNH0rNnT+3zkzuflFJcuXKFZs2aAXDs2DH8/PwAGDhwIB07dmTq1KlcvXqVtWvXMmXKFBo1asSiRYu0ehMy6t3IyEhat26NiYkJCxculN/ABiYN23xm48aNrFy5kuvXr/PNN99gamqKnZ0dAImJiXTq1ImEhATWrFkDZNzGdO7cOQDee+89Ro8erW0rPDwcPz8/7O3tWbp0KaamGcMWV6lShYCAgOfG0rx5c2bMmEHp0qXp2rUrNjY2ODk58fDhQ9zc3Lhz5w5btmzJ4TMgRP50/Phx7O3tuXHjhvZcUmRkJAAdOnTg119/pW3btqSkpFCuXLlMP5xftTxCxo/fXbt24evrm2le9erVsbGxoWPHjnz//fd88skn2vfEv9WuXZvQ0FDu3LmDqakp//3vf/Pklm4hcoshy2dsbCynTp1i5cqVzJs3j169erF3717atm2brdinTZvG6tWrGT9+PDVr1gTgr7/+4tNPP2XChAmMHz+eb7/9luHDh7/YSREin4qJidFu423atCkhISHY29sDMGHCBCpWrMi3335L4cKFM637xRdfcP/+fYYOHUr16tW16b6+vk+tG/9t27ZtfPzxxzg4OGjLFypUSCvzpUuX5v79+wA0aNAANzc3WrZsyeeff87ixYvx8fHRtmVubk7btm0ZN24cly9fpkePHvz5558vf2LEK5OGbT5y69YtQkNDGTduHADBwcGMGDGCK1euoNPpKFGiBAEBAYwePZpHjx4B8Pbbb2fZg1u0aFFMTEy4d+8ejx8/pmjRogDZ7iFasWKF9u8OHToQGhqKk5MT5ubmnDhxggsXLtCxY0ciIiK053CFeF21bNmSPXv2sG7dOjZu3Ii7u7s2r3fv3owcOZL79+/rXR3+p1ctjwA//PADnTt31irgf+rfv7/27y5dujzzOZ+yZcvy2Wef0bFjRypXrkyLFi20Z3OFMEaGLJ+lSpWiTp06NG3aFIDOnTsTHh6e7YbtzJkz8fHxoV+/fvzyyy+8++67VK1alfbt2wMZ5fmHH37I/skQIp/buHEjMTEx9OrVi4SEBO2iEsCMGTP45JNPmD9/Pm+//TYWFhZ66xYvXpy4uDit8flEdnpsAbp27UqXLl348ssvmTJlCsuWLcPU1BSllPYdYGlpCWQ0sp/o0qVLpjsx7OzstM4na2trChcuzP3797X1Rd7L/OtIGMymTZuYPXs2W7ZsYcuWLQwaNIg33niDFStWcP36dSCjx+bUqVMUL178udurV68eixcvxsHBgYkTJ7J06VIePHigXYH+59+/f0QnJyczc+ZM0tLSUEpx8OBBGjdujL+/PwcOHAAyeogKFSpEWlpazp8MIfKpIUOGEBERQXh4uDbtjTfeADIeJejSpctT13uV8viEn58fvXr1euq8b7/9lgsXLgBw4MABGjdunOUxpKamUrduXY4ePcp3333H33//TcuWLbNz+ELka4Yon8WKFaNcuXJa+XtSXz7P/fv3+eKLL1BKUaxYMaytrbl79y4Atra2BAYGvtD2hDAWP//8M//973/ZsmUL+/bt48SJEzx69IjAwEDOnDnD9OnT6d+/P5MmTcq07ujRo5k1a5bW0fPHH38AGT22/y6r/27ULliwgDt37mBiYkKjRo208ubk5MSOHTuAjBcrPrmotHjxYmJiYoCn16vBwcH8+uuvQMZFsEePHkmj1sCkYZuPfP/997z99tva5549e7JlyxZWrlzJgAEDcHd3p1WrVgwZMkS7QrR9+3Z0Op329/Dhw0zbbdKkCcuWLcPT05OjR49mK5aiRYtiaWmJra0tLi4uNGrUCJ1OR+PGjVmxYgUODg64ubnh4+ND0aJF2bNnj/askBCvu4kTJzJ37ly9ad27d6dixYp6z988zcuUR4CEhASio6OpVauWNu3kyZN4e3sDGc8mDRw4EFdXV1atWsUXX3yR5baUUtqbJt9++22mT5/+1Fu+hDBGhiify5cvZ+TIkTg5OWFpaUn79u31yufTWFpaYmpqiq2tLW5ubkRGRtK7d28A5s+fz4IFC3B1deXChQsMGjQo27EIkZ/98ccfvPnmm3o9sa1bt2br1q2MHDmSr7/+Gsh4HvbkyZP897//zbSNYsWKMXr0aBYtWkRYWBiPHz/O1r6bNGlCmzZtcHNz44svvmD69OkAzJ49m2XLluHs7My+ffu0OyebNm1Kx44dcXNz4+jRo1oP7pO3PdetW5cNGzZgb29Pz549s3z8R+QdE6WUMnQQ+V1YWBg2NjaEhobKc2j5lOSoYJF8Gy/JXcEgeTZekrvXn+TYeEnunk16bIUQQgghhBBCGDVp2AohhBBCCCGEMGrSsBVCCCGEEEIIYdSkYWuk4uLitIfX86uNGzdib2+Pq6srPXv2JCkpSW9+ZGQknp6e6HQ6nJycCAoKAiAgIIDatWtrL8TauHEjkDFO4ZAhQ7CyssrzYxHieYyhTM6YMQNbW1utbJ0+fRrIeFOkg4MDdnZ2mYZLeGLWrFl4eXmh0+n4/fffgYy3ND95sZxOp8u07qJFi/L9OREFhzGU0f379/P+++/TpEkTvekzZ87EycmJpk2b6g3F90RW9eb27dtxcnLC1taWwYMHk5qaCkBiYiIDBgzA09OTdu3a8b///S/3D06IZzDW8nn69Gm9l7hWqlSJbdu26a0XERHB2LFjsbKyIjo6OtN2//Of/2hjWMfGxuptr0aNGnz55Ze5e2CvERl8VOSKlJQUZs2aRXh4OObm5kyYMIFNmzYxbNgwbZmZM2cyfvx4OnbsyJkzZxg2bBhBQUFcvXqVmTNnam+HfKJYsWJMmzaNI0eO5PXhCPFauHr1Ktu3b6dy5cratIiICPbt20dQUBAJCQm0adMGT09PChUqpC2zf/9+Hj16xIEDB0hOTubWrVva9tasWYOTk1OmfV2+fJkzZ87k/kEJ8RopVaoUS5Ys0RuHNzY2FhMTE4KCgkhOTqZRo0YMGjQIc3NzbZms6s2goCAOHDiAubk5ffr04eDBg7Rp04a5c+fSp08fWrduza1bt/S2JYR4uqeVz8aNGxMQEABkXDDq1KmT3ggnAGZmZowcOVJvGLInbt++zcaNG6lWrRoA5cuX17aXnp6Ol5cXgwcPzp0Deg1Jj+1LCA8Px87ODnd3d3bt2gVk9E7a2NjQvn17Bg0aREBAAJGRkbRr105br1GjRgDcvHkTLy8vHBwcGDNmDJBxtXXUqFG88847hIWF4e/vj4ODA46OjtqV19jYWLy8vGjbti0LFy58Zoxbt27F3t4eR0dH9u3bB2T01syZM4c2bdqQmpqKo6MjY8eOZf369dy4cYMOHTqg0+no3LmzNm6XTqfj66+/ZuzYsdq209LS9K4mPfl7Mh4YZBTiihUrkpKSAmSMm9mwYUO9GKtVq6YNT/To0SNtcPurV6+yY8cOdDodffr04fbt20DGa9qfFHwh/knK5PPLJMCNGzeYNm0abm5ufPrppyilOH36NM7OzpiammJlZYW1tTURERF66/3444+UK1cOLy8vevXqRZEiRYCMsrp27Vrc3d358MMPefToEZAxnJC3tzczZszIfhLFa03KaPbKaMuWLalYsaLetPLly/Ppp58CEBMTQ5UqVTI1RLOqN+fNm4e5uTkPHz7k3r17WFtbA+Dv7094eDiurq58/vnn0rAt4KR8vnz5/Kcvv/yS0aNH610YBrC2tqZevXpPXWf8+PH4+PhgYmKSad7mzZvp2LEjJUuWfOa5Ef+gxHOFhoYqQIWGhiqllFq2bJlatWqVevz4sYqOjlZxcXGqadOmKikpSSUnJysnJyfl7++vrly5otq2battp2HDhkoppSIiItSJEyeUUkp5eXmp2NhY5e/vrxo1aqTu37+v0tPTVZ06dVRMTIxKTU1VOp1O3blzR40bN05t3LhRKaXU7t27lbu7+1PjTUhIUA0bNlRJSUkqMTFROTg4KKWUmj59uhowYIC2XJkyZVRYWJhSSqnevXur3bt3K6WU2rZtmxo8eLBSSil3d3fl5+f3UuftyJEjqnv37mr+/Pnq008/zTT/4cOH6p133lHr169XXbt2VbGxsUoppfz8/NTOnTuVUkpt3rxZDR06VG+9unXrZtrWv3MkXm9SJl+uTE6ePFldunRJpaenq2HDhqnNmzerM2fOKBcXF/Xo0SMVFRWlqlWrpoKDg/XWa9eunZo6dapSSqnt27erXr16KaWUWrBggQoJCVFKKTVnzhw1Z84cpZRSq1atUosXL9bi/ScpqwWDlNGXK6NPPK2ea9u2rapSpYras2dPpnnPqjc//fRTVaFCBfXFF19o00qWLKl+//13pZRSH3/8sVq1apU2T8ro60/KZ86Xz6SkJGVvb6/S0tKyXM/d3V3dvHlT+7x37141ZswYbd4/paenKycnJ3X37l296VI+n01uRX4Jw4YNY9GiRQwfPpxJkyZx9+5dmjVrpl3xbN68+TPXT0xMZNq0aSQlJXHu3DkSExOBjCtBJUqUIDY2lpiYGLp37w5AQkICkZGRnDt3jo8++ggAW1vbLLd/6dIl4uPjad++PQB3794lPj4eAE9PT225MmXKaLGeOnWK1q1bAxkDZc+ePVtb7p/rQMaVLS8vr0z7/e233yhVqhSQ8azEF198wW+//YaJiQnffPMNq1atYsSIEdryQ4cOZcGCBVhbW9O5c2f69OnDnj176N+/v7ZMly5dWLRo0TPPpxBSJp9fJgHmzp2r/fudd97hwIED9O7dm969e+Ph4UHdunVp3rw5VatW1dtOqVKl6NGjBwCdO3fG19cXQBusHjLK6qeffkpUVBQ//vijdkVdCJAymt0y+ix79uwhOjoaLy8vDhw4QKVKlbR5z6o3Z86ciY+PD/369eOXX37h3XffpWrVqtqxdunShR9++CFbMYjXk5TPVy+fP/zwA507d8bUNHs3wyYmJjJ79mztnRX/5u/vT4MGDaS39gVJw/YlxMXFMX78eG7evMm4ceNYt24dYWFhPHr0CKUUwcHBvPfee1haWhIbGwvA4cOHefDgAZDxEpbJkyfj6uqKh4cHSikAChcuDICVlRW1a9dmx44dWFpacvLkSaytrWnQoAH+/v7UrFkzyxe8ANSqVQtra2v2799P4cKFCQ4OpnTp0nr7+Pe/GzZsSGBgIB4eHhw4cEC7veTfywEUKlRIu/8/K7du3SIhIQGlFCYmJqSkpHD16lW9Zc6fP096ejoAjx8/1l5e8e233+Li4kKdOnU4cOAAjRs3fua+hJAy+fwy+eQ4x48fj4WFhVa2Hj58iJeXFyNHjiQuLo4BAwZQpUoVvfXatGnDtm3baNy4MYcOHaJ+/foALF68mL59+1KhQgVte/7+/qSmptKtWzcAzpw5w+jRo1m+fPlz4xOvLymj2SujT3Pq1CkiIiLo2bMnFStWpGzZstpjPE88rd68f/8+K1euZNKkSRQrVgxra2vt1kpbW1sCAwNxc3Pj4MGDUs8WcFI+X758PuHn58f69euzvfzx48dJTU2lb9++QEZd2aNHD3788UdtewMGDHilmAoiadi+hAsXLtC7d28SExPx9vamXLlyeHt74+joSPXq1bXejnLlymFra4uTkxNOTk5UqFABgL59+/Lhhx9Sv359GjZsSFRUlN72TUxMWLBgAe3atcPU1JQGDRqwYsUKfHx86NWrF+vXr9d7xuHfypYty+jRo3Fzc8PMzAw3NzccHByeeUyLFi1i6NChzJw5k+LFi7Nu3bpXOkcNGzbEy8uLJk2aUKpUKUqVKoWfnx/R0dF4e3uzZcsWFi9eTO/evSlatCiPHz9m8eLFANjY2DBw4EBMTU0pWbIk33777SvFIl5/Uiazp3bt2ri4uFC8eHEaN25M3759SUpKYsqUKdy6dQtLS0uWLFkCwMmTJ/Hz82PJkiV88MEHjBkzBjc3NwoVKqRV3k2bNqVjx46Ym5tTuXJl1q1bR4kSJejXr5+2T51OJ41aIWX0FVhbW7NkyRIWLVqEqakpXbt2pWbNmnpl9Gn1pqWlJaamptja2lK8eHGqVq3K9OnTAZg/fz5DhgzB19eXatWqMXny5FyJXRgHKZ+vJiEhgejoaGrVqqVN+2f5fBpPT09tNBDIqCufNGrT09Px9/dn7dq1uRbz68pEPbmsIrIUFhaGjY0NoaGhtGjR4rnLjx49mvfeey9PXlu+Z88e5s2bpzdt/vz5tGzZMtf3nZ+8aI6EcZMyabykrBYMUkaNl5TR15+UT+Ml5fPZpMfWyLVr1+6ZV7mEEHlLyqQQ+ZuUUSHyLymf4lVIwzYXyG13QuQvUiaFyN+kjAqRf0n5FMZCxrEtYHQ6HdHR0bmy7f379+uN/1W6dGn+/PPPXNmXEK+j3CyfAF5eXlr5fNobIIUQmeV2uXzi7bff1hv7+bPPPsPe3h5bW1u9Z/GEEP8nt8vnmjVr0Ol0jBw5UpuWnJxMv379cHFxwc7OTp6FzUekx1bkmNatW2uvVr927RqjR49+7ivihRB5x8zMjAMHDhg6DCHEv3z//ffa0CoABw8e5M8//yQkJISoqCg6derEyZMnDRegEAVU7dq1mTRpEtu3b9embd26lUqVKrFx40aSkpJo1KgRffv21SvDwjCkxzafCQ8Px87ODnd3d3bt2gXAsmXLsLOzo2XLlpw+fRrIuELl4+ODjY0NK1eupFu3bjRr1oyDBw8CMGDAAHx8fNDpdDg7O3PlypVM+5o4cSLOzs60atWKyMhI0tPT6datG25ubowaNUpv2dDQUL3eWJ1Ox8CBA7M8js8++4xPP/00p06LEPmCMZfPtLQ0oqOj6dq1K25ubtrbF4UwdsZcLgFiY2NZv349w4YN06bt3btXe7t41apVqVGjBhcvXsyZEyZEHjL28unp6YmFhYXetDfffJPk5GQAUlNTqV27NsWKFXv1kyVemfTY5jOBgYEMGTKEwYMHa4NPW1lZERISQlBQEKtXr9aedXB3d8fX15eKFSty/vx57t27xyeffKINPG1ubk5AQAC///47U6dOZfPmzdp+9uzZw99//83Ro0c5deoUU6dO5auvviIuLo6AgABu3LihF5eNjU22x/i6fv06f//9N3Z2djlwRoTIP4y5fCYlJeHu7s7cuXNRStGqVSvs7e2pXr16Dp4hIfKeMZdLgI8//pi5c+eSmJioTUtISNCGUgGoWLEicXFxWFtbv/R5EsIQjL18Po2Hhwe7d+9m4cKFhIWFMWvWLExMTF5qWyJnSY9tPjNs2DDi4+MZPnw4d+7cIT09nbNnz+Lu7s748eP1Kr6mTZtSvHhxatSoQZUqVShfvjz37t3T5j+5LdjDw4Nz587p7ef06dOEh4ej0+kYM2YMMTExlClTBh8fHwYNGqRdIXviRXpsV69eTf/+/XPqlAiRbxhz+bS0tGTZsmUUL16cEiVK4ObmxqlTp3L6FAmR54y5XO7YsYPy5ctja2urN71ChQrExsZqn2NjY7Gysnq1EyWEARhz+czKunXrqFOnDhMmTGDTpk3MmjVLr7wKw5Ee23wmLi6O8ePHc/PmTcaNG8e0adMIDg7m0KFDBAQE8N1332V7WydOnMDBwYGjR49Sr149vXmNGjWiTZs2LF26lPT0dEJCQkhLS6NevXr4+fnh6elJ586dKVOmDPBiV7a2bt1KWFhYtuMUwlgYc/mMjY1lw4YNjB8/nsePH3P06FGGDx/+wudAiPzGmMvlvn37uHTpEl26dCEuLo64uDgqVapE+/btWbx4Me+++y7R0dFcvXpVemuFUTLm8pmV8+fPU7t2bSDjMZ87d+4QHx9P+fLlX2p7IudIwzafuXDhAr179yYxMRFvb2/q16+Pqakpbdq0oW3btty9ezfb24qIiKB9+/Y8ePCADRs26M1r3749hw4dwtnZGRMTE7y9vbl//z4TJkzg5s2bVKpUidKlS79w/OHh4VStWpXixYu/8LpC5HfGXD6trKyIiYmhRYsWFC1alIEDB1KrVq0X2oYQ+ZExl8uvvvpK+3dAQAABAQGMGDECgN27d2Nra0uhQoVYtmzZC21XiPzCmMtnVj7++GP69+/P2rVrUUrx7rvvZmpoC8MwUUopQweR34WFhWFjY0NoaCgtWrQwdDjZMmDAAEaMGIGDg4OhQ8kTxpgj8fKMPd8FrXz+k7HnTmSPMea5IJfLfzLG3IkXY4w5lvKZwRhzl5fkGVshhBBCCCGEEEZNbkV+Tfn5+Rk6BCFEFqR8CpH/SLkUIv+S8imyQ3ps87EZM2awZcuWPNnX1atXsbS0JDIyEoA+ffpob4lr1qwZ77zzzlPXS01NpUWLFpm+cO7du0fVqlW1B/MvXryIp6cnzs7OeHl5ZXrtuhDGLC/K6vPK0PHjxzEze/q1ypCQEFq1aoWXlxdjx44lPT0dpRTe3t64uLjQsmVL9uzZk6vxC2FIeVFGk5OT6dOnD+7u7jg5OREaGgrA7du36dSpEzqdDg8PD/73v/9lWvezzz7D3t4eW1tbgoKCAIiJiaFjx464urri5OTEX3/9lavxC5GX8qJMRkVF4ePjQ9WqVQkODs40P6t6c+PGjXpvSy5RogSxsbFZlkn5jZt/SMNWADBhwgRcXFy0z5s3b9ZeZOHk5MQnn3zy1PXmz5//1Dc1Tp48GXt7e+3znj17WL16NUePHqVXr17amGVCiOx5VhlKSUlh5syZmYYMgYyLT9OmTeO3337jwIEDjB49GhMTE3bu3ImZmRlHjhxh9+7dTJgwIS8PR4jXzpo1a3B0dOTQoUN8++23WpmaPXs2I0aMICAggE8++YRZs2bprXfw4EH+/PNPQkJC+PXXXxk1ahSQ8TKpKVOmcPjwYT777DPmzJmT58ckhDEzMTGhe/futGrVKtO8Z9Wb/fr1034Df/HFF/Tt25fy5ctnWSblN27+IQ1bA3BxcSEqKgoAX19ftm3bRmBgIC1btsTGxkZvwOkn/vm2tUaNGgEZP1g/+OAD3Nzc6Ny5M7dv39ZbZ86cOZnG6Nq6dWumbfv5+eHg4EDFihUzzfvf//7HzZs3cXJyyjTv3LlzhIWF0b59e73p/v7+mJmZ0bhxY23aRx99hLW1NUoprly5QrNmzZ5xhoTIH/JTWX1WGfr8888ZOHAgxYoVyxRPSEgIVatWZfDgwbi6unL27FlMTEzo1KkTn3/+OZAxXEHRokVf7iQJYUD5qYyOGjVKe6Px48ePMTc3BzLKZ6dOnTJNf2Lv3r3069cPgKpVq1KjRg0uXrxIjx49tAvOly9flnpTGIX8VCarVKlC8+bNnxrns+rNf5oxYwaffvopQJZlUn7j5h/SsDWAwYMH8/333wMZV2Q7d+7Mw4cP2bVrF0eOHMn2lZ5169ZRuXJlAgMDGTZsGAsXLtSb7+vrq11xevLXs2dPvWWio6PZtGkT3t7eT93HokWLGDt2bKbpT25jXLx4sd70pKQkPvvsM2bPnp1pnW3btvHWW29x5coVOnbsmK1jFMKQ8lNZhaeXoTNnzvDXX3/RrVu3p+47KiqKEydO8PXXX7N9+3amTZvG7du3MTExoUiRIpw5c4ZevXqxZs2aFzk1QuQL+amMFipUCDMzMwIDAxkzZgwrVqwA0C4a/ec//2HFihWZ6seEhAQqVKigfa5YsSJxcXEAHDt2jAYNGvDjjz8yaNCgFzgzQhhGfiqTWXlevfnEiRMnqFixIlWqVNGmZVUm5Tdu/iAvjzKAnj170rZtW9zc3HBzc8PMzIy4uDh69OiBUirTVamsnD59mqCgIIKDg0lPT880JuWcOXPYv3+/3rSRI0fqFfyxY8cyf/58ChUqlGn79+/fJygoSKuc/2n58uV06NCBatWq6U3/9NNPGTduHCVLlsy0TteuXenSpQtffvklU6ZMkXH5RL6Xn8oqZC5DX375Jd7e3s98qUapUqVo3bq1Nii9ra0tFy9epGXLlvz2229s2LCBH3/8ESsrq2wdixD5SX4ro6tWreKPP/5g586deuO5T506ldTUVO0RgH+qUKECsbGx2ufY2FitPDo6OnL27Fn+85//MGjQILZv356t4xHCUPJbmfy3tLS059abT3z11VcMHz5cb1pWZVJ+4+YP0rA1AAsLCxo1asTs2bNZsmQJAFOmTOHMmTOkp6fj6uqaaZ3Hjx+Tnp7OlStXuHTpEpBxu0bt2rUZN24cycnJnD59Wm8dX19ffH19s4wjMTGR8+fPM3PmTCBjbKwbN26wfPly6tSpw08//UTnzp2fuq6/vz+pqakcPHiQa9euAVCyZEmCgoK4fPky69ev59y5c/z3v/9l3rx5HDt2jKFDh1K6dGkaNWpEeHj4C583IfJafimrAAsWLMhUhi5dusTdu3cZPXo0kHEVukuXLvj5+WkD0Ts6OjJz5kySkpIwMTHh5MmT1K5dm9OnT7Np0yZ++uknTE3l5h1hnPJTGd23bx9nzpxh3bp1etPXrl1LyZIlmTRp0lPXa9++PYsXL+bdd98lOjqaq1evYm1tzapVq+jYsSNvvvkmjRs35u7du9k9LUIYTH4qk0+TnXoTMn4jnzhxgg0bNmjTsiqTT6ufhWFIw9ZAhg4dyoQJE6hduzaQcYWrdevW2NjYUKNGDVJSUvSWHzhwIPb29jRp0oQGDRoAMGTIEIYPH46bmxvAU2//fZYSJUpw8uRJ7fOAAQOYMWMGNWrUAGDHjh18/PHHeuv06tWLJUuW8Msvv2jTnlz1evfdd3n33Xe16TNmzECn0+Hi4sKDBw9o06YNxYoVo3Dhwqxdu/aFYhXCUPJDWQVo0qRJpjL01ltvceLECW0ZnU7Hr7/+CvxfWa1UqRKTJ0+mTZs2JCcn4+3tTdmyZfn88885f/48np6e2vq//fYbpUqVeuHYhDCk/FJG16xZw7Vr19DpdACYm5uze/duVq9ejYWFBb///jsANWvWZP369VoZdXFxYffu3dja2lKoUCGtp8fOzo73338fyHgJzpdffvniJ0cIA8gvZfJp6tatm61688CBA5neL5NVmXxa/SwMw0QppQwdRH4XFhaGjY0NoaGhtGjRwtDhiKeQHBUskm/jJbkrGCTPxkty9/qTHBsvyd2zyf1nQgghhBBCCCGMmjRshRBCCCGEEEIYNWnYCiGEEEIIIYQwavLyqBcQERFh6BBEFiQ3BZPk3fhIzgoWybfxkZwVHJJr4yM5ezZp2GaDlZUVFhYW9O3b19ChiGewsLCQsTgLCCmTxk3K6utPyqhxkzL6epPyadykfGZN3oqcTdeuXSMuLi7X9/P3338zbNgwihYtypo1a6hQoUKu7zOnfffddyxbtoxBgwYxatQoTExM8mS/VlZWVKtWLU/2JQwvr8rkPymlWLlyJd9++y1jxoyhf//+ebr/nBATE8OwYcNISUlh9erVvPnmm3keg5TVgsEQZVTq0JwhZfT1J3Xoy5E6NJ9TIt+4ePGiqlKliqpTp466fv26ocN5JQsWLFCAmjJlikpPTzd0OEK8svT0dDV58mQFqIULFxo6nFcSFRWl6tSpo6pWraouXrxo6HCEyBFShwqRf0kdKvKC9NjmExcvXsTDw4MSJUrg7+/PG2+8YeiQXtnixYsZP348kydP5vPPPzfIVWchcoJSiilTpvDFF1+wePFixo0bZ+iQXtmNGzfw8PDgwYMHBAQEULt2bUOHJMRLkzpUiPxL6lCRV6Rhmw9cuHABDw8PSpYsycGDB1+LCvmJL7/8ko8//phJkyYxb948qZiF0VFK8cknn7BgwQK+/PJLvL29DR1Sjrl58yYeHh7cv3+fgIAArK2tDR2SEC9M6lAh8i+pQ0VekoatgZ0/fx4PDw9Kly7NwYMHqVSpkqFDynFLly7F29ubCRMmMH/+fKmYhdFQSjFx4kQWLVrE0qVLGTNmjKFDynHR0dF4eHhw9+5dAgICqFOnjqFDEiLbpA4VIv+SOlTkNWnYGtC5c+fw9PSkTJkyHDx4kIoVKxo6pFyzbNkyxo4dy/jx41mwYIFUzCLfU0oxYcIEFi9ezLJly/joo48MHVKuuXXrFh4eHty5cwd/f3/q1q1r6JCEeC6pQ4XIv6QOFYYgDVsDiYiIwNPTk3LlynHgwIHXukJ+Yvny5Xz00UeMGzeORYsWScUs8i2lFB9//DFLlixh+fLlfPjhh4YOKdfdunULT09PEhIS8Pf3p169eoYOSYgsSR0qdajIv6QOlTrUUKRhawBnz57F09OT8uXLc+DAAaMcjuBlrVixgtGjRzN27Fi+/PJLqZhFvqOUYty4cSxdupQVK1YwatQoQ4eUZ2JiYvD09CQuLg5/f3/q169v6JCEyETqUKlDRf4ldajUoYZkaugACop58+Zx7tw5zp49i4eHBxUqVODgwYMFqkIG+PDDD1m5cqX2zJBSivnz5/PXX38ZOjRRgP31118sWLAApRRjx45l6dKlfP311wWqQgaoUKEC/v7+lC9fHg8PD86ePcu5c+eYN2+eoUMTBZzUoRmkDhX5kdShGaQOzQfyZlShgu38+fMKUF999ZUqX768atKkiYqJiTF0WAb19ddfK0B99NFHqlmzZqp3796GDkkUYO+//75q3ry5Gj16tALUqlWrDB2SQcXExKjGjRurChUqqGXLlilAXbhwwdBhiQJK6tDMpA4V+YnUofqkDjUcuRU5D8yePZu5c+diYWFBlSpV+O9//4uVlZWhwzK4NWvWMHz4cOzt7fnrr7+IiYnB3Nzc0GGJAubhw4eUL1+ehg0bcvz4cVavXs2wYcMMHZbBxcXF4eXlxY0bN3jw4AG+vr74+voaOixRAEkd+nRSh4r8QOrQp5M61DDkVuQ8sGHDBlJSUihSpAiFChWiRYsWpKWlGTosg1q1ahW+vr44OTkREhJCYmIiv//+u6HDEgXQrl27ePDgAcePH8fZ2RlfX19WrVpl6LAMKi0tjRYtWmBmZkbhwoVJTU1lw4YNhg5LFFBSh2YmdajIL6QOzUzqUMORhm0uO378OBcvXiQ1NZX4+HiqVavGypUrKVSokKFDM6hu3boxfPhw4uLitGkzZ840YESioPrn/7vY2FiGDx9Ot27dDBiR4RUqVIiVK1dSrVo1EhISePz4MRcuXOD48eOGDk0UMFKHPp3UoSK/kDo0M6lDDUduRc5lkZGRdO/eneHDh9OzZ08sLS0NHVK+opTi9OnTzJ49m8qVK7NkyRJDhyQKGG9vb27cuMGnn35Ko0aN5C2j/3L//n22bt3K6tWr+emnn6hRo4ahQxIFiNShzyZ1qDA0qUOfTerQvCUNWyGEEEIIIYQQRk1uRRZCCCGEEEIIYdTMXnUD165d03vGQ+QvVlZWVKtWLdvLSz7zv+flVHJovF60vD4hOc97L5srkHwZq+zkXHKb/71I2ZV85n9SLl9fL1XPvspYQVevXlUWFhYKkL98+mdhYaGuXr0q+XyN/p6VU8mhcf+9SHmVnBtfriRfxv33vJxLbo3jL7tlV/JpHH9SLl/fv5epZ1+pxzYuLo6kpCQ2bdpE/fr1X2VTIhdERETQt29f4uLisnXFQ/KZ/z0vp5JD4/Wi5fUJyXnee9lcgeTLWGUn55Lb/O9Fyq7kM/+Tcvn6eul69oWawf8SGhqqABUaGvoqm8kxsbGxyt3d3dBhPFNQUJBydHRUNjY2aurUqZnmP3jwQPXo0UM5ODgoLy8vFR0drZRSKiEhQXXs2FG5u7srnU6nLl++rJRS6rffftO2N2jQIPX48WNtWy+an/yWT6WMI6dPLFy48KmxXrhwQXl4eCgnJyfl6emprl+/rpTKOqePHz9WY8eOVR4eHsrDw0OdOHFC29bzciQ5fDn79u1TvXr1Uo0bN37q/NGjR6v+/ftnmn7s2DHl4uKiWrZsqd555x11//59pVTWOfzjjz+Uq6urcnV1VT169FCPHj3StvWyuZOcv5yX/S5W6tXOueTr5WRVRn/88UfVqVMn1b59+6eul9X37BM///yzqlGjhvZ5w4YNqmXLlsrFxUX16NFDPXjwQCmVvbxJbl/Opk2blK2trbKxsVEbNmx46jJr165VOp1O6XQ69c033yillPL391e1atVS7u7uyt3dXVs3p34XST5fXExMjJYPd3d3Vb16dbV48WK9ZR49eqR69+6t3NzclKOjo/rjjz+UUrn3Oze/5TG/51CprL9v9+zZo5ycnJSTk5MaPXp0pvXOnj2rxowZo8qVK6du3rypTV+/fr1q2LCh9v9i3759Siml1qxZoxwcHFTTpk2Vj4+P3rZeNm/y8qg8lJ6ezpAhQ/jxxx85ceIEp0+f5siRI3rLzJs3DwcHB44dO8aHH36Ir68vALNnz2bEiBEEBATwySefMGvWLACCgoI4cOAAf/zxB48ePeLgwYN5flwCLl++zJkzZ546b8+ePaxevZqjR4/Sq1cvli9fDmSd0/Xr19OwYUMOHjzIL7/88tLP8YnsK1WqFEuWLCElJSXTvKNHj2b5bM6+ffvYtm0bISEhNGzYkO+//x7IOocTJkxgy5YtBAYGUrNmTbZs2ZJ7ByWy9CrfxcIwsiqjlSpVYtasWaSnpz91vay+ZwFu377Nxo0btfKZkpLCrFmzCAgI4PDhw7z55pts2rQp9w5KcPv2bRYvXszhw4c5fPgwX331FQkJCXrLnD9/nsDAQPz9/Tlw4ADu7u4AXL16lZkzZxIQEEBAQAD9+vUD5HeRIZUvX17Lx8GDB6lZsyaDBw/WW2bNmjU4Ojpy6NAhvv32WyZMmADI79z85Gnft6mpqUyfPp29e/dy9OhRYmNjOXTokN56ZmZmjBw5kkaNGulNv3r1KmvWrNH+b7Ru3ZqUlBQuX77M0aNH+fPPPwkMDOTChQuvHHuONWzDw8Oxs7PD3d2dXbt2AbBx40ZsbGxo3749gwYNIiAggMjISNq1a6et9+Tgb968iZeXFw4ODowZMwaAgIAARo0axTvvvENYWBj+/v44ODjg6OjIxo0bgYzBoL28vGjbti0LFy58Zoxbt27F3t4eR0dH9u3bB8CMGTOYM2cObdq0ITU1FUdHR8aOHcv69eu5ceMGHTp0QKfT0blzZ2JiYgDQ6XR8/fXXjB07Vtt2WloaOp0u09/du3e1Zc6fP89bb71F1apVMTExYcCAAezevVsvxr179/LBBx8A0KVLF4KDgwH4/PPP6dSpEwCPHz/G3NwcyPjxZW5uzsOHD7l37x7W1tbZztnzSE6fn1MApRTe3t7MmDHjqTF+9NFHWFtbo5TiypUrNGvWDMg6pz/++CNpaWm4u7szZswYbfrLkBxmL4ctW7akYsWKmWJ79OgR06ZNY8qUKU+Nfdq0aVhZWZGamsr169dp3LgxkHUO9+zZQ+XKlQH9nOckyXnufhfnNMnXq5VRV1dXSpcunWXsWX3PAowfPx4fHx9t3E0zMzMqVqyo/ZhLTU2lYcOGzzw3zyK5fX5uL168SOPGjSlWrBjm5uZ4eHgQFBSkF+PPP/+MtbU17dq1o127dqSmpgIZP5Z37NiBTqejT58+3L59G8i930WSz+yV1Sc2b95Mx44dKVmypN70UaNGMWLECEC/TObF71zJ4ct/35qZmXHo0CFKlCgBZHw//vs3jLW1NfXq1ct0TFevXmXt2rW4u7vz4Ycf8ujRI4oUKcK8efMwNTXlzp07mJmZ8cYbbzzz3GTLC/Xv/ss/u4mXLVumVq1apR4/fqyio6NVXFycatq0qUpKSlLJycnKyclJ+fv7qytXrqi2bdtq22jYsKFSSqmIiAjtdj0vLy8VGxur/P39VaNGjdT9+/dVenq6qlOnjoqJiVGpqalKp9OpO3fuqHHjxqmNGzcqpZTavXt3lt37CQkJqmHDhiopKUklJiYqBwcHpZRS06dPVwMGDNCWK1OmjAoLC1NKKdW7d2+1e/dupZRS27ZtU4MHD1ZKKeXu7q78/Pxe+HwdOXJEDRo0SPscFBSkhg0bprdM3bp19T7/+zaAn3/+WbVt21bFx8dr0z799FNVoUIF9cUXX+gt+6q3IktOs2fVqlXarTZZxfrLL7+oGjVqqF69eqnExES9ef/Oaf369dXatWuVUhk5mDx5srbsi96KLDl8Mf8uf5MnT1a//PKLunLlylNvRVZKqZUrV6rKlSsrb29v7RapZ+UwNTVVTZ06VY0cOVKlpaVp03PqVmTJ+fO96ndxTt6KLPl6Mf/Oi1Iq07l5mn9/z+7du1eNGTNGi+uJI0eOqO7du6v58+erTz/9VJv+Mrc8Sm6fLz4+XjVq1Ejdvn1b3b17V7Vo0UJt2bJFb5kRI0ao/v37q7S0NBUWFqZcXFyUUkr5+fmpnTt3KqWU2rx5sxo6dKi2Tk78LpJ8vnxZTU9PV05OTuru3btZLnPo0CGl0+nU//73P73pOf07V9oqL+9p37cPHz5UQ4cOVbNmzcpyPXd3d71bkRcsWKBCQkKUUkrNmTNHzZkzR5s3aNAgVbFiRfXdd9/pbcPgtyIPGzaM+Ph4hg8fzp07d7h8+TLNmjXD3NycIkWK0Lx582eun5iYyLRp09DpdJw5c4bExEQg46pBiRIliIuLIyYmhu7du+Pl5UV8fDyRkZGcO3cOZ2dnAGxtbbPc/qVLl4iPj6d9+/Z07NiRu3fvEh8fD4Cnp6e2XJkyZbRYT506RevWrQFo3bo1J0+e1Jb75zqQvasgFSpUIDY2VvscGxuLlZWV3nbKlSun3YajlNKbN3XqVE6cOMHOnTspW7asNn3mzJlcvXqVEydO8Msvv2R5Dl6U5PT5OY2KiuLHH3/UrtxlpWvXrvzvf//Dzs5Or/fvaTktWbIkPXv2BDJ6isLDw5+57WeRHL7YFeZ/+vPPP7l8+TJdu3Z95nIjR47k6tWrACxbtgzIOocPHjyge/fuNGzYkJUrV2JqmvNPg0jOc/+7OCdJvl6+jGbXv79nExMTmT17NnPmzNFbLi4uji+++IKtW7cyceJEqlevzqpVq156v5Lb5+e2bNmyfPbZZ3Ts2JHBgwfTokULqlatqredUqVK0a1bN0xNTWnevDl37twBoH///nTs2BHI+J4NDQ3V1smN30WSz+yXVX9/fxo0aJCpt/aJVatWsWHDBnbu3EnNmjW16bn9O1dy+GrftzExMbzzzjv06tWLqVOnZmsdyHgMq2XLlkDmsvrNN99w4cIF1qxZozf9Zb3yOLZPxMXFMX78eG7evMm4ceNYt24dYWFhPHr0CKUUwcHBvPfee1haWmo/KA4fPsyDBw8AmDVrFpMnT8bV1RUPDw/th0ThwoWBjLGMateuzY4dO7C0tOTkyZNYW1vToEED/P39qVmzJvv3788yvlq1amFtbc3+/fspXLgwwcHB2u1LT/bx7383bNiQwMBAPDw8OHDggN494/9cDqBQoUIEBAQ88xxZW1tz7do1bty4QeXKldm8eTMfffSR3jLt27dn06ZNjBkzhj179mj/EdauXUvJkiWZNGmStuz9+/dZuXIlkyZNolixYlhbW+fojwHJ6fNz6u/vT2pqKt26dQPgzJkzjB49WnuOFmDBggUMHTqU0qVL06hRI62R87ScArRp04Zt27bxwQcfcPDgQe321pchOXx+DrOyd+9eEhIS6NKlC0lJSZw7d46ZM2cybdo0IOM5zblz5zJx4kSKFClC/fr1uX79OpB1DkeOHMmECRNwcnJ6qZiyQ3Keu9/FOU3y9fJlNDue9j17/PhxUlNT6du3L5Dxvd2jRw+mT59OQkICSilMTExISUnRLlq9DMnt83ObmppK3bp1OXr0KElJSbz77ruZylqbNm3YtGkTnTt35uLFi5QqVQqAb7/9FhcXF+rUqcOBAwdo3Lhxrv4uknxmv6z6+fkxYMCAp87bt28fZ86cYd26dXrT8+J3ruTw5b9vlVL079+flStXUqtWrRdad/HixfTt25cKFSpoZTUqKoqdO3cyYsQISpYsSfXq1bl3795LxfZPOdawvXDhAr179yYxMRFvb2/KlSuHt7c3jo6OVK9eXbsCV65cOWxtbXFycsLJyYkKFSoA0LdvXz788EPq169Pw4YNiYqK0tu+iYkJCxYsoF27dpiamtKgQQNWrFiBj48PvXr1Yv369Xr3w/9b2bJlGT16NG5ubpiZmeHm5oaDg8Mzj2nRokUMHTqUmTNnUrx48UyF8GUsX76ct99+m0KFCtG6dWtcXFyIjo7G29ubLVu2MG7cOPr27cuWLVuwsLDQXlyxevVqLCws+P333wGoWbMm69evx9TUFFtbW4oXL07VqlWZPn36K8f4hOT0+fr166e9sAIynmlYvny5Xk6bNGlCmzZtKFasGIULF2bt2rVA1jmdNGkSw4YNY926dZQsWZINGza8dHySw5c3efJkJk+eDEBkZCQzZsxg2rRpnDx5Ej8/P5YsWUK1atVwcnKiePHiWFpa8t133wE8NYf379/nt99+49q1a9o+unbtqvf8S06QnGfPy34X5zTJV877ZxnN6nv2n89x6nQ6fvzxRwC8vLxo0qQJpUqVolSpUvj5+b10HJLb51NKsXjxYiIiIrCwsGDWrFkULlxYryx6enoSGBiIq6sraWlprFixAgAbGxsGDhyIqakpJUuW5Ntvv8XS0jLXfhdJPrMnPT0df39/7bcOoJfPNWvWcO3aNXQ6HQDm5ubs3r07T37nSg5f3l9//UVoaKjey8BGjhxJ3bp1te/brDRt2pSOHTtibm5O5cqVWbduHRYWFly6dAlbW1uKFi2Kra2t9n/ilbzQjcv/8iL3P3/44YfK39//VXaXbU/uX//n35N7uwuS3B7uR3Ka93J6uB/JYf6RV8P9SM5fXV4O9yP5yh9yY1gRyW3ey83hfiSfeS+ny6XkMP942Xo2x3ps85Mnb84Trw/JqfGTHBY8knPjIvl6fUluXy+ST+MnOcwdedaw/eczh+L1IDk1fpLDgkdyblwkX68vye3rRfJp/CSHxi/nX8kphBBCCCGEEELkIWnY/n86nY7o6Ohc2/6GDRtwdHTE3t6euXPn5tp+RIbczqeXl5f2mnQvL69c24/IkNv5fOLtt99mxowZub6fgi6387lmzRp0Oh0jR47MtX0Iw9abqamptGjR4pVe7iT0GapchoSE0KpVK7y8vBg7dizp6em5FkNBJXWo8TNkvWlM37fSsM0D8fHxfPPNNxw+fJhjx46xc+dOIiMjDR2WeAVmZmYEBAQQEBDAgQMHDB2OyAHff/895ubmhg5D5IDatWszadKkXB1/VuSu59Wb8+fPx9ra2nABihf2tHKZmprKtGnT+O233zhw4ACjR4/GxMTEgFGKlyV1qHF7Vr1pTN+3RtOwDQ8Px87ODnd3d3bt2gXAsmXLsLOzo2XLlpw+fRrIuKLh4+ODjY0NK1eupFu3bjRr1oyDBw8CMGDAAHx8fNDpdDg7O3PlypVM+5o4cSLOzs60atWKyMhI0tPT6datG25ubowaNUpv2dDQ0EwDHQ8cOFBvmXLlyrFv3z7MzDIeaVZKUaRIkRw/R8bEmPOZlpZGdHQ0Xbt2xc3NTRsmoiAz5nwCxMbGsn79eoYNG5bTp8YoGXs+PT09sbCwyOnTYnSMOY/PqjfPnTtHWFgY7du3z9kTls8Zcz7h6eUyJCSEqlWrMnjwYFxdXTl79myBbNgae26lDjX+HGZVbxrd960hXsX8MpYtW6ZWrVqlHj9+rKKjo5VSSm3evFmlpaWpw4cPqw8//FAppZS7u7vas2ePSkxMVMWLF1dRUVHq7NmzqnPnzkoppfr3769mzpyplFJq165dqnfv3tp6N2/eVLt371Y9e/ZUSikVHh6u+vTpoxISEpSbm5tKS0tTf//990sfQ0JCgurWrZtav379S2/jReT2cD+vwpjzee/ePfXRRx+pxMREdf/+fWVvb68iIyNf+ZxkR04P95NTjDmfSinVt29fdeLECeXv76+mT5/+KqfipeXVcD/ZYez5VEopf39/NXz48Jde/1nycrifV/E65PHf9WZ6erpq27atunr1qlq/fn2+qk9zO7evQz7/XS63bNmiGjdurBISElRCQoJq0qSJSkhIeOntP09uDvfzKow9t4aqQ/NDuXzC2HOoVObyaajvW6VePm9G02M7bNgw4uPjGT58OHfu3CE9PZ2zZ8/i7u7O+PHjSUxM1JZt2rQpxYsXp0aNGlSpUoXy5ctz7949bX7r1q0B8PDw4Ny5c3r7OX36NOHh4eh0OsaMGUNMTAxlypTBx8eHQYMGaVdUnsjulZCLFy/SvXt3Pv30UwYMGJCDZ8Y4GXM+LS0tWbZsGcWLF6dEiRK4ublx6tSpnD5FRsWY87ljxw7Kly+Pra1tTp8Wo2XM+RT/x9jz+LR6c/ny5XTo0IFq1arl1GkyGsaez6cpVaoUrVu3pkyZMpQpUwZbW1suXrz4sqfIaBlzbqUOzWDMOcyKMX7fGs04tnFxcYwfP56bN28ybtw4pk2bRnBwMIcOHSIgIIDvvvsu29s6ceIEDg4OHD16lHr16unNa9SoEW3atGHp0qWkp6cTEhJCWloa9erVw8/PD09PTzp37kyZMmUAsLGxISAg4Jn7e/jwIcOGDePnn3+mXLlyL3zsryNjzmdsbCwbNmxg/PjxPH78mKNHjzJ8+PAXPgevE2PO5759+7h06RJdunQhLi6OuLg4KlWqxIgRI174PLwujDmf4v8Ycx6zqjf9/f1JTU3l4MGDXLt2DYCSJUvy7rvvZvtYjJUx5zMrjo6OzJw5k6SkJExMTDh58iS1a9d+qW0ZM2POrdShGYw5h1kxxu9bo2nYXrhwgd69e5OYmIi3tzf169fH1NSUNm3a0LZtW+7evZvtbUVERNC+fXsePHjAhg0b9Oa1b9+eQ4cO4ezsjImJCd7e3ty/f58JEyZw8+ZNKlWqROnSpV8o9gMHDnD58mW6deumTfvss89wd3d/oe28Tow5n1ZWVsTExNCiRQuKFi3KwIEDqVWr1gtt43VjzPn86quvtH8/eSFYQauQ/82Y8yn+jzHnMat685dfftE+P3lDZ37+kZWTjDmfWSlVqhSTJ0+mTZs2JCcn4+3tTdmyZXNk28bEmHMrdWgGY85hVozy+9YQ9z8bUv/+/dWxY8cMHUaeyM/P2OaUgpRPpfLvM7Y5paDl85/y0zO2OeV1zaexPGObU17XPL6I/PQs36sqyPnMr8/Y5pSCltvXqVw+UdBymJXX/hlbIYQQQgghhBDiaYzmVuScYgyDC4vsk3y+XiSfrxfJ5+tB8vh6kXy+viS3xk9y+GqMvsd2xowZbNmyJU/2dfXqVSwtLbVB4oODg3F1dcXe3p4uXbrovfHsiZCQEFq1aoWXlxdjx44lPT2dtLQ0KlWqpL2dbPz48XkSvzEwZD7DwsJwcXFBp9Ph7u7O+fPn9ZZPSUmhb9++uLi44OHhwdWrV7V5O3fuxMPDA09PT+bMmZMn8RuDvMjnxYsX8fT0xNnZGS8vL27cuAFkPKMyduxYrKysiI6OzrRecnIyX375JS1atGDevHnadCmf2ZefyytAw4YNtTz26dMnT+I0BnmRt+TkZPr06YO7uztOTk6EhoYCcOvWLTp06ICDgwNdu3YlKSkp07pPqzdjYmLo2LEjrq6uODk58ddffwFZl/+CxJD5fOL48ePamMP/Xu9p37NKKby9vXFxcaFly5bs2bMHgMjISKpWraqV2wULFuTqceV3eZHbqKgofHx8qFq1KsHBwdr08PBwnJ2dsbe3Z9y4cZnWe/DgAe+//z6urq7Y2toSGBgISB36NIbMY3baKgCpqam0aNFCa1jfvn2bOXPmULdu3afG/u86Ob8ocD22r2LChAm4uLhon/ft28e2bduwsrLC19eX77//Xm9w6tTUVKZNm8Zvv/1G8eLFuXjxIiYmJvz999+8/fbbrFmzxhCHIf6/f+dzwoQJrF69moYNG7Jz504+++wzvv/+e23+t99+i7W1NZs2beLo0aNMnDiRH3/8kYSEBFavXs3+/fsxMzPjwoULhjicAmvPnj2sXr0aa2tr1q5dy/Lly/n8888xMzNj5MiRhIeHP3U9MzMzmjRpwogRI0hISNCmR0VFSfnMh160vKalpVGjRg127dpliHALvDVr1uDo6Mjo0aM5d+4cI0eOxN/fn4kTJzJ06FC6du3Kl19+yeLFi5k6daq2Xlb1ZkBAAFOmTMHFxYX9+/czZ84cvv/++yzLv8hZWeUTMi76zpw586nDvWT1Pbtz507MzMw4cuQI8fHxuLu7065dO65evcqoUaPw8fHJs2Mr6ExMTOjevXumi0KjR4/mu+++o3bt2gwbNoxdu3bRsWNHbX5oaCjvvfce3bp14+LFi/Tv35+goCCpQw0kqzw+r63yxPz587G2ttbbnk6n49GjR0/d37/r5Pwi3/bYuri4EBUVBYCvry/btm0jMDCQli1bYmNjw+bNmzOt889XYjdq1AjIqCQ/+OAD3Nzc6Ny5M7dv39ZbZ86cOZnGd9q6dWumbfv5+eHg4EDFihW1adOmTcPKyorU1FSuX79O48aN9dYJCQmhatWqDB48GFdXV86ePYuJiQlXr14lMjKS1q1b06ZNmwIxBqox5LNatWo8fPgQgEePHtG0aVO9dU6dOqW9ydrZ2VnrMdi9ezd169alW7du6HQ64uLiXvj8GJv8lM+PPvoIa2trlFJcuXKFZs2aAWBtbZ3pNfn/VKhQIby8vChSpIje9IJYPv8tP+UXXq68Xr9+nYSEBDp06IBOpysQwwTlp7yNGjVKezPq48ePMTc3B+DYsWO88847AAwcOJDdu3frrZdVvdmjRw/tR9Tly5e1cp5V+X8dGEM+AT7//HMGDhxIsWLFMsWT1fdsp06dtAsQaWlpFC1aFMj4/j1+/DgeHv+vvXuPqfn/4wD+LPouFVqS27RsuaSLjFyKlFuTzdKak80WqqVmpDHKhlmW61zm0jBhGWOaYi4zxKyFFnaaJGq1uSVNpUid8/r90To/R3XUKXw+9Xxsnz/O5fM5H+fpdd69zufzeZ9AhISEGH5ipKdRUrYjRozAxIkTW73e58+fDT+9tHjxYsMXGS38/f0Ns5b/XJO9aQxVQ46/61UA4OXLl8jPz8eCBQsM99nb28PPzw99+vRp9fy2xmTF+BczVnXEqVOnZNeuXSIi4uvrK42NjXLz5k2pqKiQ+vp6mTZtmoiIbN26Vc6fPy8iImPHjjWs7+7uLiIix44dk40bN4qISFZWliQlJXV6X96/fy9z5syRpqYmiYiIkNLSUsNjR48eleHDh0t8fLw0NjYarXfhwgXx9PSUqqoqqaqqEi8vL6mqqpLHjx/L3r17RafTyatXr8Tb27vT+9QRSpoVWQ15VlRUSHBwsKSlpYlGo5H6+nqj9Y4ePSoJCQkiInLnzh0ZMGCAiIjs3LlT5s6dK9++fZPy8nJxd3cXnU7X6f3qCKXMiqykPEVEMjIyxMXFRcLDw+Xr169Gj82aNUvev3/f7rppaWmSkpJiuP236vNXSpoVWUn5mluvJSUlkpSUJI2NjfLx40fx8PBo9X/DXEqdFVlJubW4f/++BAQESElJSavXExHx9PQ0ut3euCkikpOTI25ubhIYGCifPn0yrGOq/rvLv5h9VQ15arVaCQsLE5Hmz9r2/Po520Kr1UpgYKDk5eWJiMj169clLS1NREQePnwoQUFBZu9rW5QyK7ISs/11Nl5fX1/Jz88XvV4v0dHRsmrVqlbrlJSUiLe3t0yYMEHevHkjIn93DP3XsyKrIUcR072KXq+XoKAgKSsrk7S0NEP9tfh530VM90TdydzcFHsqskajQVBQEPz9/eHv74++ffuisrISS5YsgYi0+jajPVqtFjk5OcjNzYVer2/1e6M7duzA7du3je6LjY2FRqMx3F67di12797d5rcWsbGxiI6OxoYNG3Do0CEkJCQYHhs4cCDmzZtn+JHkyZMno7i4GFOmTIGPjw+A5qNKVlZWqK2tRf/+/Tv25qiQGvKMiIhAeno6HBwcMGPGDERGRhqd2hgdHY01a9ZgxowZWLhwoeEI0cCBA7Fo0SJYW1tj5MiRGDJkCCorK+Hk5NSp90hNlJQn0PxtckhICPbv34/ExEQcOnTI7H+bj49Pr6vPXykpX3PrddSoUYbr3Z2cnODm5oaSkpI2v63uKZSUGwCkpqYiLy8P165dg62tLQDA0tISIgILCwvU1NS0qitT4+b06dPx4sULXL58GStXrkRWVhaA7q1/JVF6njqdDvHx8WZPdpOZmYmzZ8/i4sWLcHR0BACjI0Z+fn5Gc1n0JErLti3Hjx9HfHw8gOajs5aWrU/yHDVqFJ4+fYpHjx4hLCwM+fn5vWoMVUOOLc9tr1c5fPgwgoOD4ezs3KFtmeqJlECxja2NjQ08PDyQnJyMAwcOAAASExNRUFAAvV6PmTNntlqnsbERer0epaWleP36NYDmw/yurq5Yt24dGhoaoNVqjdbZvHkzNm/e3O5+fP36FUVFRdi+fTuA5glL3r17h8OHD+PSpUvYsGED/vvvP7i5ueHt27dG606fPh3bt29HfX09LCws8OzZM7i6uiI3NxcfPnxASEgI3r59i+/fv/fIgv+ZGvIsKiqCXq8H0HzNUGlpqdG6nz9/xpYtWzB06FBkZ2ejpqYGADB37lysXr0acXFx+PLlCyoqKjB48GDz3iiVUEqeALBnzx5ER0fD3t4eHh4e7V5T21G9sT5/pZR8u1KvxcXFePDgASIjI1FbW4vCwkK4uLiY+5aoglJyA5qv6yooKMDJkyeN7vf19cXVq1exaNEinDt3zqiRAdofN1NTU7Fw4UKMHDkSnp6eqK6uBtD99a8kSs/z9evXqK6uxurVqwEABQUFCAkJwenTp2Fvb29ye1qtFunp6bh06ZJRw5SVlYVBgwbBz88Pz58/x7Bhw0xuR62UlG17dDodbt26BUtLS6xcuRLr1683evzixYsYN24cvLy8MHr0aDQ0NADoXWOo0nPU6/VISUkx2avcu3cPTU1NuHv3ruHU/wEDBiA0NLTV9kyNyWPGjOn0/v0Jim1sgeYjZOvXrzec46/RaDBv3jxMmjQJLi4u+PHjh9HzV6xYgalTp8LLywvjx48HAERFRSEmJgb+/v4AgOTk5E7tg52dHZ49e2a4vXz5cmzbtg0uLi5wdnaGr68vbG1t0b9/f5w5cwYAEB4ejgMHDmDo0KHYtGkT5s+fj4aGBsTHx8PBwQFjx47F7t27kZKSAisrq15zgb3S89yzZw/mzJkDOzs76HQ6HDx4EMD/86ysrERcXBwsLS3h7OyMI0eOAABcXV0RGhqKWbNmoaGhAfv27YOFhYVZ75GaKCFPAPDy8sL8+fNhbW0NKysrnDhxwuTzf67PtvTW+vyVEvLtSr06OzsjJycHqamp6Nu3L3bs2NFj/7j6mRJyA5qP9pSXlyMgIAAA0K9fP9y4cQPJyclYtmwZdu3aBScnJ6SnpwP4/bjp4+ODpUuXAmie1GT//v0AOl//aqP0PJ88eWJ4TkBAAK5cuQLg95+zZ86cQVFREWbPnm24LzMzE97e3oiMjERdXR2sra2Rmpra6X1VC6Vk257s7GxERUXBzs4OGo3G8Jot2U6ePBkxMTGoq6uDiGDfvn0Aet8YquQcW/5eNdWrZGRkGJ7fcvZFW00tYHpMVox/cf4z/R1KusaWuodSrrGl7qeka2zJNKVeY0t/zr++lo+6h1KusaXuwbrsuczNTbGzIhMRERERERF1BBtbIiIiIiIiUjU2tkRERERERKRq3TJ5VGFhYXdshrqZubkwT+XqaDbMUH26mhkz/3u6471mXurSmbyYrXKZkw3zVC7WZc9ldl5dubC3rKxMbGxsBAAXhS42NjZSVlbGPHvQYipTZqjupTP1yszVlxXzUvfyu8yZrTqWjtYu81THwrrsuYs546yFiAi6oLy8HJWVlV3ZBP1Bjo6OHf7RZYB5qsHvMmWG6tXZem3BzP8+c7MCmJdadSRzZqt8nald5ql8rMuey5xxtsuNLREREREREdG/xMmjiIiIiIiISNXY2BIREREREZGqsbElIiIiIiIiVWNjS0RERERERKrGxpaIiIiIiIhUjY0tERERERERqRobWyIiIiIiIlI1NrZERERERESkamxsiYiIiIiISNXY2BIREREREZGqsbElIiIiIiIiVWNjS0RERERERKrGxpaIiIiIiIhUjY0tERERERERqRobWyIiIiIiIlI1NrZERERERESkamxsiYiIiIiISNXY2BIREREREZGq/Q9dmg5AFxHqswAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'https://bit.ly/4hwOUgx'\n",
    "df = pd.read_csv(url)\n",
    "df = df.drop(['CRIME'], axis = 1)\n",
    "df = df.fillna(df.mean())\n",
    "t_col = ['PRICE']\n",
    "x = df.drop(['PRICE'], axis = 1)\n",
    "t = df[t_col]\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size = 0.3, random_state = random_seed)\n",
    "from sklearn import tree\n",
    "model_tree = tree.DecisionTreeRegressor(max_depth = 3, random_state = random_seed)\n",
    "model_tree.fit(X= x_train, y = t_train)\n",
    "score_train = model_tree.score(X = x_train, y = t_train)\n",
    "score_test = model_tree.score(X = x_test, y = t_test)\n",
    "print(f'訓練データの決定係数={score_train:.3f} / テストデータの決定係数={score_test:.3f}')\n",
    "display(pd.DataFrame(model_tree.feature_importances_, index = x.columns, columns = ['特徴量重要度']))\n",
    "plt.figure(figsize = (12, 3))\n",
    "tree.plot_tree(decision_tree = model_tree, feature_names = list(x.columns))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
